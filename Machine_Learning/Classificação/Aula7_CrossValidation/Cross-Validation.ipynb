{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada: Avaliando a performance dos estimadores\n",
    "\n",
    "Treinar um modelo de aprendizagem e testá-lo nos mesmos dados é um erro metodológico: pode gerar um modelo capaz de repetir perfeitamente os rótulos das amostras já conhecidas mas que falha ao predizer o valor de novos dados desconhecidos. Esse problema, como já vimos, é chamado de overfitting. Uma prática comum para evitá-lo é manter uma parte dos dados disponíveis como conjunto de teste. Abaixo temos um fluxograma típico do fluxo de treinamento com validação cruzada (_cross validation_ ). Os melhores parâmetros podem ser encontrados utilizando técnicas de busca em grade, busca aleatória ou otimização meta-heurística.\n",
    "\n",
    "<img src='assets/grid_search_workflow.png' width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Scikit-Learn, podemos separar rápidamente nosso conjunto de dados em treino e teste com a já conhecida função `train_test_split`. Vamos carregar o dataset iris e treinar o SVM nele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos separar o conjunto de dados usando 60% para treinamento e 40% para teste (avaliação) do nosso classificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape, y_train.shape =  (90, 4) (90,)\n",
      "X_test.shape, y_test.shape =  (60, 4) (60,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "print('X_train.shape, y_train.shape = ', X_train.shape, y_train.shape)\n",
    "\n",
    "print('X_test.shape, y_test.shape = ', X_test.shape, y_test.shape)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando avaliamos diferentes configurações de hyperparâmetros, como por exemplo o $C$ no SVM, ainda existe o risco de _overfitting_ no conjunto de testes por que o valor pode ser ajustado até que o resultado seja ótimizado. Assim, o conhecimento sobre os dados de teste podem \"vazar\" para o modelo e as métricas de avaliação deixam de reportar a performance real do modelo num cenário generalizado (com amostras desconhecidas). Para resolver esse problema, outra parte do _dataset_ pode ser mantida, chamada de \"conjunto de validação\": treinamento é feito no conjunto de treinamento, na sequencia o conjunto de validação é usado para avaliar o modelo, e após finalizar o treinamento, a avaliação do modelo em um cenário desconhecido é feita usando o conjunto de testes. \n",
    "\n",
    "No entanto, ao particionar os dados disponíveis em 3 conjuntos, reduzimos drasticamente o número de amostras que podem ser usadas para treinar o modelo, e os resultados podem depender de uma escolha aleatória particular do par de conjuntos (treinamento, validação).\n",
    "\n",
    "A solução para esse problema é a validação cruzada (CV). Um conjunto de teste continua sendo separado para a avaliação final, mas o conjunto de validação não é mais necessário. Na abordagem mais básica, chamada $k$-fold CV, o conjunto de treinamento é dividido $k$ conjuntos menores (outras abordagens seguem os mesmos princípios). O procedimento a seguir é executado para cada um dos $k$ \"folds\":\n",
    "\n",
    "- O modelo é treinado usando $k-1$ _folds_ como dados de treinamento;\n",
    "\n",
    "- O modelo resultante é validado nos dados restantes, i.e., esses dados são usados como teste para computar a performance do modelo;\n",
    "\n",
    "A média das métricas reportadas pelo $k$-fold CV é computada. Essa abordagem é cara em termos computacionais, mas não desperdiça dados como quando separamos um conjunto de validação, sendo essa sua maior vantagem quando consideramos _datasets_ pequenos.\n",
    "\n",
    "<img src='assets/grid_search_cross_validation.png' width=500px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computando métricas com validação cruzada\n",
    "\n",
    "O modo mais fácil de se computar o resultado da validação cruzada é usando a função `cross_val_score`, passando como parâmetro o estimador e o dataset.\n",
    "\n",
    "O exemplo a seguir demonstra como estimar a acurácia do SVM sobre o dataset _iris_ dividindo os dados, ajustando o modelo e computando os pontos 5 vezes consecutivas, com diferentes divisões do conjunto de treinamento a cada execução:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "# computa diretamente os valores as métricas de saída para cada execução da validação cruzada\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor médio e o desvio padrão podem ser computado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 de acurácia com desvio padrão de 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f de acurácia com desvio padrão de %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor computado a cada iteração do CV é a métrica padrão do estimador. É possível trocá-la usando o parâmetro scoring: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96658312, 1.        , 0.96658312, 0.96658312, 1.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf, X, y, cv=5, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras métricas disponíveis podem ser encontradas [aqui](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter). No caso do _dataset_ iris, o número de amostras por classe é balanceado, então o F1-score e a acurácia são quase iguais.\n",
    "\n",
    "Quando o argumento cv é um inteiro `cross_val_score` usa as estratégias [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) ou [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), dependendo do caso.\n",
    "\n",
    "Também é possível usar outras estratégias de validação cruzada passando um iterador, como, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "# gera os 5 splits\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação cruzada com transformação dos dados \n",
    "\n",
    "Assim como testar nosso modelo em dados não usados durante o treinamento, pré-processamento (como normalização, selecão de característica, etc.) e outras transformações similares devem ser executadas no conjunto de treinamento e aplicadas no conjunto de teste para predição:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# divide os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# cria um pré-processador para normalizar os dados\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# transforma os dados de treinamento\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "\n",
    "# treina o modelo\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "\n",
    "# transforma os dados de teste\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "# computa o resultado\n",
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) deixa mais fácil organizar o processo, executando o comando com a validação cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.93333333, 0.95555556, 0.93333333, 0.97777778])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A função `cross_validate` e a avaliação de múltiplas métricas\n",
    "\n",
    "A função `cross_validate` se diferencia da função `cross_val_score` de 2 maneiras:\n",
    "\n",
    "- ela permite especificar multiplas métricas para avaliação.\n",
    "\n",
    "- ela retorna um dicionário contendo as métricas `fit-times`, `score-times` (e opcionalmente os resultados do treinamento e o modelo treinado), além dos resultados sobre o conjunto de testes.\n",
    "\n",
    "Para avaliar uma única métrica, onde o parâmetro scoring é uma _string_, _callable_ ou _None_, as chaves do dicionário serão `['test_score', 'fit_time', 'score_time']`.\n",
    "\n",
    "Para avaliar múltiplas métricas, o valor retornado é um dicionário com as seguintes chaves: `['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']`\n",
    "\n",
    "`return_train_score` é setado para `False` por padrão para economizar tempo de processamento. para avaliar o resultados sobre o conjunto de treinamento é necessário setar esse valor para `True`.\n",
    "\n",
    "Você também pode armazenar os modelos treinados setando `return_estimator=True`.\n",
    "\n",
    "As múltiplas métricas podem ser especificadas tanto como uma lista, tupla, ou conjunto de nomes de marcadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.96969697, 1.        , 0.96969697, 0.96969697, 1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# métricas a serem computadas\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "# definindo o modelo\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "\n",
    "# treinando o modelo com validação cruzada - Usando strings no scoring\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "# imprimindo as chaves\n",
    "print(sorted(scores.keys()))\n",
    "\n",
    "scores['test_precision_macro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou como um dicionário mapeando os marcadores para uma função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro', 'train_prec_macro', 'train_rec_macro']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.975     , 0.975     , 0.99166667, 0.98333333, 0.98333333])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# monta o conjunto de métricas a ser retornado usando strings ('precision_macro') e callable (make_scorer)\n",
    "scoring = {'prec_macro': 'precision_macro',\n",
    "           'rec_macro': make_scorer(recall_score, average='macro')}\n",
    "\n",
    "# treinando o modelo com validação cruzada - return_train_score=True para retornar os resultados sobre \n",
    "#    o conjunto de treinamento\n",
    "scores = cross_validate(clf, X, y, scoring=scoring,\n",
    "                        cv=5, return_train_score=True)\n",
    "print(sorted(scores.keys()))\n",
    "\n",
    "scores['train_rec_macro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de validação cruzada usando uma única métrica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estimator', 'fit_time', 'score_time', 'test_score']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passando return_estimator=True para retornar o modelo treinado\n",
    "scores = cross_validate(clf, X, y,\n",
    "                        scoring='precision_macro', cv=5,\n",
    "                        return_estimator=True)\n",
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os rótulos estimados com validação cruzada\n",
    "\n",
    "A função [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict) tem uma interface similar à `cross_val_score`, mas retorna os rótulos para cada amostra no momento em que foi classificada. O método não é indicado pois as amostras são agrupadas de forma aleatória e essa classificação dependerá do agrupamento.\n",
    "\n",
    "Todo caso, ainda pode ser útil em 2 situações:\n",
    "1. visualização dos dados obtidos de diferentes modelos\n",
    "2. mistura de modelos, utilizado, por exemplo, em _ensamble_ de métodos (quando utilizamos a votação entre vários classificadores para encontrar o melhor resultado).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteradores de validação cruzada\n",
    "\n",
    "### Validação cruzada em dados independentes e distribuídos de forma idêntica\n",
    "\n",
    "Assumir que os dados são independentes e distribuídos de forma idêntica (i.i.d.) é assumir que todas as amostras foram gerados a partir do mesmo processo de distribuição.\n",
    "\n",
    "Para isso, podemos usar o famoso $k$-fold:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-fold\n",
    "\n",
    "[KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) divide todas as amostras em grupos de amostras, chamados de _folds_ (se $k=n$, o modelo é equivalente à estratégia Leave One Out), de tamanhos iguais (se possível). O modelo é aprendido usando $k-1$ _folds_ e o _fold_ restante é usado pra teste.\n",
    "\n",
    "Exemplo de validação cruzada 2-_fold_ em um _dataset_ com 4 amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Treinamento: [2 3] Teste: [0 1]\n",
      "Fold 2 - Treinamento: [0 1] Teste: [2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for i, (train, test) in enumerate(kf.split(X)):\n",
    "    # printa os indices dos conjuntos de treinamento e teste\n",
    "    print(\"Fold %s - Treinamento: %s Teste: %s\" % (i+1, train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na figura abaixo podemos visualizar o comportamento da validação cruzada. note que o $K$-_fold_ não é leva em consideração as classes ou agrupamento das amostras.\n",
    "\n",
    "<img src='assets/kfold.png' width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada _fold_ é constituido por 2 arrays: o primeiro está relacionado ao conjunto de treinamento e o segundo ao conjunto de teste. Sendo assim, poderiamos criar os conjuntos de treino/teste com os indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = \n",
      " [[0. 0.]\n",
      " [1. 1.]]\n",
      "X_test = \n",
      " [[-1. -1.]\n",
      " [ 2.  2.]]\n",
      "y_train =  [0 1]\n",
      "y_test =  [0 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "# considerando os indices treino [0 1] e teste [2 3] acima, temos\n",
    "print('X_train = \\n', X_train)\n",
    "print('X_test = \\n', X_test)\n",
    "print('y_train = ', y_train)\n",
    "print('y_test = ', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros métodos para dados independentes e distribuídos de forma idêntica\n",
    "\n",
    "- [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold) - repete $k$-_folds_ $n$ vezes\n",
    "- [Leave One Out (LOO)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut) - similar ao $k$-_folds_ com $k=$ ao número de amostras\n",
    "- [Leave P Out (LPO)](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut) - similar ao LOO, deixando $p$ amostras fora do processo. Nesse caso pode haver sobreposição de amostras.\n",
    "- [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) - gera um número independente de divisões de treinamento/teste definida pelo usuário. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada com estratificação baseada nos rótulos \n",
    "\n",
    "\n",
    "Alguns problemas de classificação apresentam uma distribuição de classes altamente desbalanceadas. Nesses casos, é recomendado usar [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), que assegura a frequência e tenta preservar, aproximadamente, a distribuição das classes em cada divisão dos conjuntos de treinamento e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold\n",
    "\n",
    "[StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) é uma variação do $k$-fold que retorna os _folds_ estratificados: cada conjunto contém aproximadamente a mesma proporção de amostras de cada classe que o _dataset_ completo.\n",
    "\n",
    "Aqui temos um exemplo de validação cruzada 3-_fold_ estratificada em um conjunto de dados com $50$ amostras com 2 classes desbalanceadas. Mostraremos o número de amostras de cada classe e compararemos com o $k$-_fold_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "# gerando 50 amostras\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "print(X[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  3]   |   test -  [15  2]\n",
      "train -  [30  4]   |   test -  [15  1]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "        np.bincount(y[train]), np.bincount(y[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [28  5]   |   test -  [17]\n",
      "train -  [34]   |   test -  [11  5]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print('train -  {}   |   test -  {}'.format(\n",
    "        np.bincount(y[train]), np.bincount(y[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que `StratifiedKFold` preserva a razão das classes (aproximadamente 1/10) tanto para os conjuntos de treinamento quanto de teste.\n",
    "\n",
    "A figura abaixo ilustra esse comportamento:\n",
    "\n",
    "<img src='assets/stractkfold.png' width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizando os hyper-parâmetros de um modelo\n",
    "\n",
    "Hyper-parâmetros são parametros que não são aprendidos diretamente pelo modelo, e geralmente precisam ser escolhidos pelo usuário. Alguns exemplos típicos são o $C$ e o kernel do SVM, e o learning rate das redes neurais.\n",
    "\n",
    "Uma prática recomendada é percorrer o espaço de busca desses hyper-parâmetros a fim de encontrar o melhor resultado utilizando a validação cruzada.\n",
    "\n",
    "O Scikit-Learn oferece duas opções genéricas para encontrar esses valores: [GridSearchCV ](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV), que faz uma busca exaustiva considerando todas as possíveis combinações de parametros, e [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV), que seleciona um determinado número de combinações candidatas do espaço de busca usando uma distribuição específica. Ambas possuem uma contrapartida mais eficiente que vai reduzindo as opções pela metade, i.e., [HalvingGridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV) e [HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search exaustivo\n",
    "\n",
    "Faz uma busca exaustiva por todas as possíveis combinações de parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Otimizando os hyper-parameters para precision\n",
      "\n",
      "Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Resultado da validação cruzada para cada combinação da grade:\n",
      "\n",
      "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
      "0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Relatório de classificação detalhado:\n",
      "\n",
      "O modelo é treinado sobre todo o conjunto de treinamento.\n",
      "As métricas são computadas apenas considerando o conjunto de testes.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n",
      "# Otimizando os hyper-parameters para recall\n",
      "\n",
      "Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\n",
      "\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Resultado da validação cruzada para cada combinação da grade:\n",
      "\n",
      "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n",
      "0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Relatório de classificação detalhado:\n",
      "\n",
      "O modelo é treinado sobre todo o conjunto de treinamento.\n",
      "As métricas são computadas apenas considerando o conjunto de testes.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        89\n",
      "           1       0.97      1.00      0.98        90\n",
      "           2       0.99      0.98      0.98        92\n",
      "           3       1.00      0.99      0.99        93\n",
      "           4       1.00      1.00      1.00        76\n",
      "           5       0.99      0.98      0.99       108\n",
      "           6       0.99      1.00      0.99        89\n",
      "           7       0.99      1.00      0.99        78\n",
      "           8       1.00      0.98      0.99        92\n",
      "           9       0.99      0.99      0.99        92\n",
      "\n",
      "    accuracy                           0.99       899\n",
      "   macro avg       0.99      0.99      0.99       899\n",
      "weighted avg       0.99      0.99      0.99       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Carrega o dataset digits\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# converte as imagens de matrizes (2D) para vetores 1D\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# divide o conjunto em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# Seta os possíveis parâmetros\n",
    "#   Note que quando usamos kernel RBF também precisamos otimizar o parâmetro gamma\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "# métricas\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Otimizando os hyper-parameters para %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Melhor conjunto de parâmetros encontrados durante treinamento com validação cruzada:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Resultado da validação cruzada para cada combinação da grade:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Relatório de classificação detalhado:\")\n",
    "    print()\n",
    "    print(\"O modelo é treinado sobre todo o conjunto de treinamento.\")\n",
    "    print(\"As métricas são computadas apenas considerando o conjunto de testes.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca aleatória\n",
    "\n",
    "Enquanto o grid search busca exaustivamente o melhor resultado testando todas as possíveis combinações de valores, `RandomizedSearchCV` implementa uma busca aleatória, sorteando $n$ possíveis valores dentro de uma distribuição. Essa abordagem possui 2 vantagens em relação ao _grid search_:\n",
    "\n",
    "\n",
    "- O custo computacional pode ser definido independentemente do número de parâmetros e possíveis combinações (escolhe de ante-mão quantas vezes a busca será executada).\n",
    "\n",
    "- Adicionar parâmetros que não influenciam na performance do modelo não vão influenciar no tempo de busca (mais parâmetros não implica em maior número de execuções)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV levou 26.82 segundos para 20 combinações candidatas.\n",
      "Modelo com rank: 1\n",
      "Media sobre conjunto de validação: 0.922 (desvio: 0.034)\n",
      "Parâmetros: {'alpha': 0.0001967058442685228, 'average': True, 'l1_ratio': 0.5661154074913664}\n",
      "\n",
      "Modelo com rank: 2\n",
      "Media sobre conjunto de validação: 0.921 (desvio: 0.033)\n",
      "Parâmetros: {'alpha': 0.000877642574424711, 'average': True, 'l1_ratio': 0.3322874249015114}\n",
      "\n",
      "Modelo com rank: 3\n",
      "Media sobre conjunto de validação: 0.919 (desvio: 0.031)\n",
      "Parâmetros: {'alpha': 0.00046103109710893275, 'average': True, 'l1_ratio': 0.899911226269865}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandro/miniconda3/envs/torchEnv/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/leandro/miniconda3/envs/torchEnv/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/leandro/miniconda3/envs/torchEnv/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/leandro/miniconda3/envs/torchEnv/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV levou 156.55 segundos para 100 combinações candidatas\n",
      "Modelo com rank: 1\n",
      "Media sobre conjunto de validação: 0.931 (desvio: 0.029)\n",
      "Parâmetros: {'alpha': 0.001, 'average': True, 'l1_ratio': 0.1111111111111111}\n",
      "\n",
      "Modelo com rank: 2\n",
      "Media sobre conjunto de validação: 0.929 (desvio: 0.031)\n",
      "Parâmetros: {'alpha': 0.0001, 'average': True, 'l1_ratio': 0.5555555555555556}\n",
      "\n",
      "Modelo com rank: 3\n",
      "Media sobre conjunto de validação: 0.928 (desvio: 0.034)\n",
      "Parâmetros: {'alpha': 1.0, 'average': False, 'l1_ratio': 0.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# baixando o dataset\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# construindo um classificador\n",
    "clf = SGDClassifier(loss='hinge', penalty='elasticnet',\n",
    "                    fit_intercept=True)\n",
    "\n",
    "\n",
    "# função para processar o resultado\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Modelo com rank: {0}\".format(i))\n",
    "            print(\"Media sobre conjunto de validação: {0:.3f} (desvio: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parâmetros: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# especificando os parâmetros e distribuições\n",
    "param_dist = {'average': [True, False],\n",
    "              'l1_ratio': stats.uniform(0, 1),\n",
    "              'alpha': loguniform(1e-4, 1e0)}\n",
    "\n",
    "# executando a busca aleatória\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV levou %.2f segundos para %d combinações\"\n",
    "      \" candidatas.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# usando o grid search completo\n",
    "param_grid = {'average': [True, False],\n",
    "              'l1_ratio': np.linspace(0, 1, num=10),\n",
    "              'alpha': np.power(10, np.arange(-4, 1, dtype=float))}\n",
    "\n",
    "# executando o grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV levou %.2f segundos para %d combinações candidatas\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procurando os melhores parâmetros por divisões sucessivas\n",
    "\n",
    "O método por divisões sucessivas ( _successive halving (SH)_ ) funciona como um torneio entre as combinações de parâmetros. É um método iterative em que todos as combinações candidatas são avaliadas com uma pequena quantidade de recursos na primeira iteração. Apenas alguns candidatos são selecionados para a próxima iteração, na qual será alocada uma quantidade maior de recursos. Para otimização de hyper-parâmetros, esse recurso representa o número de amostras de treinamento.\n",
    "\n",
    "Como ilustrado na figura abaixo, apenas um sub-conjunto de candidatos \"sobrevivem\" até a última iteração. Estes são os candidates que conseguiram resultados consistentes entre os melhores por todas as iterações. A cada iteração, uma quantidade maior de amostras é alocada por candidato.\n",
    "\n",
    "\n",
    "<img src='assets/halving.png' width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando Grid Search com Divisões Sucessivas\n",
    "\n",
    "Este exemplo compara a otimização dos hyper-parâmetros do SVM usando `HalvingGridSearchCV` e `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente definimos o espaço de busca para os hyper-parâmetros do SVM, e computamos o tempo necessário para treinar usando `HalvingGridSearchCV` e `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "X, y = datasets.make_classification(n_samples=1000, random_state=rng)\n",
    "\n",
    "gammas = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "Cs = [1, 10, 100, 1e3, 1e4, 1e5]\n",
    "param_grid = {'gamma': gammas, 'C': Cs}\n",
    "\n",
    "clf = SVC(random_state=rng)\n",
    "\n",
    "tic = time()\n",
    "gsh = HalvingGridSearchCV(estimator=clf, param_grid=param_grid, factor=2,\n",
    "                          random_state=rng)\n",
    "gsh.fit(X, y)\n",
    "gsh_time = time() - tic\n",
    "\n",
    "tic = time()\n",
    "gs = GridSearchCV(estimator=clf, param_grid=param_grid)\n",
    "gs.fit(X, y)\n",
    "gs_time = time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora plotamos os mapas de calor para cada método de otização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAEFCAYAAACcgIJfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABgS0lEQVR4nO2deXxU1fn/35+EJUCAsAiyyiKIChoRcKF1wQWq1K0qLq1Y17rUrXVptSpWf61Va7HaulLUulaty9cFd60oCiiKKJso+x4SICRAkuf3x7kDwzCTzExmkszkvF+v+yJz77mfOXM59z73POec55GZ4fF4PB5PYyGnvivg8Xg8Hk9d4g2fx+PxeBoV3vB5PB6Pp1HhDZ/H4/F4GhXe8Hk8Ho+nUeENn8fj8XgaFVlr+CTdLMmCrUrSOklTJd0madeIsr2CcqMT/A6TdGmC57wtqTI4d6ukuxM5P1kkNZV0laSvJW2StEbSp5Kuq4vvTzXB/++a+q5HQ0bSCZLelLRW0hZJSyU9J2lUnOe/L+m5GsrkB2357JRUup6QNFHStPquh6duaFLfFUgzJUDoJm8LDAYuAi6QNMrMpgfHlgMHAbMT1D8I+D7Bc44C9gWWAGut7hZS3gucCdwGfAoUAAcCPwX+XEd1SCUPA6/UdyUaKsEL1WXAY8A/gbXAbsBpwOuSdjez72qQuRjYmtaKejz1gLJ1Abukm4FLzaxjxP4C4EOgBTDAzCrrvnZ1i6SWQDFwvZndEXFMdWh8PXWApOOBF4FfmtnEKMd/Ckw3s2Uxzm9hZmVxflc+sCHWd9U3kpoCVTXd55ImAgPNbEidVMxTr2StqzMWZlYMXAPsjut97eTqDNweUyPPlXRJ4CZsHXzewdUp6UeS/idpfbDNkHRK2PHcwEW3SNJmSbMknRHle34s6YPgu9ZKeij0ncHxAkkPS1omqTzQe6ian90KaAqsiHI9thk9SWcHvyk/oj4/SLozYt+Jkj6TVBbU8TVJu4UdHyjpVUkbgu0/4S7mwPV6Z9i1WCbpv5KaxfMbw12dklpJKpV0SZRrOVXSv4O/u0iaIGlBUO+5km4NfWfYOb+TND/43pWS3lCEe7yBcwUwNZYhMrNXwo1e8H9+laS/SVoNzAz27+TqlPSz4LqVSfoQGBBPhWq6ppLaS3owOFYu6WNJB0Ro/Cb4/ywJyr0iafeIMu/LuXMvkPQdUA50DY6dL2lmWB2ek9Q24vyjJH0VtKePJO0dz+/zZBbZ7uqMxftABc7V90aU488Ar0nqbWbhrswxwGtmtiHyBEltgP8DXgJuAQQMwrkUQ9yCM7rjgKnAz4An5DpdTwU6w4G3cW/sJwMdcK7IdsFngL8CBwNX4oxZD+CQWD/WzFZLWgzcLKkUeCvab4gXSb/AudCeBv4Y/NYRwC7AwuBhNBmYBvwc187+CLwiaVhgbH+Hc71eh3MX7wocA+Qm+hvNrFTS/wGnAveF1bMPMAR3vQE6AkXAVcA6oD9wc1DvC4NzzgJ+D1wLzMJd/xG4l4cGj6QmOBf8nTWVjeBqnCfkF8R4IZY0GHdv/Be4HBgIPBtHnaq9ppKa49p8QVCPVbghibcl9TOz0Atbd5zLfiHQBvgV8HFQpiTsK4cDfYPv2wSUSLoBd//9I/iOlsCxQD5uSASgJ3AHbjigDHcNn5E0yHtFsgwzy8oN90BbU83x5cA/g797AQaMDj43AdYA14WV7wZUASeH7TOcOxXcA9aA1jG+rz1QCtwUsf81YE7Y5/8B70WUGRFoDww+fw38OsHrMQL3QDGgEmeUfgs0CytzdnA8P+LcH4A7g79zgKXAC9V81+PAnAjtfsH3Hht8/j/grmo0qv2Nkf+/wImBftewfb/DGbqmMTSaAGfgegXNgn33As/Xd/utRbvvHPwfXhixX8HvDW2KaMefR9F6H3gu7POzwDcR514fnH92NXWq9poC5wJbgH4R/zffAXfEOCcXN1yxATgros5lQOewfQU4A/jXauowEfcyHF6HE4LfNqC+/1/9ltqt0bk6w1CsA2ZWAbyA6+GFOAVnuF6Ncdp3wEbgSUnHy40lhjMQ95b5n4j9zwD9Je0iNxZ3EPCspCahDfgIN8lg/+CcGcDVki6W1L/6n7ntN72Lews+DZiAe+u+A3hXUiLtYA+c6+hf1ZQ5EtcrqAr7Dd/jDGhoDGUGcLakayTtIyny/2MGif3G13HX/5SwfWOA/5rZVnDjmZKukPSNpDLcNX0CaI572w997zGSxkkaJimXzCSyh/Ib3O8NbZFu4dfi0BwGvGyBVQh4IY7zZlD9NT0SmA58H9ZeAD5ge3tB0oGS3pK0FmekNuF6bJHtY7qZrQz7fBDOSFbXZgF+MLN5YZ+/Cf7tXsN5ngyjURo+SXm4B//Kaoo9DRSGPXTH4G76qIP+ZrYON2bYFPdmvFpujKtPUKRL8G/kd4Y+t8e5M3Nx7pjwh9TmQLdHUPZSnCv0RmCOpHmSTqvuNwd13GBmz5jZ+UAfnPtxOG5mZ7x0CP5dXk2Zjjg309aIrU/Yb7gV55a8GPgSWCzp8jCNhH6jmZXj3MxjACTtgZs9+3RYsStw7qv/AsfjHuQhA5AX/DsB55Y7FTf7dWUwDpgpBnAtrr1EPqwfB4YGWzSquxdC7IrzGoQT+TkaNV3Tjrhhh8j28kuC9iKpJ/Am7oX1Qly7HRp8fx47Evlb4mmz4CaAhbMl+DdS35PhNErDBxyOc6V8Uk2ZD3A30Bi5SRsH4npnMTGzKWY2CudaOQn3JvpkcDh003WKOK1z8G8R7sYz4Ca2P6TCtwnB9xSb2WVmtivu4f4pbqxwr+rqF1FXw/X4YPsEhfLg32YRxduF/b02+LcLsSkCHojxG24Nvr/czG40s1646/QM8DcFa8yS/I3PAAcGD8kxwGrg3bDjp+Bcd9eb2ZtmNhXXi9+GmVWZ2d1mtieuF3gnzmV6fjXf22AIvBWfAEdH7F9pZtPMLNZatXjGsFawc/uN/BytTjVd0yKc6z1aezkxKDMK5zE53syeM7OPcT3J9nH8lnjarKcR0egMX+CCvB2YjxtQj4q56c//wT1AT8UZpWgTYaKdW2Zmr+AMVehB/TXONXNKRPFTgblmttrMSoEpwB6hh1TEttP0czP7CjdYn0OMGXZyMygLohzqF/wbekNeEvy7Z9i5B+AmEoSYgxvjGxvtuwLeAfbGuZwif8MPUX7DPNx442a2X6/w4zX+xoA3cf9Pp+L+356zHaextwi+I5wzY4mZ2WIz+zOurcT9UtEA+BtwQDAJKZVMBY6LcEuflIhAjGv6Dm6W9aIo7WVmUKYFboy9IkzuVOKboPcJbtyvujbraURk+6zOJpIODP5ujRsjuwj35jjKal7D9wzO5XYl8KKZbYlVUNKxwDk499wi3GSYCwl6HGZWJOlvwA2SKnBvuCfhZjKeHiZ1DfCOpCrgOdzgfU/cDLTrzWyupI9w7rqvcW+35+N6Lp/FqF5bYK6kR4H3cLPY9sC9dS8NtAjOXwrcI+kPuLfpa4D1ISEzq5J0Da739QTwVFCHEcBTQY/i5kDrVUkTcBOFuuFcwRPN7H1J/8WN63yBeyidjGuPHwbXM9HfiJltlfQCbtZmF5wbNZy3gMskfYobkz0T98DdhqQHcD2QKcF1Ohz3gnBtrO9taJjZS0FbmyjpcNxC/zU4l1+oJ7gxCenbcT3vZyU9ghu3Premk+K4po/hZmi+L7dsZkFQ12HACjO7G3cf5QL/Cr57b9zLUnFN329mxZL+CNwmt3TlNdy47rHAODNbGtev92QP9T27Jl0b7uFrwVaFu0Gm4aYq7xpRthdhszrD9gtnxAwYGeU7wmd17oEzVItxvYolwP1A+7Dyubip9Ytx4wffAGdG0T0A17tcj3vYf4Ob3t82OH4Hbq3VhuB3vQf8uJpr0Qy3bOBDXO+uDPfGfT/QPaLsUNyb/SacURpO2KzOsHIn4QxXOc6V9CqwW9jxAcH1KAr7vgdC34frwU3DPQg34B6ox4edX+1vJMasXdxECcMZ8JyIY/m4CQ5FwfYwMJodZ8yejVuKURRcg6+Ac+u7PSd5D5yIM/ZFuDGzZcDzwE9iteOI/e8TNqsz2HdK8H9Zjpt0NZSaZ3XWeE1xL2fjw+6NJbiJM8PDyvwC98JShjOiB0S2zWh1Djt2Ie5e2oxz2z4LtAmOTQSmxfNc8Fvmb1kbucXj8Xg8nmhku6vT4/F4GiUjD29la4tSH5Fx+lebJ5mbxJexeMPn8Xg8Wciaoko+nZT6JYhNu3zXseZSDRtv+DwejycLMYyt2R+DPym84fN4PJ4spYqq+q5Cg8QbPo/H48lCDKPST16MSqNbwB4Pkk5VhmeUThdB2pan5FIVmVzew3jOez8oH207KCjTRdIdkr6UtFHSYkmPSuoaoTWxGq3To9cgM/BtLzZBrNXr5VJUlUv6XNLIOM9tIum6IPTdZklL5JL1ho43k/SstqesWi3pdUn7R9E6QS510WZJ30u6KpW/M5VUYSnfsgHf44vOqbj4gRPruR4NkVHAPrhoGzXGBw3jYnaMAAMuTcx+uHWD4AIMnIhbX/cpLpzbzbjUMwPNLLTo+o+4NYjhXITLtPBWAnVqiPi2F5vrcLFbb8SFK/s5LtXVcHPh56pjIi7IwjhgNi4GaHg0nlzcmr0/4dYKtsEFrnhX0n5mtgC2pQ17AReV6be4tYS3S6oys7/V/iemDgO2eldnVPw6vijIJd/saGaH1XddGhqScsysKvh7DXCvmd2chE4z3CLiZ8zsomBfAbDRXLzJULn+uDBpZ5vZo9XozcKFvPpJonVpSPi2F52gvawBxpvZH8L2TweWm9noas4dhYtes6+ZfROrXJTz8nHBGX5nZn8N9k0CWprZj8PK3YULqL2rVRPdqa7Zd99mNum11E/A7NJ9+XTL8Ez13tUZgaSJuASxh4a5z24OO368pGmBq2WFpL9Iahp2/GZJayQdEJQrk8vk3FtSJ0kvBm68byWNiPjuH+Sykv8h0N4o6QntnCW6d6CzXi67+U6ZqNNFyOilgFG44NdPhWkXhxu9YN9cXLSPrsRA0j64t/enIvafqyAFUfB/8oEacEZt3/aqpS8u7GBkj/5N4KjAMMbiHODdRIxeQClBrsawfYUx6tAOl/4IqDnjfF1RlYYtG/Cuzp35Iy42ZgHbYz0uATf+gnu4PoBLs9IX5xrJwbk9QrQEHgT+grt57sGlhdmMyxv3D1wMzP9I6mFmm8LOPR0XEup8XLzJv+Bcf6cEdWiOczNuDcpU4Nw3H8hlii6K9cO0Pc9ZdVRa3bgBTsNd1/9VVygwai2BuTVolePipIbOOwTnDr0RF6S4De7B1DbK+Q0F3/Zit71QaqDIHtUWnGHqg3NhRuMA4GVJ9wJn4Z57b+DCtO0Q+F2ScG7PjrgchpXs+EKVF6MO4IK7f6AaMs7XFYZRmSVjcqnGG74IzOw7SUW4OI9TQvuDG+IO4DEzuzhs/2bgPkl/MrNQ+pMWwGVm9kFQpisu99xNZnZnsG8J7qY4FPdAIuzcY0PjWZJKgccl7Wlm3+JcKj2B/mHjDp/iAvteiHsYxmJrHJfgl6R5fEku4e5xwAPVGVm5BLnjgXnAy9VIjgFeM7P1YfuGAV+ZWfj1qE6j3vFtr9q2twA3bDUUF6czxLDg32jpiULsiosX+iXuJak1zqj/V9KBEW3wWrb/jtXAMWa2MOz4fHbOaRhZh2HAm2b2j7Ay8STsTSlmsNXbvah4wxc//XE3/bMRb6/v4t4CB+Jy+IF7AwzvycwPKxu5r1vE97wVNokDXIYC4W62b3E31eehBw+AmS2RNBn4UQ2/IVYS0nC+j6NMbfkp7u33qRrK/QnXSzvUgizqkcilTerDztkTZgB/kZu5919gSkMaf0mQRt/2zKxE0lPA9ZK+xhmxM3FByaF6L5yC7fjQC4Kk5bhrNgLXiw0xEZeuLJTd4/8kHRLmJr0fuF/S+bgg7MNw2UDC6zADOFfSOFzw9ulWcyaYNCAqUc3FGiHe8MVPaJT4tRjHe4T9vSFiLCz0wC0O7TCzLe5FfqfszjtktDazTZI2sj2JZheiZ8teCewWq/IBM2o4Ds61k25OA+Zb7KSoSLoYl8HhdDP7tAatDbgHzDbM7G1JvwQuAy4HNkp6HLjGXN7DTMK3PccVuFRhISO+GJfY+GbcRKlYrAMWhPWKwWWW2IIbG95m+MxsRUhL0uu4nvF1OBcpuNmc+wL/xLmUN+Feuv4eVocJuF7lBThX+1pJ9+N63XVmAA2o8j2+qHjDFz+h8YsLcOl6IklVT2mHjNaBWzCf7Rncl+NykUXSOayOsah3V2cwWeInOFdTrDI/wz1IrjGzmFnvA1foqbhciWWRx4NZoI9K2gWXRulunJG8rlY/ou7xbQ8ws9XACEndcWO1c3DGcIVFSXAcxrfsbOTB9QJj9hTNrELSTJxHIbSvErhULl9ld9y1DyVHnhKUqcK1tbsl9cD1TG9je6qyOsGALX7+YlS84YvOFna+UUKZx3uZ2UNp/O6jJOWHuZxOxLXhUO/oU+AsSb3N7HsASd2Ag3FvvtXREFydJ+KSgEZ1c0o6DHgC+HtoTKoaDsHN9qzWZRo8MB+QdBINP5O6b3s1YGZLgCWS8nAzNifUcMr/AeMkdTSzNcG+Q4CmOJdpVAL9wbhcgpF1WIfrSYa8Ex+b2U6Ta8xsMfDnwPtQ522vyrLH1SnpXzWVMbNfxqPlDV90ZgPHSzoB95a2zMyWSfoNbrC/DW5SwBbc2+AJwMkRM+SSpQyXufwOnGvpDuC/YWMME3Guldcl3YhzD92EW+P0QHXC1bkW40XSbmx/iDUD9pJ0MlBqZq+HlfkOOMfMHouQOA34MpgsEam9J25m5mzgGUkHhh1ebWbfRdFaQ5RF68H4SntcYtI1uIXyh9Lwe3u+7cVA0i9wxmoBbszzyqAOfworE63tPYhzeb8i6f/h3JC3A2+b2UfBeafjPBFv4BL2hsb4uuCSQIf0D8SNZ87AzRQ+HRhJ2Binas44XycYZNsYX6S3QThvQzfc9f4hXiFv+KLzD9yDcgJufc444GYze0bSetxU5XNwN90C3BtlqiZOPI1zxz2CczO9jItKAoCZbZZ0JO5mfAT3n/8+8LPqppOnkMNxWcxDnBJsC3EZqwnqlEvEOlFJHYEjgD8QnQNwLqx9gY8jjj2Km5kX0mqCW/P2fOTav4CpuAdjaBbfQlyvZHzsn9Yg8G0vNjk447EbzqC8CPw+YkLOTm3PzNbLrVu8B/cbtwAv4dpHiNm4SDB/xV335bge7hAzmxVWbituFvHNODfp/3BZ4meGlfkEt9zjQlzvfT5wvpm9mPQvTwJDVGaRq9PMhkXbL2kQ8B/ceG9c+MgtDQhJPwDPmdlvayrr8aQS3/ayjwH7NLcJr0RO3K09w3t93+Ait0g6A/cSNDCe8r7H5/F4PFmJqLTs6fHVwAqgn8JCKlaHN3wej8eThRhQlUWuzhBBQIc9cGP4a4KwhrNxazJziSOymjd8DQgz61XfdfA0Tnzby07qY3KLXFDw8Tgj9LCZ/Tni+G64MexdcJNSfh7M1I1H+1TgLsKCL0hahFv69Gy8dcy+1wGPx+PxYCa2Wm7Kt+qQlIsLkfcT3PKN0yVFLuO4Exd+bx9carLqQt2Fa4/ExZ2dCJyH69T+BBdp50lJx8d7bRptj6+Zmlte3caM9aSI3fdJT+CVL77assbMdkmLeBi+7Tk292yZNu29ClbVXCgJctLUg/o8DW3PLWeo877NMFxUplAs16eB44HwzBh7sT3M23uEBZevgd/j4vv+QdJg3Azet81skqQy4AbcbN0aabSGL49WHKAj6rsaniR4+Y2aco4mR8uuCxfWXKr2+LbnmHt91NnpKeGD0fekRbdFtdmPkqdZ1wVpaHv1MrmlGy6UXIgluGVK4XyJi6Q0HhckobWkDhEh5aIxGPhzjGMv4XqBcdFoDZ/H4/FkMwY1uiaTpKOk8IAED5rZgwmc/1vgXklnAx/iohLFE8O0kthrVvsSFo+2Jrzhi0HHbu0Ze8sYho4spHWH1hQtX8fHL03l8XH/YWNx8q42r5te3UhyW5xAs4K/AbCl+Foqy2KG/vR4soo0LmBfU806vqXsGDS9e7Bve71cDsSTYFuW+5+ZWXEc37sAZ+DCs2n0kHQ4ricYt/H1hi8KXfp0ZvzkW2nXuYDJL37G4jnL2GPo7px0+bEMGVnIFT+6gQ1FG2sW8rp1qhuJcrrQtM0tWNVGlJNfaz2PJ9OoqntX51TcerreOIN3GnBGeIEgglNRsN7ud9QcazXEK7jxwpCBM5wxLMNNqPl9vJX0hi8Kl913Hu06F3DvZY/w0r1vbNt/4V1jOfnK0Zxz2+mMvyjxWMFeN726kTQtuAOrWkdl+Rs0zb+w1noeTyZRH5NbgowWlwKTcMsZJpjZLEm3ANPM7GXgMOBPkgzn6rwkTvlxuPjA4AKa/wI3nvh1EDQ8bvxyhgi69OnMkJGFLP9+FS/fN2mHY4/d9AxlG8s54ueHkNeyuddtQLqR5Lb8JTnNDmZrydWwc8YijyfrMep+OQOAmb1mZv3NrK+Z3RbsuzEwepjZc2bWLyhznpltjvMnNSEwfGa2zsyeNLP/JWr0wBu+nSg83AUAn/7Wl0TGMS3bWM6sybNp0SqPPQ/s53UbkG44atKXpm2upbL0X1Rt+SxpHY8nkzGDSstJ+VaP/B3XkwRAUhdJ/5O0QdK7QYqsuKjTXyFpgqRVkr4O2zdR0veSZgRbZFT+ULnekj6VNF/SM5KbVyzpEEmfS6oI0uPUiu57uGu3dO6yqMeXzndJlrv17+p1G5DudnJp1vZurHIpWzfEzHXr8TQCRFUatnrkECA8zdltQAFuHLE5LvlvXNS1+Z4IjIqy/2ozKwy2g2Oceztwt5ntjksAeW6wfxEuXc2Tqahgq7ZuUW1pSfT0ZqH9+QWJLb71uunVDdEk/zLUdG+2Fl8NxOtB8XiyDyPrenw9gLlhn48H7jSzV3GzOg+NV6hOJ7eY2YeSeiV6XhCUdATbZwc9isuH9U8z+yEoU2NgUk92o6aFNMm/hIrSh6ja+nl9V8fjqVdCY3xZxCZcfkMkDcPlTXw3OFaCy7sZFw1lVucdkm4I/p5lZmdGHO8AFIclHF1CWJDSeJF0AXABQB7RexShHkeoZxJJaP/G4sQSXnvd9OpCLs0K7sIqvqdiw19rLl7HxNP2PJ5Uk02JaHEZ7a+StBa4CfjSzEJRYvoA0cdPotBQDN/VZvZcur8kiC7wIEAbtY+agXfJHLfWMtYYU7fddwVij1HFwuumVxe1IqdJXwBadJkbtUizgtuh4HYqSiewdf0tienXknjanseTSox6WceXTn4HvAlMxvX+woNSDwCeiFeooRi+nZA0CegMTAPOBwokNQl6fTtFA0gVM96bBcD+R+2LpB1mHrbIz2Pv4QMoKy3n2ynzvG4D0sU2U7Hp6aiHcpoOJKfpQCq3fIZVLKBqi3eDerKfbHN1BusB+wB7AgvDlzGY2XWJaDXY1wEzGxlMdjnP3NPxPSA0a3MscUbhTpTlC1YybdIMuvTuxHGXjNzh2FnjxtAiP493/v0h5ZsSmzjhddOrC5vZWnJd1K2y/G0AKjc9H3z+vwS1PZ7MpBKlfKtPzGyzmc1IZu1eOIpcS5VOJD2FW7XfEViJ89P+GDcbpySs6DAz2xJxbh/gaVzW3S9wyQs3SxoK/Bc30FkOrDCzvWuqSxu1t1gR8iNDai2avZQBw/qx34iBLJ6zjMuHX5+SUF1eNzndl5cmlp2hSf4VNG19RY2xOlt2XTi9mhiEKaO6tteYmHt/+rIzzMy87Awpb3vd9i6wi5/9USolAbhh4Kt1cp9EQ9IxuIwO3QkmuoRjZofHpVOXhq8hUdPDZ5fuHRg7bgxDRhXSJgiiPPnFz2odRNnr1l7XG77swBu+7aTL8F34zCGplATgpkGv1Ivhk3Qt8P+AecBsomRqMLNT49Lyhs+TaSRq+OLFG766xRu+7aTD8HXdu52d+/RhqZQE4NZ9Xqwvw7cQeN7MrqqxcA002MktHo/H40keN6uzfsfkUkwB8GoqhLzh83g8niwly9bxvQQczo75+JLCGz6Px+PJQgxlW4/vWeAeSR1wwap3mtlpZh/EI+QNn8fj8WQhZmTVOj62L2HbFgUpAhHnEj1v+DxpY9KyGWnRPWHe6LTouiTOnkjSNQklXRNQIH2TUDKNLOvxDUqVkDd8Ho/Hk4U4V2f2jPGZ2Tep0vKGz+PxeLKU+o60kkok7ZZIeTNbGOuYN3wx6NitPWNvGcPQkYW0DhZYf/zS1Fov3Pa6Du3yHsrtHvWYVa7GVsdKyxib1k1acWCHfRjSfiC9WnWlfbO2VFglC0uX8c7KKby9cgpG41y36ml8GKKiKqvG+BZAXJbcqGG8zxu+KESG1Fo8Zxl7DN2dky4/liEjC7niRzekJFRXY9UNYVXrYdPEKPsTTUnkGN5xPy7udxprN5cws2Quazavo6Bpaw7suC+/7n8mg9vvxe3fPpJ0fT2eTKOeM6anmp+mSsgbvihcdt95tOtcwL2XPcJL976xbf+Fd43l5CtHc85tpzP+ooe8bpK627D12Ma/J39+BMvKVvHHWfczrWjWDj27x354mbsKr2Z4x/04qEMhn6ydkbLv9HgaKmZQmUWTW8zstVRpZc/IZ4ro0qczQ0YWsvz7Vbx836Qdjj120zOUbSzniJ8fQl7L5l43Cd108lXJXKYWfb2TO7N46wbeWPERAIMK+tVH1TyeOifk6kz11hCRVCjp+3jLe8MXQeHhLrHD9Le+JDKOadnGcmZNnk2LVnnseWBiD1CvG41mkHcctPoVtBwLzQ4gXU2yoqoSgEqrTIu+x9MQqUIp3+oLSYMlvSNpqaTV4RsubV3PsH1XV6dVp4ZP0gRJqyR9HbZvoqTvJc0Ito9jnNtb0qeS5kt6RnILdSRdJekbSV8FFyWhmT+RdN+jGxA7A/jS+SuA2BnEvW78KLcTOQV3kdP6N+S0uYGc9v9GHd+GpqldN5ZDDod3PgCAz4u+Tam2x9NQCcXqTPVWj9yLS2n3KPD3iO0/uAktoc+fVidU12N8E3GVfyxi/9Vm9lwN594O3G1mT0u6HzgX+CcuN98QM9sk6SLgL8CYZCvYqm1LAEpLok+wCO3PL2jpdZPQDWGbnse2ToOKeVBVCk16oJa/gBZjUPuHsbWnQsXspLQjGdv7eHq16srUoq/5otgbPk/jIZvW8eEWsI+OFpZM0jDgPDO7JR6hOr0qZvYhUJToeZIEjABCxvFR4IRA8z0zCz2dp+ASFHoaOqX3wpYpULUWKIeKedj6G2HTBKQWKP/XKfma0V0P5cTuR7B40wrunhP5vuXxZC9mosJyUr7VIy2B6qaRx71WqaG8DtwR5up8IsrxDkCxmVUEn5cA3aKUOxd4PdaXSLpA0jRJ07ayOWqZUE8m1OOJJLR/Y3FiU+69bnzYpqfcH82G1lrr2C6HcEHfU1hUupzrvxrPxorU1jUR4ml7Hk+qyTJX5+HAnBjHvgmOx0VDWc4Qj6uzWiT9HBgCHBqrjJk9CDwILhlotDJL5iwFYo9dddt9VyD22FcsvG6cVAUOASXnQg1xXNfDOK/vyfxQuow/zLyHkq3JrzdMBfG0PY8nlWRbPj4z+1DSQEkjgDLgDTNbHBzbCHwYr1ZDMXw7IWkS0BmYBpwPFEhqEvT6ugNLw8oeCVwPHGpmtXqdnvHeLAD2P2pfJO0wo7FFfh57Dx9AWWk5306Z53WT0K2RpoXu38rFSUuc1P1Izu59Ags2LuYPM+9lQ0XyEWY8nkwmmwyfpDNxw1wVOG9lmaSRZjZF0l3AUjP7azxaDcXVuRNmNtLMCs3sPHNP3feAk4PDYwlSVEjaD3gAOM7MVtX2e5cvWMm0STPo0rsTx10ycodjZ40bQ4v8PN7594eUb0rMvnrdMHL7glpE2d8NtbkJACt7aefjcTCmxyjO7n0C8zYs4oaZf/dGz9NoMbJujO9m4BmgNdAGN3Pzj8GxGcBp8QrVaY9P0lPAYUBHSUuAm4JDd0i6IazoMDPbEnH6tcDTkm7FzeQMxZ66A8gH/uPmwLDIzI6rTT3vueRhxk++lUvvOZf9Rgxi0eylDBjWj/1GDGTxnGVMuP4pr1sLXbU4BlqeA1umQdXSYFZnT2h+GFIeVv4+lCYeWmxEpwM4s9doKq2Sb9bP56ddD9upzMrytby7qtqZzh5PdmDZ1eMDugKPmNlWYGswu//B4NhCoH+8QnVq+Mzs9Ci743rCmdkCYKcFXmZ2ZG3rFcnyBSu5ZOh1jB03hiGjChl2zGCKlq/jhfGv1io4s9d12OZPUW4faLon5Ax2vT/bAFumU1X2IpS/mJRu57wOAOQql+O7jYhaZmbxPG/4PI2CbBvjA74EBgLvBp+XAe0l5eB6gOXxCjXYMb76ZvWStdx57j+8bjp0t36GlXyWWk3gqUWv8dSilIXz83gyGheyrMGOZiXD5cBzktbgXJ4hr2Bz4FdA3A8Vb/g8Ho8nS7Hs6vE9gxvW+jcuGEoRrmO7EjfLM+5cZt7weTweT5aSZWmJoi15KwfmAi+Z2YZ4hbzh83g8nizEsmxyi5ldkyqtrHIAezwejyeEqKzKSflW47dKoyTNCRIKXBfleE9J70n6IkgucExCv0rKkbSbpAOCfxO2Y77H18iZtGxG2rRPmDey5kJJcEX3t9Ki+0paVOuOufenNqtFiJmj70mLbguXYCUtVJCe9FNbMyytVV2P8UnKBe4DjsKFlpwq6WUz+yas2A3As2b2T0l7Aa8BveLUvwK4BtgVN74nYLmkv5jZ+Hjr6Q2fx+PxZCH1tJxhGDA/WH6GpKeB43GxNMOr1ib4uy1uWUKNSBqHi9D1AC6AySqgE3Ac8FdJ7czs5ni0vOHzeDyebMTcOF8a6ChpWtjnB4NYtOCSB4THG1wCHBBx/s3Am5J+DbQC4l2L/Svg/5nZjRH735S0Frgo0K4Rb/hi0LFbe8beMoahIwtp3aE1RcvX8fFLU2u1cDsTdbXLeyg3eqYnq1yNrY57BvE2WjdpxYEd9mFI+4H0atWV9s3aUmGVLCxdxjsrp/D2yilY/BlGdqBvu9/SuvlAWjbtRdOcdlRZOeUVy1i96W2WrH+CiqripHQ9nkzDgMr0hBhbY2ZDanH+6cBEM7tL0kHA45IGmllVDeflAf+Lcewj4Mp4K+ANXxS69OnM+Mm30q5zAZNf/IzFc5axx9DdOenyYxkyspArfnQDG4oSj/afabohrGo9bJoYZX9yaX6Gd9yPi/udxtrNJcwsmcuazesoaNqaAzvuy6/7n8ng9ntx+7eJhywD6NF2LBs2f0NR2cdsrVxLjlrQNq+QPu0uo1vrMUxbdiqbK1ckpe3xZBb1kkZoKdAj7PMOCQUCzgVGAZjZJ5LycJnVa4q1/DLwMyDaIP9JwAvxVtIbvihcdt95tOtcwL2XPcJL976xbf+Fd43l5CtHc85tpzP+ooeyXncbth7b+Pfkz49gWdkq/jjrfqYVzdqhZ/fYDy9zV+HVDO+4Hwd1KOSTtTMS1v5w4f5U7RTmFfq0u4JeBRexW8GFzF07rjbV93gyhjS5OqtjKtBPUm+cwTsNOCOizCLgCGCipD1xPbnVcWi/iovr/BbwPNvH+E4C9gSukXRsqLCZvRpLyC9niKBLn84MGVnI8u9X8fJ9k3Y49thNz1C2sZwjfn4IeS2bZ7VuOvmqZC5Ti77eyZ1ZvHUDb6z4CIBBBf2S0o5m9ABWlbr8xC2b7paUrseTiZgp5Vv132cVwKXAJOBb3OzNWZJukRRKHvAb4HxJXwJPAWebxWWin8AFqh6Bmzn6n+DfI4L9/8b1Cl+mhknavscXQeHhewMw/a0vify/KNtYzqzJsxkyspA9D+zHF+9+nbW6O9IM8o6D3K5gZVAxG7ZMBWpyySdORZWbLl6Z4mnjHVu6oNUbt8RK4OzxZBdmxLXuLvXfa6/hliiE77sx7O9vgOFJSPeuZdW2kZThCxYM5kXuN7NqB30kTQBGA6vMbGCwbyIua3pJUGyTme00YyLoOj8NdACmA78wsy2SfgVcAlQCG4ELItaMJET3PboBsTOLL52/giEjXWbyRAxJpumGo9xOqOCuHfZZxWKs5DrYmrpg0znkcHhnNwHs86Jva6XVo805NMlpSW5Oa9o0H0hB3hA2bJ7NwuIHaz45AZK9FzyeuqAeXJ1pw8wWpUorbsMnl+zuGlw29FiWN7cGmYnAvcBjEfuvNrNocdjCuR2428yeDvIwnQv8E3jSzO4P6ngc8FeCgdNkaNW2JQClJdGfW6H9+QUts1o3hG16Hts6DSrmBXnzeqCWv4AWY1D7h7G1p7oeYAoY2/t4erXqytSir/miuHaGr2fbc2jeZJdtn9du+pBvVl/H1qp1ta1mqu4FjyftZFmQagAkHY1bItEFWA5MNbM3qj9rRxLpB18GXIfLnyfgNuAWXIDQH4ALahIwsw9xEbUTInjQjGB7kNJHgRMCzfVhRVtBkvPgPdEpvRe2TIGqtUA5VMzD1t8ImyYgtUD5v07J14zueigndj+CxZtWcPecyPeixJm8+Ee8+/0e/G/hwXy18hLymvRgWLcXyW+2VwpqW/t7weNJNxbM6kz1Vl9I6iDpI+B14GKcu/Ri4FVJH0nqEK9WIobvfFzG9L8En180s3HA3sBsILnZCI47JM0ItieiHO8AFAcDp+AWRXYLHZR0iaTvgrpdVot6bOshhXpSkYT2byxOzJOVabo1YZuC7OvNhtZa69guh3BB31NYVLqc678az8aK1NV1a9Va1mx6my9XnkPT3AL22uX2VMim817weFKD1f3kljRzF87DcqiZdTGzfc2sC26orA/O2xcXiRi+3sAMM6sEtgIFAMGiw38AYxPQiuRqMysMtjMTPdnM7jOzvsC1uDhwUZF0gaRpkqZtZXPUMkvmuCUn3fp3jXq82+67ArHH1GKRabo1UhV03JWcCzXEcV0P48LdT+WH0mVcP3M8xVvjziySEOUVyyjdMp/8Zv1pmtOutnIJ3wvxtD2PJ+VYGrb646fA78zso/CdwefrgGOjnhWFRAzfWlwSQHDrMPYLO9YOaJGAVo1ImhT0AB8OvrtAUmhMMtqiSHCTX06IpWlmD5rZEDMb0pTo0/tnvDcLgP2P2hfnYd1Oi/w89h4+gLLScr6dMi+h35NpujXStND9W7m42mLVcVL3Izmv78ks2LiY678aT8nW5BfZx0PzJp0AsNoHME74Xoin7Xk8qSbLenx5xB4qW0sCNigRwzcZCPm1ngRulnSbpJtwXcx3EtCqETMbGfQAzwvWeLwHnBwcHosLUoqkcLfSsUCtnvDLF6xk2qQZdOndieMu2TG7wFnjxtAiP493/v0h5ZsSe2vPNF0AcvuCorSl3G6ozU0AWNlLiesCY3qM4uzeJzBvwyJumPl3NlQkH1YtRIsmvchVfpQjok+7K2iW25Hi8s+pqFofpUxC1Om94PEkgwFVVUr5Vo98CvxW2tHNFHy+Boh7inkiyxluZvu42v/DuXfOxlnZt4AaZzlIego4DBfkdAlunATcGF+4i3KY2U4rka8FnpZ0K/AFbmIBwKWSjsS5nNZRO5crAPdc8jDjJ9/Kpfecy34jBrFo9lIGDOvHfiMGsnjOMiZc/1Sj0FWLY6DlObBlGlQtDWZ19oTmhyHlYeXvQ2niocVGdDqAM3uNptIq+Wb9fH7a9bCdyqwsX8u7qz5NSLdDy0Pp2+4qSjZPp2zrErZWFdMstyPt8obSomlPNlesYvaamJ7wRLiZWt4LHk/aMSC7ZnX+FtcB+l7Sq8BKoDNuiVwecHi8QnEbPjObA8wJ/t4MXB5scWNmp0fZHdeTM0hzsVPCMTNLqA7xsHzBSi4Zeh1jx41hyKhChh0zmKLl63hh/Ku1Cvqcabq2+VOU2wea7gk5g13vzzbAlulUlb0I5S8mpds5z02+ylUux3cbEbXMzOJ5CRu+dWUfs7xpT9o235/8VnvRJKc1VVbGpq0/sGLd31m8/nEqqkpqFqqBVNwLHk9dkGXr+D6XtB/OAP4YaI9zfT4P3BFKhRQPPnJLDFYvWcud5/6jcetu/QwrSd0C9RBPLXqNpxa9VnPBBCndOo+5a/+Ycl2PJ2PJIsMH2zpAF9dWJyHDJ+lU4EScmydatIr0pID2eBoY/l7wNHyE1e+YXIMlkcgtf8YNIE4F5gPRowF7PFmOvxc8GYFlZ+SWVJBIj+8c4Hoz+1O6KuPxZAj+XvBkBlnm6kwViRi+rbjg0B5PY8ffC57MwPf4opKI4RsPnCfprThzJ3lSyGtLP0+L7gnzfpIWXYDlj/RJi+6fZ0WbHJwK4k5QW6t7YXPPVsy79oBET6uRmaPHp1wToIWapUW3ovaBBGKSk6ZUoy2UYbHH/ZM6KoksZ/iLpDuB2ZI+AIp3LmLXprJyHk9DxN8Lnowgy9bxSaoxi7SZLYxHK5HJLWcCV+Cyj+az84C+4RaZezxZjb8XPJlClvnmFuCyoVRHXF39RFydfwaeAX5lZumJJNyA6NitPWNvGcPQkYW07tCaouXr+PilqbVaEJ4u3ZzW16Cmg1CT3pDTDqwcKpdSVf4WVaWPgxUnpdu6SSsO7LAPQ9oPpFerrrRv1pYKq2Rh6TLeWTmFt1dOwZLwpYwY0o/BA7rTv8cu9Ou5C/ktmvP6x99y44OvJ1XPED8esReDBu9G3/670qffrrTKb847r3/F7Te+UCvdKDSqe8GTwWTXcoafRtlXgEtZdwQuUHVcJGL42gATGsON3qVPZ8ZPvpV2nQuY/OJnLJ6zjD2G7s5Jlx/LkJGFXPGjG9hQlHhA5XTp5rT6JbZ1Frb5I6xqLaglalpIbusryGl5GhVrToaq5QnrDu+4Hxf3O421m0uYWTKXNZvXUdC0NQd23Jdf9z+Twe334vZvEw9Zdu5xB9C/ZydKy7awat0G8lukJmjzGeceQt/+u7KpdDNrVq2nVf4uNZ+UHI3mXvBkNsqiHp+ZxYp68WQQynIk7oW0RhIxfM/jYqFlfQDey+47j3adC7j3skd46d7tiX0vvGssJ185mnNuO53xFz3UYHQrVuxLtKVk1vo35OZfTE7+r6haf9POJ9bAsrJV/HHW/UwrmrVDz+6xH17mrsKrGd5xPw7qUMgna2ckpPvXJz9g1boNLF5ZzOAB3XngulMTrls07v/rG6xetZ5li4vYZ3Av7nzg7JToRqHR3AueDKb+0wjVJe8BL+CWGtVIIlOfJgFnSnpY0hmSjonckqltQ6NLn84MGVnI8u9X8fJ9k3Y49thNz1C2sZwjfn4IeS0T66WkS9cRff10VdmrAKhJryQ04auSuUwt+nond2bx1g28scKlxBpUkHjO1emzF7N4ZXFSdaqOL6f/wLLFsbKWpJRGcS94Mh25yS2p3hoYklrjDF7caVcS6fGFQvyfQ3SrakCGzfXdmcLD9wZg+ltfEjlTvWxjObMmz2bIyEL2PLAfX7z7db3rVkdO3hEA2NbZKdELp6LKTUWvtPRNSW/ANIp7wZMFVNV3BVKHpGiTW5oBu+A6cXFn5knE8PVOoGxUJE3ApZBYZWYDg30TcanjQ2HzN5nZwVHO7Y1LNNsBt3j4F+GpiyT9DHgOGGpm05KtY/c9XLaZWBnLl85fwZCRLuN5IgYqXbrh5LQ6z2VEV2vUbBA5zYZiW7+lqvSBpPRifg85HN7ZrUP7vOjblGpnCLW+FzyeOiG7XJ3/YWfDV4CzH6+Y2RPxCiWyji+u9RE1MBG4F3gsYv/VZvZcDefeDtxtZk9Luh84F/gnbOvqXo5LVFgrWrV1OQ5LSzZFPR7an1/QMurxutYNJ6fVeSh3+4SOqvIPqCy5GqpS6/4b2/t4erXqytSir/miuPEZvhTdCx5PesmydXyx1sZKEvCMpGvM7C/xaCWclkhSHtCV6BHpv6nuXDP7UFKvJL5TuCmrZwS7HsUlA/1n8PmPOMN4daLa2UTFqgPdHzkdUNP9yW1zNU06vkJF0flQMSsl3zG666Gc2P0IFm9awd1zIt9fGhe1uRc8nrpAWeTqjIWZmaSHgX8BqTV8kroDD+KmjO50mNqNa4RnYJ9lZmdGHO8AFJtZRfB5CUEGbEmDgR5m9qqkWhu+UM8r1EOLJLR/Y3H0nltd60alai22+U0qir6myS5v06TgTirW1D402bFdDuGCvqewqHQ5N8y8h40VKahrBpLme8Hj8STO/kDTeAsn0uN7HOgDXErqU7HE4+rcCUk5wF+Bs+MsfwFwAUAe0Q3QkjlLATfWFo1uu+8KxB6ri0W6dKulchlUzEdN9wa1A1uXtNRxXQ/jvL4n80PpMv4w8x5Ktia+3jCLSPheCG97ue0L0lk3j2cb2bSOT9K/ouxuBuwODCXO3h4kZviGAGea2csJnJM0kiYBnYFpwPlAgaQmQa+vO7AUaA0MBN533lB2BV6WdFy0CS5m9iDuTZ02ah+1Scx4z7kE9z9qXyTtMAOzRX4eew8fQFlpOd9OmZfQ70mXbo3kdA7+SH725Undj+Ts3iewYONi/jDzXjZUJB+5JktI+F4Ib3vNd+uRRY8jT4Mmi8b4gL2j7CvHhTK7y8yejVcokXV830CMblIaMLORZlZoZucFEfDfA04ODo8FXjKzEjPraGa9zKwXMAWIavTiZfmClUybNIMuvTtx3CU7erLOGjeGFvl5vPPvDynftLlB6JLbC5Qf5YDIaf0blNuRqi3TweJe4rIDY3qM4uzeJzBvwyJumPl3b/QcdXoveDxJYbjlDKne6gkzGxZlO8TMTk/E6EFiPb5fAw9IWmxmkxOrskPSU8BhQEdJS4BQOJHwMT6AYeFLFQKuBZ4OQtN8ASQeKytO7rnkYcZPvpVL7zmX/UYMYtHspQwY1o/9Rgxk8ZxlTLj+qZpF6kg3p/lh5LS5GtsyDSqXYFXrUE5H1GwYarIbVrmKypLfJ1XfEZ0O4Mxeo6m0Sr5ZP5+fdj1spzIry9fy7qrEJtMeOrgvhw3eHYAObVsBMGj3Ltx0nnshKN5QxvhnPky4vgcfOoCDDxsAQLsO7mVgz0Hd+e1NJwBQUryJh8a/mbBuFGp9L3g8dUE2uTpTSSKGbwbwGfChpC3ATnEKzaxTdQJmFi2RWlwGzMwWAMNqKHNYPFo1sXzBSi4Zeh1jx41hyKhChh0zmKLl63hh/Ku1CiadDt2qLR/DpmfJaTYEmu6F1AasDKv4nqoN46kqfRSspGahKHTO6wBArnI5vtuIqGVmFs9L2PD179mJ0T/a0WvRvVMB3TsVALBsTUlShq9v/105enThDvu6dm9P1+7tAVixrDhVhm8GtbwXPJ46IcsMn6R+uBn9RwDtgTW40IE3m9l38eokYvgeBk7BLRJP9eSWBsfqJWu589x/NHzdirlUrR+XFg/EU4te46lFseLCJs9DL37CQy9+knLdxx96n8cfej/lulFoVPeCJ4PJIsMnqT9uOGsmLi7nhbi14ScC0yX9yMziiv6RiOE7EbjSzO5PrLoeT9bh7wVPg0cGyq60RLcCn5jZsZL2A34F/CHY3sCt5T5WkiwyLmQEiUxuWQ0sSrLCHk824e8FT2ZgadjqjxHAhODvbRbdzCqBe4AfB7v+J2n36oQSMXy3AL+Vok4h9HgaE/5e8GQEstRv9UgL3JheNMK9lxOATyVdEksoEVfnsUA/YJGkaUBxxHEzszEJ6Hk8mYq/FzyZQT0YKkmjgPG46EUPm9mfI47fjctnCW5ZUCczK4hDeiluDXeEnHbHuUHfADCzCZK+xI0D3hdNKBHD1xE3kA8uNEza0lt7PA0cfy94Gj5W97E6JeXijM1RuNCSUyW9HB671syuDCv/a2C/OOXfAY4EQlkYDJgN9MJl7Pl12HdMl7R/LKFEsjMcXnMpz2tLP0+L7q+W/LjmQkmw/JE+adFNJ+v2bpMe4TjDHtT2XtirYCUfnDC+NhJRaaFmKdcEqEpTt6FJGsOZbrQEA0HEybdb0nON00bd9/iGAfOD5WdIeho4Hhf0IRqns309d038EReeDJzL8xFgMTDNzF6PLGxmsdyiiWdn8Hg8Hk9mUA9jct1wxijEEuCAaAUl7YbLbfluPMJmtgxYFvy9iCD2bTIkZPiCvHfHA/2JnorlmmQr4vFkEv5e8GQE6TF8HYOx7RAPBrFoE+U04LlgVmZcSGoB/BIXlHpXYAUwFZhgZuXx6iSSlqgv8DFuZk0r3JTu9oHGOlwG9ay52Tt2a8/YW8YwdGQhrTu0pmj5Oj5+aWqtIrfktL4GNR2EmvSGnHZg5VC5lKryt6gqfRysOGHNVrmtGNxuf/Yp2JduLbrTrlk7KqoqWFq2hI/WfMTkNf/Dkmz9I4b0Y/CA7vTvsQv9eu5CfovmvP7xt9z44E5ehazWjaSx3QueDCV9szDXmNmQGMeWAj3CPocSCkTjNCDmzMtIJA0E3sSlqZsOrAL2wOVpvV7S0WYWV+LRRHp8d+Ms6ylAKXAM8CUwBvhT8G9W0KVPZ8ZPvpV2nQuY/OJnLJ6zjD2G7s5Jlx/LkJGFXPGjG9hQlHhanpxWv8S2zsI2f4RVrQW1RE0LyW19BTktT6NizclQtTwhzSHth3FWr7EUb1nH7A2zmbZuLW2btGFwuyH8svc5DGo7iH9+F3ViU42ce9wB9O/ZidKyLaxat4H8Fs2T0sl03Sg0mnvBk+HUvatzKtBPUm+cwTuN7QnEtyFpANAOSCSE0/04YzckcHuGtLoAr+GynwyPRygRwzcMOA8IjRo3C7qoT0rqiJu+enACeg2Wy+47j3adC7j3skd46d43tu2/8K6xnHzlaM657XTGX/RQwroVK/YlWnQra/0bcvMvJif/V1Stj3ec17GyfAX3zP0bX5V8uUPP7vklz3PDXjcypP1Q9i8awvR1iSes+OuTH7Bq3QYWryxm8IDuPHDdqQlrZINuFBrNveDJcOrY8JlZhaRLgUm45QwTzGyWpFtwk1BCqbxOA56uKcJKBPsDp4cbveA7l0u6GXg6XqFEFrDnAevNrAooAsIzqn4N7JuAVoOlS5/ODBlZyPLvV/HyfZN2OPbYTc9QtrGcI35+CHktk+lNRA/pWFX2KgBq0ithxdkbvuXLkhk7uTPXV5Tw/ur3ANij9YCEdQGmz17M4pXFSZ2bTbpRaBT3giezEW45Q6q3mjCz18ysv5n1NbPbgn03huevNLObzey6BH/SD8ROB9YSl5cvLhIxfHOB3YK/vwB+JSlPUlPgXILZNtUhaYKkVZK+Dts3UdL3kmYE28cxzu0t6VNJ8yU9I7m525LOlrQ67PzzEvhNO1F4uMsaMP2tL4l8GSnbWM6sybNp0SqPPQ/sV5uv2YGcvCMAsK2zU6YJUBmMGVfGP3bsiY9a3wseT9pJQ9SWeo7cci1wi6Qd3JmSDsYtYI/bkCZi+J4GCoO//4Cboroel5JlDC5VRE1MBEZF2X91kHS20MxiuYhuB+42s91xEwjODTv2TNj5D8dRj5h036MbAEvnRn92LZ2/AoBu/btGPR4POa3OIyf/MnJaX09uh6fJbX0VtvVbqkofSFpzp+8gh4M7uEv5dcnMlOl6gNTcCx5P+smuWJ03AK1xsThXSPpK0grgIyAfuFHS1NBWnVAiC9j/Gvb3lGCGzSjczLZ340kHYWYfSuoV73eGkCRcgNLQIOmjuIfLPxPVqolWbV1PurRkU9Tjof35Bckn4M5pdR7K3R7so6r8AypLroaqoqQ1Izm5xyl0b9mDr4q/ZNb6uDJ1eOIkFfeCx1MnZFFaItwwQkrurUSWMxwSZfec4N8CSfsAc8ySCpkQnoF9lpmdGXG8A1BsZhXB5yW4hZIhfhbUby4uXcxiGjAVqw50f+R0QE33J7fN1TTp+AoVRedDRVyzcavliE5HMnLXn7CsbBkPL0hmeY2nOtJ8L3g8KaOuQ5alEzM7J1VaiczqfJ8d3x8U5XOZpIeBqxJZlIhzdT6XQPlwXgGeMrPNki7E9QajpguXdAHBav+8GGOkoR5dqOcXSWj/xuLoPcKEqFqLbX6TiqKvabLL2zQpuJOKNT+pleSITkdwxm4/Z2nZUu6c/RdKK5Nbc+iplvdJ8F4Ib3s9uqUvVJfHs436d002WBIxfEfiYqO9BryMW7S7Cy56xTHAb4A9gd8DG4Hra1MxSZOAzrgIiufj3qSbBL2+bYsizWxt2GkPA3+JpRlEF3gQoI3aR20SS+a4tZaxxvC67b4rEHsMMCkql0HFfNR0b1A7sHVJyRzZ+WhO73kGSzYt5s45f2FDxYbU1dETTsL3Qnjb22/fZv5x5KkT6nkySkqR9K+aipjZ2cEawhvN7JexCiZi+C4FHjWzmyP2TwrWUJxtZj+V1AQ4m1oaPjMbGf5Z0nvAybiJBWOBl4L9XcwstOr7OODb2nzvjPecq3H/o/ZF0g4zO1vk57H38AGUlZbz7ZR5tfmancnpHPyR3AzMn+x6DCf3OJVFpQu5a+4dbKxIfIG9J27q9F7weJIlm1ydwN41HA8lp21RU9lEZnUejZs9E43JbM+v9CHQJWqtpKdwK/X3kLREUmhm5h1hyxFmhJYqRHAtcJWk+bgxv0eC/ZdJmhXkX7oM96BJmuULVjJt0gy69O7EcZfsYHs5a9wYWuTn8c6/P6R8U4LDN7m9IGreUpHT+jcotyNVW6aDrU+4zqO7HMfJPU7lh9LvuXPOX7zRSz+1vhc8njohi2Z1mtmwGrahQblvzGxYdVqJ9PiKcD2qt6McOy44Dm4hYUmMip8eZfcjUfZFO3cBLmJG5P7fAb+LRyNe7rnkYcZPvpVL7zmX/UYMYtHspQwY1o/9Rgxk8ZxlTLj+qYQ1c5ofRk6bq7Et06ByCVa1DuV0RM2GoSa7YZWrqCz5fcK6B3cYzondT6LSKpm7YS5HdD5qpzJrN69h8tpYz+nYHDq4L4cNdllAOrRtBcCg3btw03nuhaB4Qxnjn/kw63WjUOt7weNJO36MLyaJGL6/APcEyxFeYedxjVASwMNx8doyluULVnLJ0OsYO24MQ0YVMuyYwRQtX8cL419NOkh11ZaPYdOz5DQbAk33QmoDVoZVfE/VhvFUlT4KlvgzsmNztywiV7kcvevIqGVmr5+dlOHr37MTo3+0o8ege6cCuncqAGDZmpKkDEmm6Uah0dwLnsxFbPf9ZQtBSMCrcGtnuwDLcffYndXl39tJJ5FQaZJOxPWu9sPFYavERa74k5n9N6xiW8yS8NnVIW3U3g7QESnXzbREtF/dt09adDORaY/+Zno1Ued3oDb3wn77NrMPXu9Mqsm0RLQ5aXwsZ1oi2uG9v4+77cVLy849rN/pV6VSEoCvxl+V8rrGg6R92T6jehIuYHVn3NCDgMPNbEY8Wgnl4wtu6P8G6eU74tJTVEaUidvqejyZir8XPBlBdrk678Jlcj/azLa53SS1whnCu4C4ejNJZWAPbvCVyZzr8WQT/l7wNGiyy/AdCJwRbvQAzKxU0u0kkJ0hKcPn8Xg8ngZO/QeVTjVbcLE6o9Ga7WnCasQbPo/H48lSsmwd36vAnyTNNbNtk8YkDcMlMXgtXqFGa/gqO7SiePRBKdf92fzUT1oAKL69Z1p0W1BRcyFPSslBaZmIkqtEluXGz+aq6Hkka8v8inQ+ldMzcaZlzta06KaN7OrxXQW8CXwq6QfcEENnoBfwVXA8Lhqt4fN4PJ5sJ5tcnWa2WtJQ4CTgx0B7XEjLj4Dnw5IY1Ig3fB6Px5ONZOEC9sC4PRtsSeMNXww6tcvnwhMP5qBBvWibn8eaklI++Pw7HnrxEzYkGq4MaN2kFQd22Ich7QfSq1VX2jdrS4VVsrB0Ge+snMLbK6dgSbbSQ4f3p3BgD3bv04nde3eiVcvmvPneLG6969Wk9Lyux5P5iKwb40sZ3vBFodsubXnkhtPo0LYV738+n4XLi9ir966cfvRgDhrUi/NufZqS0vKENId33I+L+53G2s0lzCyZy5rN6yho2poDO+7Lr/ufyeD2e3H7t3FFb9uJs8YcRL8+ndm0aQur126gVcvmSel4XY8ny8iyHl+q8IYvCteedQQd2rbijn+/y7Nvz9i2/4rTDuXMUftz0cnD+fOj7ySkuaxsFX+cdT/Timbt0LN77IeXuavwaoZ33I+DOhTyydoZsUVicO9D77F67QaWLFtH4aAe3POnaCFRE8frejyZjRKIzNWYSM80sAym2y5tOWhQL5auLuE/78zY4diDL37MpvItHHPwXuQ1S+yd4auSuUwt+nond2bx1g28scLF0RxU0C+pOn8xcxFLliWXw8/rejxZijlXZ6q3bKBODZ+kCZJWSfo6bN9ESd+HpST6OMa5vSV9Kmm+pGfCUxdJOlXSN0F6oidrU8che/YA4NOvFxL5srSpfCtfzltGi+ZNGdQ3ddlmKqpcpKvKhJLWezweTw1kUVqiVFLXPb6JwKgo+682s8JgOzjGubcDd5vZ7sA64FwASf1wwYKHm9newBW1qeBuXdoDsGhl9J7D4pXFAPTctV1tvmYbOeRweOcDAPi8qFY5dD0ej2cHZKnf6vX3SC0lHSbpQkm/k3SlpNMl9U9Ep07H+MzswyCVS0JIEjACOCPY9ShwM/BP4HzgPjNbF3zHqtrUMb+F60hujDFzc2OZ2986RRMnxvY+nl6tujK16Gu+KPaGz+PxpJAs6KEFz//jcZ2dkbhsKAasB5oDeUGxJcDjwP1mtrg6zYYyxheegf2JKMc7AMVhCxSXAN2Cv/sD/SVNljRFUrQeZYNkdNdDObH7ESzetIK75zxW39XxeDzZRBaM8QXhyGYADwErgNOAPmbWxMzam1krIB+Xn+8u4BBgjqR7qtNtKLM6rzaz55I8twnQDzgM6A58KGmQmRVHFpR0AXABQLNW0V2VG8tceKb8GD26/BZufzJr+cI5tsshXND3FBaVLueGmfewsWJTrfQ8DZvwttezW0O57TzZjKh/12QK2AMYDzxuZlHjxZlZGS4Z7VRgfDD8dV11og32DpQ0CReHbRrOnVkgqUnQ6+sOLA2KLgE+DS7K95Lm4gzhTpmvzexB4EGAVh17RG0SC5cXAdCzc3TD2KNzAQCLViQ/e/C4rodxXt+T+aF0GX+YeQ8lWzcmreXJDMLb3v77Ns/8x5EnM8jw5Qxm9ngS58wjmAMSi4bi6twJMxsZTHY5z1ya+PeAk4PDY4GXgr9fxPX2Qhmv+wMLkv3ead861/ABA3dDEXFuW+Y1Zd9+XSnbvJWZ3y1PSv+k7kdyXt+TWbBxMdd/Nd4bPY/HkzaybXJLLIJZ//+Kt3yd9vgkPYUzUh2DgcibgkN3SLohrOgwM4sMCX8t8LSkW4EvgFCYk0nA0ZK+ASpxbtO1ydZx6eoSPpn5AwcN6sUpRxTusID9ghMOpmVeM55/70vKtySe1WBMj1Gc2Ws08zYs4qav7/XuTY/Hkz4MlEUrpCR1AC4GBgCR6U3aA4dLyg8+P2tm/4mlVdezOqOF0ogrTpeZLQCGRdlvuHQUcaekqInbH3uHR244jat/PoKhe/Xkh2VF7N1nV4bu1ZOFy4v453OTE9Yc0ekAzuw1mkqr5Jv18/lp18N2KrOyfC3vrvo0Ye0fHbg7Pz7QLX5v364VAHsP6MrvrvgJACXry/jHhPe9bpK6Hk/G0kB7aEnyIHA0MBOIjBnZBvdrOwSfW1Yn1GDH+OqTpatLGDvuiW1Bqofv05s1xaU89ebnSQep7pzn/j9ylcvx3UZELTOzeF5Shq9fn8785MhBO+zr1qUd3bq4ccrlK0uSeuB7XY8ns2morskkORT4uZm9FHkgSFf0qZlFf7hGlrcMH/xMllYde9heo69MuW6Xc5MeXqyWdCWi9Wznf69eO93MhqT7e/bft7lNeaN7ynXTlYh2U0Ymos0s9tttScrbXn67HlY44vJUSgIw+YWr6+Q+iURSJW4YbHqUY8OAT8wsNx4t3+PzeDyebCW7+jXjgGUxji0JjseFN3wej8eThWTJOr5tmNktsC2Syx64CS1rzGyumS0DbolXq8EuZ/B4PB5PLTBLz1aPSDoVWAR8A3wEzJb0Q7A/brzh83g8niylPkKWSRolaU6QSSdqBJVkMupIGomLxTkROA/nyP0J8DbwpKTj47sqjdjVmbu2lILHPkm57nIOSrkmAB3TI+vJHiotPZNFmis9j4m9m6ZF1hNGXbs6JeUC9wFH4cbdpkp62cy+CSsTnlFnnaROccr/HnjAzP4gaTDOm/u2mU2SVAbcwPbAJtXie3wej8eTjRhQZanfqmcYMN/MFgRBSJ7GZVYIJ9mMOoOB12McewkYGKeON3wej8eTtcSTWDbRzUXemha2XRD2jd2A8JRA4Zl0QiSbUacSiLW2pi9QHKdO43V11kTHbu0Ze8sYho4spHWH1hQtX8fHL03l8XH/YWNxadK6ndrlb1sY3zY/jzUlpXzw+XdJL4zPRN0RQ/oxeEB3+vfYhX49dyG/RXNe//hbbnww1stc/dfZ48lEVHMPLRnW1HIdX9wZdSJYgDNw74Tt6yHpcODPBEHg462AJ4IufTozfvKttOtcwOQXP2PxnGXsMXR3Trr8WIaMLOSKH93AhqLEg0t326Utj9xwGh3atuL9z+ezcHkRe/XeldOPHsxBg3px3q1PU1IaGYkn+3TPPe4A+vfsRGnZFlat27At1VMqSFedPZ5MpB6WMywFeoR9Ds+kEyLujDoRvIJzm4YMnOGMYRluXPH38VbSG74oXHbfebTrXMC9lz3CS/e+sW3/hXeN5eQrR3PObacz/qKHEta99qwj6NC2FXf8+90dgl9fcdqhnDlqfy46eTh/fvSd2AJZovvXJz9g1boNLF5ZzOAB3XnguoRmItdLnT2ejGO7a7IumQr0k9QbZ/BOA86IKPMicDrwrwQz6oxje3Dq74Ff4NyqX4fGC+PFj/FF0KVPZ4aMLGT596t4+b5JOxx77KZnKNtYzhE/P4S8GIlqY9Ftl7YcNKgXS1eX8J93Zuxw7MEXP2ZT+RaOOXgv8pol9i6SaboA02cvZvHK4oTPq4l01tnjyTQEqNJSvlVHkC/1UlzWnG9xWRJmSbpF0nFBsUnA2iCjznvEn1GnCYHhM7N1Zvakmf0vUaMHdWz4JE2QtErS12H7Jkr6XtKMYPs4xrm9JX0arA15RlKzYP/dYefOlVRcmzoWHr43ANPf+pLIOKZlG8uZNXk2LVrlsWeQBSBehuzpev+ffr1wpzWgm8q38uW8ZbRo3pRBfbtktW46ycQ6ezzpRGYp32rCzF4zs/5m1tfMbgv23WhmLwd/m5ldZWZ7mdkgM3s6zp/zd5zRdL9N6iLpf5I2SHpXUuQkmpjUdY9vIhBtBs/VQdLZQjM7OMa5twN3m9nuwDqCDLtmdmXoXNyFeaE2Fey+h7t2S+dGDwm3dP4KALr175qQ7m5d2gOwaGX0l5NQD6jnrtEzv2eLbjrJxDp7PGkjHTM66zdwyyHAY2GfbwMKcO7U5sDd8QrVqeEzsw+BokTPC2KzjQCeC3Y9CpwQpejpwFPJ1g+gVVuXxqm0JHqS2ND+/IJq0z3tRH4L55reGGNW4cYyt791gi7UTNNNJ5lYZ48nfWRdyLIewNywz8cDd5rZq7hZnYfGK9RQBjvCM7DPMrMzI453AIoD/zFEWRsiaTegN/BuWmvq8Xg8GUKaljPUF5uAPNiWhqgd25/3JUDreIUaiuG72syeq7lYtZwGPGdmlbEKBAstLwDIi5GgN9SjC/X8Ignt31gcvUcYi41lbt1lfozeRmhKf6LrzDJNN5005DqHt72e3RrKbefJaiy+2JoZxBTgKklrgZuAL80stFi+D7FTFu1Eg53VKWlSMGHlYWAtUCBtCxoYbW3IadTg5jSzB81siJkNaUr0h+OSOU421hhet913BWKPAcZi4XLn4e3ZOfr4Uo/OBQAsWpHYBKVM000nDbnO4W2vY4cGe9t5so3scnX+DhgATAZ+BPwm7NgA4Il4hRrsq6eZjQz/LOk94GRc7LexhAUjlTQA1+2tddTpGe/NAmD/o/ZF0g4zO1vk57H38AGUlZbz7ZR5CelO+9a9mBwwcDekHdtPy7ym7NuvK2WbtzLzu+VZrZtOMrHOHk9aySJPZ7Asog+wJ7AwfBmDmUXNAhGLul7O8BTOOO0haYmkc4NDd4QtSZgRWqoQwbW4bu583JjfI2HHTgOetsj1B0mwfMFKpk2aQZfenTjukh1sL2eNG0OL/Dze+feHlCfoLlu6uoRPZv5At13acsoRhTscu+CEg2mZ14zXPv6G8i0V0QWyRDedZGKdPZ50oqqqlG/1iZltNrMZkWv3JPWR9K94dZQCW5GRtFF7O0BHRD0WGbJs0eylDBjWj/1GDGTxnGVcPvz6mCHLis+KnZYoMpzWD8uK2LvPrgzdqycLlxdxbopCizV03UMH9+WwwbsD0KFtKw4a1Islq4qZMde5mYs3lDH+mQ8T1q1tnac9+pvptYxBGBf779vcprzRPd1f48kgmnVdkPK216ZVNztw7wtTKQnAW1NvqpP7JBJJHYCLcW7NyM5Re+Bw4Png87Nm9p+YWt7wRWeX7h0YO24MQ0YV0iYIUj35xc9qDFJdneED6Nw+PIByC9YUl/L+5/NrHUA5k3TPP+EgLjgh9nVatqaE43/7SMzjNZFsnb3h89QX6TB8bVt1tQP3Sr3he3PazfVl+J4HjgZmApFvr22A/YAPgs+PmtmjMbW84UstNRk+T8PFGz5PfZE2w7fnBTUXTJA3p4+rL8O3BjjXzHZKNitpKC7wdVzDdw12covH4/F4aoEBNcTWzDDa4dZwR0MkMJXHGz6Px+PJUuKJrZlBjCP2Wr0lwfG48IbP4/F4spUsMnxmdgtsC2G5B25Cyxozm2tmy4Bb4tXyK2k9Ho8nGzGDqqrUb/WIpFOBRcA3wEfAbEk/BPvjptH2+Dawbs3b9tzCOIt3BNbEVfLRhCKvxa+bGF43Oe3d0lSHHfj8qy1rmnVdkPq2lxheN/3a9d/2sihkmaSRwOPAX3CJaB8CjgFOAZ6UtDnaxJdoNFrDZ2a7xFtW0rR0zGLyuunVTbd2svi213B006ndENpelo3x/R54wMz+IGkwbkLL22Y2SVIZcANhEb2qw7s6PR6PJ1vJrlidg4HXYxx7CRgYr1Cj7fF5PB5PVmMGlVnk64RKYEuMY32B4niFfI8vPh70uhmpm27tuiDTrnmm6aZTu/7bXnb1+BbgDFw4PST9EpeI9rGdT4lOo43c4vF4PNlM27xd7eDuv0i57hvf3VlfkVvGAUPM7NhgjG8qbpyvDLgP+F11+VjD8a5Oj8fjyUYMyK4M7OPYHpz6e+AXwGLg68hsDTXhDZ/H4/FkJQZVcXWAMgIzqyIITh0YuieT1fJjfB6Px5ONhHp8qd7qEEmjJA1L8Jx8Sb+prow3fDUQhMfJGDKtvgCSvOchCpn2f5lp9YVG0PYyf3JLE+B1SR9LulLSgGjtTFLbwEg+hIvs8pOaRD1RkNQXWBt8LK7HqsSFpN2AdbiXmeIU6vYP9HLNbHmqdAPtg4FvzKxYUm68A9Nx6B4KVJjZ5FTo1TW+7e2gnZb21zjantV7iLHaYmb/J6k3cAkuCe2dQKmkRbh20RwXIacnbqnD/wEnmFm1may94YuCpJ8CtwJzgCJJr8cbCqcG3ROAQ8zsqtpqRegeC1wPrAS+k/QvM5uVAt2f4K7Dl0C5pD+b2aLa6gbaXXGLToskHZCqB1AQ1ujvwNiwfbIMmb7s294O2mlpf42m7RkZb/gAzGw98CfgT5IKgeFAf1yQ6nJgBfAZ8D8zK45H0xu+CCR1xN1slwPfAUOBmyXlm9kTtdDdDzflNi+4F6r1QSegexhwF3AakIuLWzcImFWbmy7Q/RPwK1y8wT/gFpCmitW4dTf7AV9KGmpmq2ojGLzF/xO4xMw+kdQaN9W5BbChthVON77t7aSdrvbXeNpeZrzvxY2ZzQBm1FbHj/HtzAZgCm6K7GIzewG4BviNpNGJioX5owuAc4FuwI8k3ROjXKK6+wD3mdkMM5uOm+Z7SqL1jKI7APitmU0B1gOHAX+W9P8kjUpWP/iOXDPbinPnnQU8CkyWdHzQg0i2zoXALGCepAHABNwDbnxt61xHNOq2F6GdlvbX6Npe5o/xpQVv+AIkNQUws824tSL/Ch0zs7dwEcGPlNRSUiLXrUmg8R4wxczKgaOBAyT9Paxc3IGLA0L1vQd4OqxOnxPEZDczk9Q2Sd37zextSfk4v/rdwO3At8AFkjon8cAMaYfe3FcAZ5vZjcBM4L8E10FSbhJ1/gfwNq7X9CLwblDvD4FfStol0TrXBb7tRdVOaftrlG3PDKusTPmWDXhXJyDpaGCUpFXAU2b2S0nPS3rUzEL++qnAz2DbepJEdFcCr+JySGFmJcFb4BuSbgHmA0dJusDMyhKs7yvAt2F1WofzfSPpF8AASbcED9VE6vsaMMvMNkq6ITS2Imk9LhVIeSKurDDt5cCbuIfNZ8AZkgYCe+MeGHdKesXM1sYUi667GnjWzMZLKgU+MLN/BmVW42Z5JVTnusC3vZh1Tln7a9RtL7sWsKeMRm/4JB0APIWbMXQM8FtJs3FjCw9IehW4CDgEN3OoJbApCd3OwDJJd5tZZbAA8wBJ64DNwFFxPngidTuF6wbF1ku6MCgzJk6jF6m7K7Bc0l1mtkhSTvCAG4pzmTWtSbMa7a7AD7gxkb2BaUE9X5L0J6Ad22c1JqJ7uaS5OPebhdV5f6ALbgZYgxnr822vWu2UtL9G3/Ya1nteg6HRx+qU8+sPN7Pfyw1IHwqMwo2z3C/pfmArMAw438y+SlL3EGAksBC428yqJB0EPAuMincmXE26QCtgXvD5bDP7NkW6AFcDpwJjzezreHSr0T4G19v4BlhrZtPi1atB9ye4YLZ/C67x5bixnITqXBf4tpeQNiTR/hpz22ub29EOyj8u5bqT1v+rXmJ1phI/xudmjI2RtL+ZbcD56d8ABkrqbGa/Ai4DRsT74Imh+w7OzdKd7RHGm+GmmCcy/bs63d7Bvo+ACxJ58NSg2yd4e21NcjdxNO03cG/CC81smqQcKeExkFi6PYA+QZkC4KyGZvQCfNuLT7s27a9Rtz0/xhedRm34JMnMPgXGAxdJ2tvcBID3ce6h08AN1JtZaYp0uxNEFTCzD8zs+xTqHhfonmxmX6ZQ99hA94ZEb+IatHsDRwXaVYmMgSRQ53EJPtzrBN/2EtJOqv35tpeGGZ1Z4iFsVIYvyltd6PdPwvn9fyNpmJltBD4BOiiOWXRJ6HZUHDPHktBtJym3prfXJK9DjboJam8ItHdJ0zWOu851gW97tdKO6//St70IjIyP1ZkuGuUYn6S9gO8tGNCX1Axoi3vL/i0u7M0pwGFm9o3XTUw3U+tcF2TadfFtJP266aJtTgc7sFnqlxC+ufnJjB/ja3SGT9KpwAnAHWb2haR7gUozuzw4XogbS1hsZj943cR0M7XOdUGmXRffRtKvm07aqL0d2OTolOu+VfGMN3yZgrZPL0bSr4HdcGMpbYHjzcwC331CF8TrZnad64JMuy6+jaRfty5oo/Z2QM5RKdd9u+pZb/gaOpL2tGCGmaQmZlYR/P0ObvbVL8zsI6+bnG6m1rkuyLTr4ttI+nXrEklv4DIXpJo1ZpYJIQBjktWGTy5a+n24tVHfhd7KJN2Fi+79IW4R7qvAZHMx/LxunLqZWue6INOui28j6df1NByydlanXEqTP+IW/s7H+d+R1B0oNbOfmtkduGgKx+Kiy3vdOHUztc51QaZdF99G0q/raWCYWdZtuDBB3wGnBp974haX7gvkRCnf3uvGr5updfZtz7eRbG57fot/y9YeX3tcipBiSUOAJ4D/M7MvLSzIr7ZHbC/yugnpZmqd64JMuy6+jaRf19PQqG/Lm8oN6B/294nAk7g0JjdElDvQ6yaum6l19m3Pt5Fsbnt+S3yr9wqk7IfAaFzk+mfC9h0JPAeMAToH+87AJczs6nXj183UOvu259tINrc9vyW3ZcWsTkmtgOeBF4CDgWZmdkZw7ETgJOBlXEqSMcB5FkdkBa+b2XWuCzLtuvg2UjfXwtPAqW/Lm6oN1zjzcetWngOeDDt2DG7q8VfA3l43cd1MrbNve76NZHPb81tyW1b0+CKR1AF4ENhiZqdL6g0cAbxhZku8bu10M7XOdUGmXRffRtKv62l4ZKXhA5DUEbgDGB7sOtTMlnvd1OimUzudda4LMu26+DaSfl1PwyJblzNgZmtwLoo2wM9S1Xi9bvq101nnuiDTrotvI+nX9TQsstbwSWqH89EfbWYzvW5qddOpnc461wWZdl18G0m/rqdhkbWuTgBJeeYyI3vdNOimUzudda4LMu26+DaSfl1PwyGrDZ/H4/F4PJFkravT4/F4PJ5oeMPn8Xg8nkaFN3wej8fjaVR4w9eIkfQzSe9KKpa0WdJcSX+V1LW+6+bJbnzb89QnfnJLI0Uum/QVwL+Al4D1wF7Ar4AFZnZi/dXOk834tuepb7zha4RI+iku+O65ZjYh4lgubg3T6/VSOU9W49uepyHgDV8jRNK7QFsz27++6+JpXPi252kI+DG+RkaQPfpg4I36rounceHbnqeh4A1f46MD0BxYVN8V8TQ6fNvzNAi84Wu8eB+3p77wbc9Tr3jD1/hYC2wGetZ3RTyNDt/2PA0Cb/gaGWa2FZgMjKzvungaF77teRoK3vA1Tv4GDJE0NvKApBxJo+q+Sp5Gwt/wbc9Tz/jlDI2UYBHx5cAE3CLijcAA3CLiH/wiYk+68G3PU994w9eIkfQz4FJgMNAC+AG3uPhOM1tRj1XzZDm+7XnqE2/4PB6Px9Oo8GN8Ho/H42lUeMPn8Xg8nkaFN3wej8fjaVR4w+fxeDyeRoU3fB6Px+NpVHjD5/F4PJ5GhTd8Ho/H42lUeMPn8Xg8nkaFN3wej8fjaVT8fyhkuTb9NPsYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_heatmap(ax, gs, is_sh=False, make_cbar=False):\n",
    "    results = pd.DataFrame.from_dict(gs.cv_results_)\n",
    "    results['params_str'] = results.params.apply(str)\n",
    "    if is_sh:\n",
    "        # SH dataframe: get mean_test_score values for the highest iter\n",
    "        scores_matrix = results.sort_values('iter').pivot_table(\n",
    "                index='param_gamma', columns='param_C',\n",
    "                values='mean_test_score', aggfunc='last'\n",
    "        )\n",
    "    else:\n",
    "        scores_matrix = results.pivot(index='param_gamma', columns='param_C',\n",
    "                                      values='mean_test_score')\n",
    "\n",
    "    im = ax.imshow(scores_matrix)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(Cs)))\n",
    "    ax.set_xticklabels(['{:.0E}'.format(x) for x in Cs])\n",
    "    ax.set_xlabel('C', fontsize=15)\n",
    "\n",
    "    ax.set_yticks(np.arange(len(gammas)))\n",
    "    ax.set_yticklabels(['{:.0E}'.format(x) for x in gammas])\n",
    "    ax.set_ylabel('gamma', fontsize=15)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    if is_sh:\n",
    "        iterations = results.pivot_table(index='param_gamma',\n",
    "                                         columns='param_C', values='iter',\n",
    "                                         aggfunc='max').values\n",
    "        for i in range(len(gammas)):\n",
    "            for j in range(len(Cs)):\n",
    "                ax.text(j, i, iterations[i, j],\n",
    "                        ha=\"center\", va=\"center\", color=\"w\", fontsize=20)\n",
    "\n",
    "    if make_cbar:\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "        fig.colorbar(im, cax=cbar_ax)\n",
    "        cbar_ax.set_ylabel('resultado médio (teste)', rotation=-90, va=\"bottom\",\n",
    "                           fontsize=15)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, sharey=True)\n",
    "ax1, ax2 = axes\n",
    "\n",
    "make_heatmap(ax1, gsh, is_sh=True)\n",
    "make_heatmap(ax2, gs, make_cbar=True)\n",
    "\n",
    "ax1.set_title('Divisões Sucessivas\\ntempo = {:.3f}s'.format(gsh_time),\n",
    "              fontsize=15)\n",
    "ax2.set_title('Grid search\\ntempo = {:.3f}s'.format(gs_time), fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
