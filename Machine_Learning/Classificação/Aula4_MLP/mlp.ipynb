{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Redes Neurais Multilayer Perceptron (MLP) com PyTorch\n",
    "\n",
    "Redes Neurais podem apresentar um número massivo de parâmetros com dezenas de camadas a serem aprendidas (nesse caso, chamamos de ''deep learning''). Pora ajudar a construir essas redes, o PyTorch possui o módulo `nn`, que contêm diversas ferramentas para construir redes neurais de forma eficiente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importando os pacotes necessários\n",
    "\n",
    "# comandos para plotar imagens mais bem definidas no notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Algumas funções auxiliares\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como exemplo, vamos mais uma vez utilizar o já conhecido dataset MNIST, formado por imagens de digitos em tons de cinza de dimensão $28\\times28$, apresentados na imagem abaixo.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Mais uma vez, vamos usar o pacote `torchvision` para carregar o dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transformação dos dados. \n",
    "# Note que nesse caso joga um valor médio de 0.5 e desvio de 0.5, normalizando os valores entre -1 e 1.\n",
    "# (https://discuss.pytorch.org/t/understanding-transform-normalize/21730)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90d0b43d0bb446049ac7ecddcd40c0e8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "438f363bc3e3455a9eb4290dda9c7d3b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7138955450bd47f082548e62910bf899"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "051132bbd2934dea8be5ee66dcefb318"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/laryssastephanie/.pytorch/MNIST_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/laryssastephanie/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criamos o data loader de treinamento `trainloader` e criamos um _iterator_ `iter(trainloader)`, que será chamadado da seguinte forma:\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "Note que usamos batches de tamanho $64$. Aqui vamos consultar o primeiro batch para verificar os dados. Observe que `images` aqui é um vetor com tamanho `(64, 1, 28, 28)`, ou seja, 64 imagens por batch, $1$ cor por canal (se fossem imagens coloridas seriam 3 canais), e imagens de 28x28 pixels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "plotando uma das imagens"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAc60lEQVR4nO3df7BudV0v8PcnKLiHFM9lSqa8DeIvmEy5HEqFEUEmLqYBJlwdp2IasR+XroF6yzHponnLaSwlUGxykgZHqEE9TkrqTX7/0OqQoZOKhAd0ghAQFA6Q6Pf+8axT5x73Ppz9PM/Za+/v83rNPLP2s9b6PN8Py+V57/Xs9aNaawEA+vF9YzcAAMyXcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzuw9dgN7QlV9Jcnjk2wduRUAmNZBSb7ZWnvySgu7DPdMgv0/Dy8AWCi9fi2/dewGAGAOtk5TNGq4V9WTqurPqupfquqRqtpaVe+sqo1j9gUA69loX8tX1VOSXJ/kh5N8JMkXk/xUkt9IckJVHdVau2es/gBgvRrzyP3dmQT7a1prJ7fW3tBae2GSdyR5RpL/M2JvALBuVWtt9QedHLXfksnfEp7SWvvuDssel+SOJJXkh1trD07x+VuSHD6fbgFgNDe21jattGisr+WPHaaf3DHYk6S19q2qui7J8Umem+RTy33IEOJLOWQuXQLAOjTW1/LPGKY3L7P8y8P06avQCwB0Zawj9/2H6f3LLN8+/wm7+pDlvqrwtTwAi6zX69wBYGGNFe7bj8z3X2b59vn37flWAKAvY4X7l4bpcn9Tf9owXe5v8gDAMsYK9yuG6fFV9f/1MFwKd1SSbUk+vdqNAcB6N0q4t9b+OcknM3nizRk7LX5zkv2SXDTNNe4AsOjGfCrc/8jk9rN/XFXHJflCkudkcg38zUl+e8TeAGDdGu1s+eHo/YgkF2YS6q9L8pQk5yZ5rvvKA8B0Rn2ee2vtq0l+acweAKA3rnMHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM7sPXYDwHgOO+ywqWv33nu2fz5++Zd/eab6Qw89dOrao446aqaxx3TnnXdOXfusZz1rprHvvvvumepZPY7cAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAzwh0AOiPcAaAznucOI9u4cePUtZs3b55p7COPPHLq2r322mumsWf1yCOPTF17/fXXz7GTlXnmM585U/2BBx44de0ZZ5wx09hvfvObZ6pn9Yx25F5VW6uqLfO6c6y+AGC9G/vI/f4k71xi/gOr3AcAdGPscL+vtXbOyD0AQFecUAcAnRn7yH2fqvr5JD+W5MEkNyW5urX2nXHbAoD1a+xwPzDJRTvN+0pV/VJr7arHKq6qLcssOmTmzgBgnRrza/n3JTkuk4DfL8lPJPmTJAcl+euqevZ4rQHA+jXakXtrbecLJj+f5Fer6oEkr0tyTpKXPsZnbFpq/nBEf/gc2gSAdWctnlD3nmF69KhdAMA6tRbD/evDdL9RuwCAdWothvtzh+mto3YBAOvUKOFeVYdW1fccmVfVQUnOH96+f1WbAoBOjHVC3cuTvK6qrk5yW5JvJXlKkhcn2TfJZUnePlJvALCujRXuVyR5RpL/muSoTP6+fl+SazO57v2i1lobqTcAWNdGCffhBjWPeZMaWC2zPHb1ta997Uxjz1I/6+/An/vc56auveGGG2Ya+x/+4R9mqv/whz88de0999wz09izuO6662aqf97znjenTujZWjyhDgCYgXAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDozCjPc4d5+73f+72Z6s8444w5dbJyp59++tS1F1988Rw7YXf9wA/8wNS1BxxwwBw7WZmvfvWro43N6nLkDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0JlqrY3dw9xV1ZYkh4/dB6vngQcemKn+2muvnbr21a9+9Uxjewzn+nPZZZdNXXvCCSfMNPYdd9wxde2P/uiPzjQ2o7ixtbZppUWO3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM3uP3QDMww/+4A+O3QLryMaNG2eqP/bYY+fUycp99KMfHW1s1g9H7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ3xyFdgXZrlsa3XXHPNTGPvs88+U9e++93vnmnsN7zhDTPVsxgcuQNAZ+YS7lV1SlWdV1XXVNU3q6pV1fsfo+bIqrqsqu6tqoeq6qaqOrOq9ppHTwCwqOb1tfybkjw7yQNJvpbkkF2tXFUnJflgkoeT/EWSe5P8bJJ3JDkqyalz6gsAFs68vpY/K8nTkzw+ya/tasWqenySP03ynSTHtNZe1Vr7X0kOS3JDklOq6hVz6gsAFs5cwr21dkVr7cuttbYbq5+S5IeSXNJa+/sdPuPhTL4BSB7jFwQAYHljnFD3wmH68SWWXZ1kW5Ijq2r601EBYIGNcSncM4bpzTsvaK09WlVfSfLjSQ5O8oVdfVBVbVlm0S7/5g8APRvjyH3/YXr/Msu3z3/Cnm8FAPqzrm9i01rbtNT84Yj+8FVuBwDWhDGO3Lcfme+/zPLt8+/b860AQH/GCPcvDdOn77ygqvZO8uQkjya5dTWbAoBejBHulw/TE5ZYdnSSDUmub609snotAUA/xgj3S5PcneQVVXXE9plVtW+Stw5vLxihLwDowlxOqKuqk5OcPLw9cJg+r6ouHH6+u7X2+iRprX2zql6dSchfWVWXZHL72RMzuUzu0kxuSQsATGFeZ8sfluS0neYdPLyS5LYkr9++oLW2uapekOS3k7wsyb5Jbkny2iR/vJt3ugMAllA95qhL4WDt27Bhw0z1H/jAB6auPfHEE2ca+6GHHpq69uijj55p7C1blrt3F526cbnLvnfF89wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6M6/nuQOsyLnnnjtT/UknnTR17YMPPjjT2C95yUumrvXIVlaDI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IznuQNTeeUrXzlT/ctf/vKZ6h966KGpa08++eSZxr7yyitnqoc9zZE7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZzzyFRbYG9/4xqlr3/rWt8409sMPPzxT/W/+5m9OXfs3f/M3M40Na50jdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojOe5w8g2btw4de3mzZtnGvvII4+cunbbtm0zjf2Wt7xlpvrzzz9/pnromSN3AOjMXMK9qk6pqvOq6pqq+mZVtap6/zLrHjQsX+51yTx6AoBFNa+v5d+U5NlJHkjytSSH7EbNPybZvMT8z8+pJwBYSPMK97MyCfVbkrwgyRW7UfPZ1to5cxofABjMJdxba/8e5lU1j48EAKY05tnyP1JVv5LkgCT3JLmhtXbTSj6gqrYss2h3/iwAAF0aM9x/enj9u6q6MslprbXbR+kIADowRrhvS/K7mZxMd+sw71lJzklybJJPVdVhrbUHH+uDWmublpo/HNEfPo9mAWC9WfXr3Ftrd7XWfqe1dmNr7b7hdXWS45N8JslTk5y+2n0BQC/WzE1sWmuPJnnv8PboMXsBgPVszYT74OvDdL9RuwCAdWythftzh+mtu1wLAFjWqod7VR1eVd8zblUdl8nNcJJkyVvXAgCPbS5ny1fVyUlOHt4eOEyfV1UXDj/f3Vp7/fDzHyV5WlVdn8ld7ZLJ2fIvHH4+u7V2/Tz6AoBFNK9L4Q5LctpO8w4eXklyW5Lt4X5Rkpcm+ckkL0ry/Un+NclfJjm/tXbNnHoCgIVUrbWxe5g717mzmjZs2DBT/Qc+8IGpa0888cSZxv72t789de2ZZ54509gXXHDBTPWwIG5c7p4uu7LWTqgDAGYk3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM/N6njusa0ccccTUtX/+538+09iHHnro1LXbtm2baeyXvOQlU9deeeWVM43NYnnxi188U/2NN944de0dd9wx09jrkSN3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiM57nThQ0bNsxU/6EPfWjq2ic96Ukzjf2Nb3xj6tpNmzbNNPbWrVtnqmd9Oe+882aqP+WUU6auveqqq2Ya+7rrrpupftE4cgeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMR76yZmzcuHHq2s985jMzjT3LY1v/7u/+bqaxn/Oc58xUz8rNsq8lyWGHHTZ17aWXXjrT2LP0ftddd8009llnnTV17cUXXzzT2KyMI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IznubNmnH322VPXPvWpT51p7E9/+tNT1x5//PEzjb2oXvnKV85Uf/DBB09de8YZZ8w09hOf+MSpa7dt2zbT2O9617umrn37298+09i33XbbTPWsnpmP3KvqgKo6vao+XFW3VNVDVXV/VV1bVa+qqiXHqKojq+qyqrp3qLmpqs6sqr1m7QkAFtk8jtxPTXJBkjuSXJHk9iRPTPJzSd6b5EVVdWprrW0vqKqTknwwycNJ/iLJvUl+Nsk7khw1fCYAMIV5hPvNSU5M8rHW2ne3z6yqNyb52yQvyyToPzjMf3ySP03ynSTHtNb+fph/dpLLk5xSVa9orV0yh94AYOHM/LV8a+3y1tpf7Rjsw/w7k7xneHvMDotOSfJDSS7ZHuzD+g8nedPw9tdm7QsAFtWePlv+28P00R3mvXCYfnyJ9a9Osi3JkVW1z55sDAB6tcfOlq+qvZP84vB2xyB/xjC9eeea1tqjVfWVJD+e5OAkX3iMMbYss+iQlXULAP3Yk0fub0vyzCSXtdY+scP8/Yfp/cvUbZ//hD3UFwB0bY8cuVfVa5K8LskXk/zCnhgjSVprm5YZf0uSw/fUuACwls39yL2qfj3JuUn+KcmxrbV7d1pl+5H5/lna9vn3zbs3AFgEcw33qjozyXlJPp9JsN+5xGpfGqZPX6J+7yRPzuQEvFvn2RsALIq5hXtV/VYmN6H5bCbBftcyq14+TE9YYtnRSTYkub619si8egOARTKXcB9uQPO2JFuSHNdau3sXq1+a5O4kr6iqI3b4jH2TvHV4e8E8+gKARTTzCXVVdVqSt2Ryx7lrkrymqnZebWtr7cIkaa19s6penUnIX1lVl2Ry+9kTM7lM7tJMbkkLAExhHmfLP3mY7pXkzGXWuSrJhdvftNY2V9ULkvx2Jren3TfJLUlem+SPd7wPPQCwMjOHe2vtnCTnTFF3XZKfmXV8+vEzPzPe7rB58+apax/3uMfNNPYf/MEfzFQ/iw0bNkxde8opp8w09r777jtT/RLfEO62rVu3zjT2H/7hH05d+/u///szjX3vvTtfgATfa0/ffhYAWGXCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPVWhu7h7mrqi1JDh+7D1bmqquumrr2+c9//hw7YXc8/PDDM9V/7GMfm6n+Qx/60NS1F1988Uxjwyq6sbW2aaVFjtwBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6I9wBoDPCHQA6s/fYDcB2J5100tS173vf+0Ybe1Yf+chHpq797ne/O9PY55577tS1d9xxx0xjf/nLX56pHlieI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6Ey11sbuYe6qakuSw8fuAwBmdGNrbdNKixy5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdGbmcK+qA6rq9Kr6cFXdUlUPVdX9VXVtVb2qqr5vp/UPqqq2i9cls/YEAIts7zl8xqlJLkhyR5Irktye5IlJfi7Je5O8qKpOba21ner+McnmJT7v83PoCQAW1jzC/eYkJyb5WGvtu9tnVtUbk/xtkpdlEvQf3Knus621c+YwPgCwg5m/lm+tXd5a+6sdg32Yf2eS9wxvj5l1HABg98zjyH1Xvj1MH11i2Y9U1a8kOSDJPUluaK3dtIf7AYDu7bFwr6q9k/zi8PbjS6zy08Nrx5ork5zWWrt9N8fYssyiQ3azTQDozp68FO5tSZ6Z5LLW2id2mL8tye8m2ZRk4/B6QSYn4x2T5FNVtd8e7AsAulbfexL7HD606jVJzk3yxSRHtdbu3Y2avZNcm+Q5Sc5srZ07w/hbkhw+bT0ArBE3ttY2rbRo7kfuVfXrmQT7PyU5dneCPUlaa49mculckhw9774AYFHMNdyr6swk52VyrfqxwxnzK/H1YepreQCY0tzCvap+K8k7knw2k2C/a4qPee4wvXVefQHAoplLuFfV2ZmcQLclyXGttbt3se7hO9+Sdph/XJKzhrfvn0dfALCIZr4UrqpOS/KWJN9Jck2S11TVzqttba1dOPz8R0meVlXXJ/naMO9ZSV44/Hx2a+36WfsCgEU1j+vcnzxM90py5jLrXJXkwuHni5K8NMlPJnlRku9P8q9J/jLJ+a21a+bQEwAsrD1yKdzYXAoHQCfWxqVwAMC4hDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0Bneg33g8ZuAADm4KBpivaecxNrxTeH6dZllh8yTL+451vphm02HdttOrbbytlm01nL2+2g/EeerUi11ubbyjpQVVuSpLW2aexe1gvbbDq223Rst5WzzabT63br9Wt5AFhYwh0AOiPcAaAzwh0AOiPcAaAzC3m2PAD0zJE7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRGuANAZ4Q7AHRmocK9qp5UVX9WVf9SVY9U1daqemdVbRy7t7Vq2EZtmdedY/c3lqo6parOq6prquqbw/Z4/2PUHFlVl1XVvVX1UFXdVFVnVtVeq9X32Fay3arqoF3se62qLlnt/sdQVQdU1elV9eGqumXYd+6vqmur6lVVteS/44u+v610u/W2v/X6PPfvUVVPSXJ9kh9O8pFMnt37U0l+I8kJVXVUa+2eEVtcy+5P8s4l5j+wyn2sJW9K8uxMtsHX8h/PhF5SVZ2U5INJHk7yF0nuTfKzSd6R5Kgkp+7JZteQFW23wT8m2bzE/M/Pr6017dQkFyS5I8kVSW5P8sQkP5fkvUleVFWnth3uSGZ/SzLFdhv0sb+11hbileQTSVqS/7nT/D8a5r9n7B7X4ivJ1iRbx+5jrb2SHJvkaUkqyTHDPvT+ZdZ9fJK7kjyS5Igd5u+byS+cLckrxv5vWoPb7aBh+YVj9z3yNnthJsH8fTvNPzCTwGpJXrbDfPvbdNutq/1tIb6WH47aj88kqN610+L/neTBJL9QVfutcmusU621K1prX27DvwqP4ZQkP5Tkktba3+/wGQ9nciSbJL+2B9pcc1a43UjSWru8tfZXrbXv7jT/ziTvGd4es8Mi+1um2m5dWZSv5Y8dpp9c4n/ob1XVdZmE/3OTfGq1m1sH9qmqn0/yY5n8InRTkqtba98Zt61144XD9ONLLLs6ybYkR1bVPq21R1avrXXjR6rqV5IckOSeJDe01m4auae14tvD9NEd5tnfHttS2227Lva3RQn3ZwzTm5dZ/uVMwv3pEe5LOTDJRTvN+0pV/VJr7aoxGlpnlt3/WmuPVtVXkvx4koOTfGE1G1snfnp4/buqujLJaa2120fpaA2oqr2T/OLwdscgt7/twi6223Zd7G8L8bV8kv2H6f3LLN8+/wl7vpV1531Jjssk4PdL8hNJ/iSTv0/9dVU9e7zW1g3733S2JfndJJuSbBxeL8jk5Khjknxqwf+U9rYkz0xyWWvtEzvMt7/t2nLbrav9bVHCnSm11t48/O3qX1tr21prn2+t/WomJyL+pyTnjNshvWqt3dVa+53W2o2ttfuG19WZfMv2mSRPTXL6uF2Oo6pek+R1mVz18wsjt7Nu7Gq79ba/LUq4b/9Ndf9llm+ff9+eb6Ub209IOXrULtYH+98ctdYezeRSpmQB97+q+vUk5yb5pyTHttbu3WkV+9sSdmO7LWm97m+LEu5fGqZPX2b504bpcn+T53t9fZium6+pRrTs/jf8/e/JmZzYc+tqNrXOLeT+V1VnJjkvk2uujx3O/N6Z/W0nu7nddmXd7W+LEu5XDNPjl7gr0eMyuanDtiSfXu3G1rHnDtOF+QdiBpcP0xOWWHZ0kg1Jrl/gM5ensXD7X1X9ViY3oflsJgF11zKr2t92sILttivrbn9biHBvrf1zkk9mchLYGTstfnMmv41d1Fp7cJVbW9Oq6tClTiCpqoOSnD+83eUtV0mSXJrk7iSvqKojts+sqn2TvHV4e8EYja1lVXX4UrdWrarjkpw1vF2I/a+qzs7kRLAtSY5rrd29i9Xtb4OVbLfe9rdalHtJLHH72S8keU4m18DfnOTI5vaz/5+qOieTk0+uTnJbkm8leUqSF2dyt6vLkry0tfZvY/U4lqo6OcnJw9sDk/y3TH6rv2aYd3dr7fU7rX9pJrcDvSST24GemMllS5cm+e+LcGOXlWy34fKjp2Xy/9uvDcuflf+4jvvs1tr2sOpWVZ2W5MIk38nkq+WlzoLf2lq7cIeak7Pg+9tKt1t3+9vYt8hbzVeS/5LJpV13JPm3TALrnUk2jt3bWnxlchnIxZmcWXpfJjd++HqS/5vJdaI1do8jbptzMrlV5XKvrUvUHJXJL0TfSPJQks9lckSw19j/PWtxuyV5VZKPZnJnyQcyuZ3q7ZncK/35Y/+3rKFt1pJcaX+bbbv1tr8tzJE7ACyKhfibOwAsEuEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQmf8HLnDFyEwA/YYAAAAASUVORK5CYII="
     },
     "metadata": {
      "image/png": {
       "width": 251,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicialmente, podemos construir uma rede usando matrizes e multiplicação de matrizes. Depois, vamos refazer nossa rede usando as ferramentas do modulo `nn`. \n",
    "\n",
    "As camadas da rede MLP são chamadas de *fully-connected* ou *dense*, isso porque  todas as unidades de uma camada está conectada a todas as unidades da camada seguinte. As entradas de cada uma das camadas deve ser um vetor de uma única dimensão, e por isso nossas imagens de 28x28 devem ser convertidas em tensores de 784 unidades. Sendo assim, nosso tensor de tamanho `(64, 1, 28, 28)` é convertido para um de tamanho `(64, 784)`. Esse procedimento é chamado de *flattening*, nós achatamos um tensor de 2 dimensões em um tensor de 1 dimensão."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "## Definindo a função de ativação\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "# fazendo o flattening. Mantém o tamanho da primeira dimensão (64), referente ao tamanho do batch\n",
    "#    e transforma todas as outras dimensões em uma única dimensão.\n",
    "inputs =  images.view(images.shape[0],-1)\n",
    "\n",
    "# pesos conectando a camada de entrada (784) à camada escondida \n",
    "#    note que a camada escondida é composta por 256 neurônios\n",
    "W1 = torch.randn(inputs.shape[1] , 256)\n",
    "# pesos conectando a camada escondida à camada de saída.\n",
    "#    note que a camada de saída tem 10 neurônios pois queremos classificar 10 dígitos (classes)\n",
    "W2 = torch.randn(256, 10)\n",
    "\n",
    "# termos de bias para a camada escondida de camada de saída\n",
    "B1 = torch.randn(256)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "# computa os termos da camada escondida\n",
    "h = sigmoid(torch.mm(inputs,W1) + B1)\n",
    "\n",
    "# computa a saída da camada de saída, ou seja, a saída da rede\n",
    "out = torch.mm(h,W2) + B2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dadas essas 10 saídas, queremos apresentar uma imagem a rede e computar a probabilidade de pertencer a cada classe, o que, a princípio, será algo do tipo:\n",
    "\n",
    "\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "A probabilidade para cada classe é mais ou menos a mesma, porque a rede não foi treinada.\n",
    "\n",
    "Para calcular essa distribuição de probabilidades, frequentemente é usada a função [**softmax**](https://en.wikipedia.org/wiki/Softmax_function), a qual pode ser definida como:\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "O que a função faz é `esmagar` a saida da rede para valores entre zero e um e depois normalizar esse valor, sendo assim, a soma das probabilidades de cada classe vai ser igual a 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def softmax(x):\n",
    "    # dim = 1 é para executar a soma pelo eixo 1, percorrendo todas as 10 possíveis classes, \n",
    "    #    e não cada uma das amostras. A saída da softmax será um tensor de 64x10, ou seja, para cada\n",
    "    #    amostra, a probabilidade dela pertencer a cada uma das classes.\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim = 1).view(-1,1)\n",
    "\n",
    "# Aqui, probabilities recebe a saída da softmax, ou seja, o tensor com formato (64,10) \n",
    "probabilities = softmax(out)\n",
    "\n",
    "# verificando o formato (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Verificando se a soma do valor das probabilidades de cada amostra é igual a 1.\n",
    "print(probabilities.sum(dim=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construíndo nossa rede usando PyTorch\n",
    "\n",
    "Agora vamos ver como fica a construção da nossa rede usando o modulo `nn` do PyTorch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define a função Sigmoid e Softmax\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1) # dimensão 1 para passar por colunas\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passa o tensor de entrada por cada uma das operações\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indo por partes\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Aqui herdamos da classe `nn.Module`. Combinada com `super().__init__()` criará uma classe que trilha a arquitetura e fornece varios atributos e métodos. Essa herança é obrigatória e qualquer nome pode ser dado à classe.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "Essa linha cria um modulo para a transformação linear , $x\\mathbf{W} + b$, com 784 entradas e 256 saídas, e aqui chamada de `self.hidden`, para nossa camada escondida. O módulo cria automaticamente os tensores de pesos e bias, os quais serão usados no método `forward`. Esse pesos e bias podem ser acessados após instanciar a rede (`net`) usando os comandos `net.hidden.weight` e `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "De forma similar, criamos outra transformação linear, com 256 entradas e 10 saídas.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Aqui definimos a função de ativação Sigmoid para ativação, e a Softmax para computar as probabilidades. Setando `dim=1` na `nn.Softmax(dim=1)` estamos computando os valores para cada coluna.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "As redes criadas usando o módulo `nn.Module` do PyTorch devem definir o método `forward`. Ela recebe como entrada um tensor `x` e passa ele pelas operações definidas no método `__init__`.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Aqui o tensor de entrada `x` é passado por cada uma das operações e o retorno é jogado de volta pra `x`. O vetor passa pela camada escondida, pela Sigmoid, pela camada de saída, e finalmente pela Softmax. A sequência em que esses métodos são definidos no método `__init__` não importa, mas eles devem ser definidos na ordem correta no método `forward`\n",
    "\n",
    "Agora podemos criar nosso objeto `Network`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Criando a rede e visualizando sua representação em forma de texto.\n",
    "model = Network()\n",
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A mesma rede pode ser definida de modo mais consido e limpo usando o módulo `torch.nn.functional`. Para isso, importamos o módulo `F`, `import torch.nn.functional as F`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Camada escondida com ativação Sigmoid\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Camada escondida com ativação Softmax \n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funções de ativação\n",
    "\n",
    "Até agora nós utilizamos a função de ativação Sigmoid, mas no geral, qualquer função pode ser usada como uma função de ativação. O único requisito é que a função seja não linear. Aqui tem alguns exemplos de funções de ativação comuns: Tanh (Tangente hyperbolic), e ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "Na prática, ReLU é a função usada quase que exclusivamente para a ativação  de camadas escondidas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sua vez de construir uma rede neural\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercício:** Crie uma rede neuraç com 784 neurônios de entrada, uma camada escondida de 128 unidades e função de ativação ReLU, outra camada escondida com 64 neurônios e novamente a função de ativação ReLU, e finalmente uma camada de saída com a Softmax como função de ativação, como mostrado na figura acima. Para usar a ReLU, pode usar o módulo `nn.ReLU` ou a função `F.relu`.\n",
    "\n",
    "Uma boa prática é nomear suas camadas por seu tipo, como 'fc', por exemplo, representando camadas _fully-connected_. Para varias camadas, use `fc1`, `fc2`, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "## Coloque a sua solução aqui"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passagem Forward \n",
    "\n",
    "Agora que temos nossa rede, vamos ver o que acontece quando apresentamos uma imagem a ela."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Obtendo algumas imagens\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Redimensionando essas imagens em vetores de 1 dimensão. \n",
    "#    Novo formato deve ser(tamanho do batch, número de canais de cor, pixels da imagem) \n",
    "images.resize_(64, 1, 784)\n",
    "# podemos usar tambem images.resize_(images.shape[0], 1, 784) para pegar o tamanho do batch automaticamente\n",
    "\n",
    "# Passagem Forward pela rede\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como pudemos ver, nossa rede não faz ideia de que digito seja. Isso porque ela foi inicializada com pesos aleatórios e ainda não foi treinada!\n",
    "\n",
    "\n",
    "### Usando `nn.Sequential`\n",
    "\n",
    "PyTorch também fornece um modo mais conveniente para construir redes mais simples, onde o tensor é passado de forma sequencial pelas operações, `nn.Sequential` ([documentação](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Podemos utilizá-lo para construir uma rede similar equivalente à acima:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Hyperparametros da rede \n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Construindo a rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Passo Forward de uma única amostra pela rede e mostrando a saída\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nosso modelo aqui é o mesmo que o de antes, com 784 unidades de entrada, uma camada oculta com 128 unidades, ativação ReLU, camada oculta com 64 unidades seguida por outra ReLU, e então a camada de saída com 10 unidades seguida pela Softmax.\n",
    "\n",
    "As operações ficam disponíveis se consultadas pelo indice apropriado. Podemos, por exemplo, consultar os pesos da primeira operação linear usando `model[0]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "print(model[0])\n",
    "print(model[0].weight)\n",
    "#print(model[0].bias)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos também passar um `OrderedDict` para dar um nome a cada camada de forma individual, e assim buscar por elas sem precisar passar um índice. Note que as chaves desse dicionário devem ser únicas, então _cada operação deve ter um nome diferente_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora podemos acessar as camadas tanto pelo indice quanto pelo nome."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Treinando a rede Neural\n",
    "\n",
    "A rede que construimos ainda não é tão esperta, e não é capaz de reconhecer os dígitos:\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "A princípio, a função responsável por mapear as entradas para as saídas é composta por pesos aleatórios. Nós vamos treinar o modelo apresentando dados reais, e ajustando esses pesos a fim de aproximar a saída da função do rótulo real esperado.\n",
    "\n",
    "Para encontrar esses pesos, ou parametros, precisamos identificar o quanto a rede está errando, e pra isso usamos a já conhecida **funçao loss** (também chamada de função de custo), uma medida de quanto as estimativas da rede estão errando. Uma função loss que já vimos para regressão e classificação é o erro médio quadrático:\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "onde $n$ é o número de amostras de treinamento, $y_i$ são os rótulos verdadeiros, e $\\hat{y}_i$ são os rótulos estimados.\n",
    "\n",
    "Minimizando esse erro ao ajustar os pesos da rede conseguimos encontrar a configuração em que o erro é mínimo e a rede fica pronta para estimar os rótulos que fornecem a melhor acurácia. Podemos encontrar esse erro mínimo utilizando um processo chamado **gradiente descendente**. O gradiente é o vetor de derivadas, ou seja, inclinação da função de custo em direção ao mínimo da função. Para alcançar o ponto mínimo, devemos seguir o gradiente na direção de sua descida. Pense se estivesse descendo uma montanha e cada iteração fosse um passo na direção de sua base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backpropagation\n",
    "\n",
    "Para redes com uma única camada, o gradiente descendente é mais fácil de implementar, como vimos na última aula. No entanto, fica mais complicapo para redes mais profundas, como a que construímos. A complexidade é tanta que levou cerca de 30 anos até que os pesquisadores descobrissem uma forma adequada de treinar essas redes.\n",
    "\n",
    "O treinamento de redes multi-camadas é feito pelo algoritmo **backpropagation**, o qual é apenas uma aplicação da regra de cadeia em calculo. É mais fácil entender se convertermos uma rede de 2 camadas em uma representação gráfica.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/backprop_diagram.png' width=550px>\n",
    "\n",
    "No passo forward, os dados e operações seguem de baixo pra cima. A entrada $x$ passa pela transformação linear\n",
    "$L_1$ com pesos $W_1$ e biases $b_1$. A saída passa pela Sigmoid $S$ e outra camada linear $L_2$. Finalmente computamos a saída da função loss $\\ell$, o qual é usado para medir o quanto a rede está errando. O objetivo é ajustar os pesos e bias para minimizar $\\ell$.\n",
    "\n",
    "Para treinar os pesos com gradiente descendente, propagamos o gradiente do erro de volta pela rede. Cada operação tem alguns gradientes entre a entrada e a saída. Conforme enviamos os gradientes de volta, multiplicamos o gradiente atual pelo gradiente da operação. Matematicamente falando, o que o método faz é apenas calcular o gradiente do erro em relação aos pesos usando a regra da cadeia.\n",
    "\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "Os pesos são atualizados usando esse gradiente em conjunto com uma taxa de aprendizagem $\\alpha$. \n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "A taxa de aprendizagem $\\alpha$ é escolhida de forma que a atualização dos pesos a cada passo seja pequena o suficiente para que o método chegue ao valor mínimo de loss de forma iterativa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Funções de loss em PyTorch\n",
    "\n",
    "Vamos relembrar como calcular funções de loss usando PyTorch. Usando o módulo `nn`, podemos encontrar várias funções _loss_, como por exemplo a entropia cruzada (`nn.CrossEntropyLoss`). Essa função geralmente é atribuída como `criterion`. Como vimos anteriormente, classificação multi-classe, como no caso da MNIST, usamos a softmax para predizer a probabilidade de cada classe. Com a saída da softmax, queremos usar a entropia cruzada como função de _loss_. Para calcular o erro de fato, precisamos definir o critério e passar os rótulos corretos à nossa rede.\n",
    "\n",
    "\n",
    "\n",
    "Note um ponto muito importante na documentação:[documentação de `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> Esse critério combina `nn.LogSoftmax()` e `nn.NLLLoss()` em uma única classe.\n",
    ">\n",
    "> A saída deve conter a pontuação esperada para cada classe.\n",
    "\n",
    "Isso significa que precisamos passar diretamente a saída da rede para computar o _loss_, em vez de fornecer a saída após passar pela função Softmax. Essa saída direta (antes da Softmax) é chamada *logit* ou *scores*. Usamos os logits porque as probabilidades fornecidas pela Softmax ficam muito próximas de 0 ou 1. ([leia mais aqui](https://docs.python.org/3/tutorial/floatingpoint.html)). Ou seja, é melhor evitar calculos usando probabilidades, uma vez que é mais comum usar o log das probabilidades."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define as transformações para normalizar os dados\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Baixa e/ou carrega os dados\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Definindo a função loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Obtendo os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logits = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As vezes pode ser mais conveniente construir um modelo usando como saída a função log-softmax usando `nn.LogSoftmax` ou `F.log_softmax` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Então você pode obter as probabilidades reais através da exponencial `torch.exp(output)`. Com a saída da log-softmax, podemos computar o _negative log likelihood_, `nn.NLLLoss` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)), o que é equivalente à saída da `nn.CrossEntropyLoss`. \n",
    "\n",
    ">**Exercício:** Construa um modelo que retorne o log-softmax como saída e calcule a função de loss utilizando o _negative log likelihood_. Note que para `nn.LogSoftmax` e `F.log_softmax` você precisa setar o parâmetro `dim` de forma apropriada. `dim=0` computa o softmax pelas linhas (amostras), de forma que as colunas somem 1, enquanto `dim=1` calcula a softmax pelas colunas, de forma que as linhas somem 1. Pense no que deseja como saída e escolha `dim` de forma apropriada.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Construa sua rede feed-forward com saída log-softmax\n",
    "model = \n",
    "\n",
    "# TODO: Defina a função de loss\n",
    "criterion = \n",
    "\n",
    "### Rode o trecho para testar se funcionou\n",
    "# Obtém os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logps = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autograd\n",
    "\n",
    "Agora que sabemos como computar o _loss_, como usá-lo no backpropagation? O PyTorch tem um módulo chamado `autograd` que computa os gradientes de forma automática. Autograd armazena as operações executadas em cada tensor, então faz o passe de volta calculando os gradientes pelo caminho. Para ter certeza que PyTorch está armazenando as operações de um tensor, devemos setar `requires_grad = True` no tensor. Podemos fazer isso em sua criação com a chamada `requires_grad`, ou a qualquer momente com `x.requires_grad_(True)`.\n",
    "\n",
    "Também é possível desligar os gradiente de um bloco usando `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Além disso, podemos ligar ou desligar a armazenagem de todos os gradientes ao mesmo tempo usando `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "Os gradiente são computados em relação a alguma variável `z` com `z.backward()`. Isso faz o passo de volta pela operação que criou `z`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "y = x**2\n",
    "print(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo podemos ver a operação que criou `y`, uma operação ao quadrado `PowBackward0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "## grad_fn mostra a função que gerou essa variável\n",
    "print(y.grad_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modulo autograd mantém registro dessas operações e sabe como computar o gradiente de cada uma. Dessa forma, ele consegue computar o gradiente para uma cadeia de operações, com relaçao a qualquer tensor. Vamos reduzir o tensor `y` para um escalar, computando a média."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos verificar os gradientes de `x` e `y`, mas no momento eles estão vazios."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para computar os gradientes, precisamos executar o comando `.backward` na variável `z`, por exemplo. isso irá computar o gradiente de `z` em relação a `x`.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O calculo dos gradientes é muito importante para qualquer rede neural. Uma vez que conhecemos o gradiente, podemos executar o gradiente descendente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Juntando a função Loss e Autograd \n",
    "\n",
    "Quando criamos uma rede com PyTorch, todos os parametros são inicializados com `requires_grad = True`. Isso significa que quando computamos o erro e chamamos `loss.backward()`, os gradientes dos parâmetros são computados. Esses gradientes são usados para atualizar os pesos usando gradiente descendente. Abaixo vemos um exemplo de como computar os gradientes usando a passagem de volta (_backward pass_)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinando a rede!\n",
    "\n",
    "A última peça que precisamos para começar a treinar é a seleção do otimizador, o qual utilizaremos para atualizar os pesos com o gradiente. Esses otimizadores estão em disponíveis em [`optim` package](https://pytorch.org/docs/stable/optim.html). Como exemplo, podemos usar o gradiente descendente estocástico (SGD) com `optim.SGD`. Definimos da seguinte forma:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que sabemos como utilizar as partes individuais, é hora de juntar tudo. O processo geral pode ser definido da seguinte forma:\n",
    "\n",
    "* Fazer a passagem forward na rede\n",
    "* Usar a saída da rede para computar o o erro (_loss_)\n",
    "* Fazer a passagem de volta (backward) pela rede com `loss.backward()` para computar os gradientes\n",
    "* Utilizar o otimizador para atualizar os pesos\n",
    "\n",
    "Abaixo passamos por um passo do treinamento e printamos como os pasos e gradientes vão mudando. Note que a linha `optimizer.zero_grad()` é usada para zerar os gradientes, que são acumulados a cada bassagem backward. Ou seja, esses valores devem ser zerados a cada iteração para evitar os valores acumulados em outras passadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "print('Pesos iniciais - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Limpa os gradientes acumulados\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Passagens Forward, backward, e atualização dos pesos\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradiente -', model[0].weight.grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# Passo de atualização dos pesos\n",
    "optimizer.step()\n",
    "print('Pesos Atualizados - ', model[0].weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando de verdade\n",
    "\n",
    "Agora vamos colocar o algoritmo dentro de um laço para que possamos iterar por todas as imagens. Uma passagem por todas as amostras de treinamento é chamada época. Vamos iterar pelo `trainloader` para obter nossos batches de treinamento. Para cada batch, vamos fazer uma passada de treinamento onde é computado o erro, faz o backpropagation e atualiza os pesos.\n",
    "\n",
    ">**Exercicio:** Implemente o treinamento completo de nossa rede. Se for implementada corretamente, você deverá ver o _loss_ diminuindo a cada época."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "## Sua solução vai aqui\n",
    "\n",
    "# TODO: defina o modelo, o critério e o atualizador\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: implemente a etapa de treinamento\n",
    "        \n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com a rede treinada, podemos verificar as predições estimadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# desligando o gradiente para acelerar o processo\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# As saidas da rede são o log da probabilidade, por isso precisamos fazer o exponencial para termos as \n",
    "#    probabilidades reais.\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b48a08561fd7e728b99163935dfd430a6e9dd7380afe98d8e7cbd9767295b8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}