{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência e validação\n",
    "\n",
    "Agora que treinamos a rede, podemos usá-la para fazer predições. Esse processo é chamado de **inferência**, um termo emprestado da estatística. No entanto, redes neurais tem uma tendencia de aprender *muito bem* o comportamento dos dados de treinamento, e as vezes apresentam dificuldade para generalizar esse conhecimento para dados desconhecidos, i.e., conjunto de testes. Esse problema é chamado de **overfitting**, o qual prejudica a performance da inferência. Para testar se está ocorrendo overfitting enquanto treinamos o modelo, podemos avaliar a sua performance em um conjunto especial de dados chamado conjunto de **validação**. Podemos evitar o _overfitting_ usando técnicas de regularização, como por exemplo **dropout**, enquanto monitoramos a performance da validação durante o treinamento.\n",
    "\n",
    "Como de costume, vamos começar carregando o conjunto de dados utilizando torchvision. Podemos baixar o conjunto de testes setando `train=False`:\n",
    "\n",
    "```python\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "O conjunto de teste geralmente contém 20% a 30% do tamanho total do dataset, e é usado para validar e testar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define as transformações para normalizar os dados\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Baixa e carrega o conjunto de treinamento\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# baixa e carrega o conjunto de testes\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um model MLP com 3 camadas escondidas, uma com 256, uma com 128 e uma com 64 neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # certificar que o tensor com as imagens foi 'achatado'\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo do conjunto de validação é medir a performance do modelo durante o treinamento sem usar as amostras empregadas para ajustar os pesos. Essa performance pode ser medida pela acurácia, taxa de acerto, entre outras opções. No exemplo usaremos a acurácia. Vamos começar fazendo o passo _forward_ sobre o conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Computa a probabilidade das classes (lembrando que usa exp por que a saída da rede é log_softmax)\n",
    "ps = torch.exp(model(images))\n",
    "# confirmando se o formato da saída é apropriada, i.e., 64 amostras com probabilidade de pertencer a 10 classes\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse vetor de probabilidades, podemos pegar a classe mais provável usando o método `ps.topk`, o qual retorna os $k$ maiores valores. Como queremos saber qual é a (única) classe mais provavel, usamos `ps.topk(1)`. A função retorna uma tupla com os $k$ maiores valores e seus indices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Veja as classes mais prováveis para as 10 primeiras amostras\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para verificar se a classe estimada corresponde ao rótulo, comparamos `top_class` e `labels`. Lembre que `top_class` é um tensor 2D com formato `(64, 1)`, enquanto `labels` é 1D com formato `(64)`, e para igualá-los, precisamos ajustar o formato do nosso tensor labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)\n",
    "# * quer dizer que está desempacotando os valores da lista top_class.shape, ou seja, é o mesmo que \n",
    "#   fazer labels.view(top_class.shape[0],top_class.shape[1])\n",
    "\n",
    "print('top_class.shape = ', top_class.shape)\n",
    "print('*top_class.shape = ', *top_class.shape)\n",
    "print('equals.shape = ', equals.shape)\n",
    "#print('equals = ', equals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos calcular a porcentagem de predições corretas. `equals` é composto por uma lista de valores binarios, o que significa que se somarmos os acertos e dividir pelo tamanho do vetor teremos a porcentagem de estimativas corretas, ou seja, é o mesmo que computar a média, o que poderia ser feito usando `torch.mean`. No entanto, usando `torch.mean(equals)` teremos o erro:\n",
    "\n",
    "```\n",
    "RuntimeError: mean is not implemented for type torch.ByteTensor \n",
    "```\n",
    "ou\n",
    "```\n",
    "RuntimeError: Can only calculate the mean of floating types. Got Bool instead.\n",
    "```\n",
    "\n",
    "Isso porque `equals` é do tipo `torch.ByteTensor` ou `torch.bool`, mas `torch.mean` não funciona pra esses tipos de dados. Então devemos converter `equals` para tensor de floats. Note que `torch.mean` retorna um tensor com um escalar, e para pegar o valor de fato desse tensor devemos usar `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Acurácia: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rede não foi treinada, por isso apresentou resultados ruins. Agora vamos treinar a rede e incluir um passo de validação para avaliar o quanto a rede progride sobre dados desconhecidos. Visto que não vamos computar os gradientes nessa etapa, devemos desligar o autograd para deixar o processo mais rápido usando `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# desligando o calculo dos gradientes\n",
    "with torch.no_grad():\n",
    "    # passo de validação\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.518..  Test Loss: 0.440..  Test Accuracy: 0.836\n",
      "Epoch: 2/30..  Training Loss: 0.392..  Test Loss: 0.409..  Test Accuracy: 0.855\n",
      "Epoch: 3/30..  Training Loss: 0.353..  Test Loss: 0.394..  Test Accuracy: 0.861\n",
      "Epoch: 4/30..  Training Loss: 0.333..  Test Loss: 0.393..  Test Accuracy: 0.858\n",
      "Epoch: 5/30..  Training Loss: 0.316..  Test Loss: 0.367..  Test Accuracy: 0.870\n",
      "Epoch: 6/30..  Training Loss: 0.301..  Test Loss: 0.355..  Test Accuracy: 0.875\n",
      "Epoch: 7/30..  Training Loss: 0.291..  Test Loss: 0.379..  Test Accuracy: 0.866\n",
      "Epoch: 8/30..  Training Loss: 0.282..  Test Loss: 0.367..  Test Accuracy: 0.867\n",
      "Epoch: 9/30..  Training Loss: 0.274..  Test Loss: 0.355..  Test Accuracy: 0.878\n",
      "Epoch: 10/30..  Training Loss: 0.261..  Test Loss: 0.356..  Test Accuracy: 0.877\n",
      "Epoch: 11/30..  Training Loss: 0.259..  Test Loss: 0.347..  Test Accuracy: 0.881\n",
      "Epoch: 12/30..  Training Loss: 0.250..  Test Loss: 0.367..  Test Accuracy: 0.878\n",
      "Epoch: 13/30..  Training Loss: 0.245..  Test Loss: 0.339..  Test Accuracy: 0.886\n",
      "Epoch: 14/30..  Training Loss: 0.245..  Test Loss: 0.377..  Test Accuracy: 0.875\n",
      "Epoch: 15/30..  Training Loss: 0.231..  Test Loss: 0.376..  Test Accuracy: 0.881\n",
      "Epoch: 16/30..  Training Loss: 0.232..  Test Loss: 0.381..  Test Accuracy: 0.878\n",
      "Epoch: 17/30..  Training Loss: 0.228..  Test Loss: 0.369..  Test Accuracy: 0.880\n",
      "Epoch: 18/30..  Training Loss: 0.219..  Test Loss: 0.378..  Test Accuracy: 0.881\n",
      "Epoch: 19/30..  Training Loss: 0.216..  Test Loss: 0.389..  Test Accuracy: 0.879\n",
      "Epoch: 20/30..  Training Loss: 0.220..  Test Loss: 0.372..  Test Accuracy: 0.884\n",
      "Epoch: 21/30..  Training Loss: 0.208..  Test Loss: 0.391..  Test Accuracy: 0.877\n",
      "Epoch: 22/30..  Training Loss: 0.205..  Test Loss: 0.388..  Test Accuracy: 0.881\n",
      "Epoch: 23/30..  Training Loss: 0.201..  Test Loss: 0.358..  Test Accuracy: 0.882\n",
      "Epoch: 24/30..  Training Loss: 0.204..  Test Loss: 0.381..  Test Accuracy: 0.891\n",
      "Epoch: 25/30..  Training Loss: 0.192..  Test Loss: 0.398..  Test Accuracy: 0.883\n",
      "Epoch: 26/30..  Training Loss: 0.192..  Test Loss: 0.423..  Test Accuracy: 0.878\n",
      "Epoch: 27/30..  Training Loss: 0.188..  Test Loss: 0.419..  Test Accuracy: 0.886\n",
      "Epoch: 28/30..  Training Loss: 0.187..  Test Loss: 0.420..  Test Accuracy: 0.878\n",
      "Epoch: 29/30..  Training Loss: 0.185..  Test Loss: 0.427..  Test Accuracy: 0.884\n",
      "Epoch: 30/30..  Training Loss: 0.180..  Test Loss: 0.413..  Test Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        # else pode ser usado em laços tipo for no python, e só será executado se não cair em nenhum break\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            # passo de validação\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                ps = torch.exp(log_ps)\n",
    "                \n",
    "                test_loss += criterion(log_ps, labels)  \n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy+= torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "        test_losses.append(test_loss / len(testloader))\n",
    "                \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Se olharmos para os valores de loss sobre o conjunto de treinamento e de teste veremos um fenômeno conhecido como overfitting:\n",
    "\n",
    "<img src='assets/overfitting.png' width=450px>\n",
    "\n",
    "A rede aprende o comportamento do conjunto de treinamento cada vez melhor, reduzindo o erro nesse contexto. No entanto, tem problemas para generalizar e classificar corretamente os dados desconhecidos. O objetivo maior dos algoritmos de aprendizado de máquina é poder predizer e fazer estimativas sobre dados desconhecidos, por isso o objetivo deve ser minimizar o erro sobre o conjunto de validação/testes. Uma possível solução, chamada *parada-antecipada* (_early-stop_) seria salvar o modelo a cada época e usar a rede com melhor resultado sobre o conjunto de validação, no entanto não é a melhor opção.\n",
    "\n",
    "A abordagem mais comum para reduzir overfitting é a utilização de técnicas de regularização. Veremos a seguir como usar uma técnica chamada *dropout* para essa tarefa, a qual seleciona de forma aleatória, a cada iteração, alguns neurônios para serem desligados. Dropout força a rede a compartilhar informações pelos pesos, reforçando seu poder de generalização. Adicionar dropout ou PyTorch é bem simples, basta utilizar o módulo [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
    "\n",
    "\n",
    "<img src='assets/dropout.png' width=550px>\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Módulo Dropout com probabilidade de 0.2 para desligar um neurônio\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # aplicando 'flattening' nas imagens\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Agora com dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # saída - não há dropout aqui\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "Durante o treinamento nos queremos usar dropout para evitar overfitting, mas durante a inferência, queremos usar a rede completa. Sendo assim, precisamos desligar o dropout durante o processo de validação, teste, ou qualquer etapa em que usemos a rede para fazer predições. Para isso, usaremos `model.eval()`, que seta o modelo para o modo de avaliação e desliga o dropout. O dropout pode ser religado voltando ao modo de treino com `model.train()`. No geral, o padrão para o laço de validação tem o formato a seguir, onde a desligamos a computação do gradiente e setamos o modelo para modo de avaliação, calculamos o loss e as métricas, e depois setamos de volta para o modo de treinamento.\n",
    "\n",
    "```python\n",
    "# desligar a computação dos gradientes\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # setar para modo de avaliação\n",
    "    model.eval()\n",
    "    \n",
    "    # passagem das amostras de validação/teste\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# volta o modelo para modo treinamento\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        x = F.log_softmax(self.fc4(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/leandro/hd_linux/miniconda3/envs/torchEnv/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.610..  Test Loss: 0.456..  Test Accuracy: 0.834\n",
      "Epoch: 2/30..  Training Loss: 0.482..  Test Loss: 0.434..  Test Accuracy: 0.840\n",
      "Epoch: 3/30..  Training Loss: 0.457..  Test Loss: 0.428..  Test Accuracy: 0.847\n",
      "Epoch: 4/30..  Training Loss: 0.431..  Test Loss: 0.410..  Test Accuracy: 0.855\n",
      "Epoch: 5/30..  Training Loss: 0.421..  Test Loss: 0.411..  Test Accuracy: 0.850\n",
      "Epoch: 6/30..  Training Loss: 0.414..  Test Loss: 0.428..  Test Accuracy: 0.856\n",
      "Epoch: 7/30..  Training Loss: 0.409..  Test Loss: 0.399..  Test Accuracy: 0.858\n",
      "Epoch: 8/30..  Training Loss: 0.401..  Test Loss: 0.394..  Test Accuracy: 0.860\n",
      "Epoch: 9/30..  Training Loss: 0.392..  Test Loss: 0.387..  Test Accuracy: 0.866\n",
      "Epoch: 10/30..  Training Loss: 0.385..  Test Loss: 0.395..  Test Accuracy: 0.856\n",
      "Epoch: 11/30..  Training Loss: 0.390..  Test Loss: 0.396..  Test Accuracy: 0.859\n",
      "Epoch: 12/30..  Training Loss: 0.384..  Test Loss: 0.383..  Test Accuracy: 0.867\n",
      "Epoch: 13/30..  Training Loss: 0.378..  Test Loss: 0.390..  Test Accuracy: 0.869\n",
      "Epoch: 14/30..  Training Loss: 0.373..  Test Loss: 0.372..  Test Accuracy: 0.870\n",
      "Epoch: 15/30..  Training Loss: 0.372..  Test Loss: 0.402..  Test Accuracy: 0.868\n",
      "Epoch: 16/30..  Training Loss: 0.366..  Test Loss: 0.395..  Test Accuracy: 0.865\n",
      "Epoch: 17/30..  Training Loss: 0.363..  Test Loss: 0.376..  Test Accuracy: 0.870\n",
      "Epoch: 18/30..  Training Loss: 0.362..  Test Loss: 0.429..  Test Accuracy: 0.858\n",
      "Epoch: 19/30..  Training Loss: 0.363..  Test Loss: 0.378..  Test Accuracy: 0.870\n",
      "Epoch: 20/30..  Training Loss: 0.358..  Test Loss: 0.365..  Test Accuracy: 0.875\n",
      "Epoch: 21/30..  Training Loss: 0.362..  Test Loss: 0.379..  Test Accuracy: 0.874\n",
      "Epoch: 22/30..  Training Loss: 0.354..  Test Loss: 0.368..  Test Accuracy: 0.869\n",
      "Epoch: 23/30..  Training Loss: 0.358..  Test Loss: 0.383..  Test Accuracy: 0.873\n",
      "Epoch: 24/30..  Training Loss: 0.357..  Test Loss: 0.404..  Test Accuracy: 0.874\n",
      "Epoch: 25/30..  Training Loss: 0.349..  Test Loss: 0.369..  Test Accuracy: 0.870\n",
      "Epoch: 26/30..  Training Loss: 0.351..  Test Loss: 0.385..  Test Accuracy: 0.869\n",
      "Epoch: 27/30..  Training Loss: 0.359..  Test Loss: 0.382..  Test Accuracy: 0.865\n",
      "Epoch: 28/30..  Training Loss: 0.347..  Test Loss: 0.369..  Test Accuracy: 0.874\n",
      "Epoch: 29/30..  Training Loss: 0.344..  Test Loss: 0.374..  Test Accuracy: 0.869\n",
      "Epoch: 30/30..  Training Loss: 0.340..  Test Loss: 0.372..  Test Accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for image, label in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(image)\n",
    "        loss = criterion(log_ps, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for image, label in testloader:         \n",
    "                \n",
    "                log_ps = model.forward(image)\n",
    "                prob = torch.exp(log_ps)\n",
    "                \n",
    "                test_loss+= criterion(log_ps, label)\n",
    "                \n",
    "                \n",
    "                k_prob, k_class = prob.topk(1, dim=1)\n",
    "                equals = k_class == label.view(*k_class.shape)\n",
    "                \n",
    "                accuracy+= torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "    train_losses.append(running_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "          \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "          \"Test Loss: {:.3f}.. \".format(test_losses[-1]),\n",
    "          \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência\n",
    "\n",
    "Agora que treinamos o modelo, podemos usá-lo para inferência. Já fizemos isso antes, mas agora precisamos lembrar de setar o modelo para o mode de inferência com `model.eval()`. Precisamos também desligar o autograd usando `torch.no_grad()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/leandro/hd_linux/miniconda3/envs/torchEnv/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importando o módulo helper para ajudar a plotar\n",
    "import helper\n",
    "\n",
    "# Testando nossa rede\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convertendo imagens 2D em tensores 1D\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Computando o log das probabilidades para cada imagem (com log_softmax)\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "# computa as probabilidades fazendo o exponencial do log das probabilidades \n",
    "ps = torch.exp(output)\n",
    "\n",
    "# plotando as probabilidades\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando e carregando modelos\n",
    "\n",
    "Agora aprenderemos a salvar e a carregar os modelos treinados. É muito importante pois, frequentemente, precisaremos salvar os modelos após treiná-los para usá-lo em predições sobre novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformação para normalizar os dados\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# download e carrega os dados de treinamento\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# download e carrega os dados de validação/teste\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando uma das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando a rede\n",
    "\n",
    "Para não ficar muito confuso com muito código, a parte de modelagem da rede que já apredemos foi escrita no arquivo `fc_model`. Com esse arquivo, podemos criar uma rede chamando `fc_model.Network` e treiná-la com o comando `fc_model.train`. Após treiná-lo, será usado como exemplo para demonstrar como salvar e carregar modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a rede, definindo o criterion (função loss) e o otimizador\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando e carregando o modelo\n",
    "\n",
    "Como já devem ter percebido, não é prático ficar treinando a rede toda hora que precisar usá-la. Em vez disso, podemos salvar o modelo treinado e carregá-lo para usar mais tarde para continuar o treinamento ou fazer predições.\n",
    "\n",
    "Os parâmetros da rede são armazenados em um `state_dict`. Esse 'dicionário de estados' contém os pesos e biases para cada uma das camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nosso modelo: \\n\\n\", model, '\\n')\n",
    "print(\"As chaves do dicionário: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modo mais simples de salvar o modelo é usando `torch.save`. Podemos, por exemplo, salvá-lo num arquivo `'checkpoint.pth'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E depois carregá-lo usando `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sequência, carregamos nosso state_dict na rede, usando o comando `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece bem simples, mas como já estamos acostumados, nunca é tão fácil. Carregar o dicionário de estados só funciona se a arquitetura for exatamente a mesma que a do modelo salvo no checkpoint. Se criar um novo modelo com alguma diferença na arquitetura o método falha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando uma nova rede\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# Vai dar erro porque o número de neurônios nas camadas escondidas são diferentes\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso significa que precisaremos reconstruir exatamente o mesmo modelo usado no treinamento, salvando também as informações sobre a arquitetura do modelo no checkpoint, junto com o state dict. Para isso, construiremos um dicionário com todas as informações necessárias reconstruir o modelo completamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora o checkpoint tem todas as informações necessárias para reconstruir o modelo treinado. Podemos criar uma função para fazer o processo, assim como podemos, de forma similar, criar uma função para carregar os checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício em grupo\n",
    "\n",
    "Cada grupo deve desenvolver uma rede neural MLP para classificar o dataset Kuzushiji-MNIST. O objetivo é conseguir a melhor acurácia no conjunto de teste.\n",
    "\n",
    "Sugestões:\n",
    "\n",
    "- Testar diferentes configurações, como número de camadas escondidas e neurônios por camadas;\n",
    "- Testar como funciona com ou sem dropout;\n",
    "- Testar diferentes otimizadores (não apenas SGD) e diferentes valores de taxa de aprendizado;\n",
    "- Testar possiveis transformações no dataset;\n",
    "- Testar diferente números de épocas.\n",
    "\n",
    "Apresentação:\n",
    "\n",
    "- Carregar o modelo treinado e executar o passo de inferência sobre o conjunto de testes;\n",
    "- Mostrar gráfico de convergência durante as épocas, considerando o conjunto de treinamento e o conjunto de testes;\n",
    "- Mostrar matriz de confusão, acurácia, e demais métricas que acharem necessárias.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('torchEnv': conda)",
   "language": "python",
   "name": "python37764bittorchenvconda44a76b6c90fa48eea1939354f840259c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
