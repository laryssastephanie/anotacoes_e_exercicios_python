{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introdução ao PyTorch\n",
    "\n",
    "\n",
    "[PyTorch](http://pytorch.org/) é um framework para desenolver e treinar redes neurais. Muitas de suas funções se comportam exatamente da mesma forma que o numpy, onde os arrays são chamados de tensores. A vantagem desses tensores em relação aos arrays do numpy é que eles facilitam a movimentação dos dados da CPU para a GPU, e também são usados por funções do PyTorch para computar automaticamente gradientes (para o backpropagation) e outros modulos para construir redes neurais. No geral, PyTorch é mais coerente com programação Python e Numpy/Scipy quando comparada com TensorFlow ou outros frameworks.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como vimos na Regressão Linear, Regressão Logística e Perceptron, uma coisa muito comum na área de aprendizado de máquinas é resolver equações lineares do tipo:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Em forma de vetores, podemos representar o produto escalar:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensores\n",
    "\n",
    "A grosso modo, algoritmos de aprendizado envolvem um monte de operações de algebra linear em tensores, uma generalização de matrizes. Um vetor é um tensor de 1 dimensão, e uma matriz é um tensor de 2 dimensões, e um array com 3 dimensões é um tensor tridimensional (para imagens com RGB, por exemplo). Sendo assim, a estrutura fundamental de redes neurais e PyTorch são os tensores.\n",
    "\n",
    "\n",
    "<img src=\"assets/tensor_examples.svg\" width=600px>\n",
    "\n",
    "Vejamos alguns exemplos de uso do PyTorch e seus tensores"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Primeiramente, importamos o PyTorch\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def activation(x):\n",
    "    \"\"\" Função de ativação - Sigmoid\n",
    "    \n",
    "        Argumentos\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Gerando dados aleatórios\n",
    "torch.manual_seed(7) # Seta um seed para sempre gerar os mesmos números aleatórios\n",
    "\n",
    "# Features é um tensor com 1 linha (1 única amostra) e 5 colunas (5 características por amostra), \n",
    "#   inicializadas de forma aleatória usando uma distribuição normal com média zero e desvio 1.\n",
    "features = torch.randn((1, 5))\n",
    "\n",
    "# Gerando os pesos aleatórios para o nosso modelo. randn_like gera um tensor com as mesmas carácterísticas\n",
    "#    que o tensor passado como parâmetro\n",
    "weights = torch.randn_like(features)\n",
    "\n",
    "\n",
    "# termo de bias - tensor com uma única linha e coluna.\n",
    "bias = torch.randn((1, 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Esses tensores podem ser somados, subtraidos, multiplicados, etc, assim como os arrays numpy. Em geral, usamos os tensores de forma bem parecida com esses arrays, com a vantagem de poder utilizar em GPUs. Como exemplo, podemos computar a saída desse nosso modelo de neurônio:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Podemos predizer a saída do nosso neurônio:\n",
    "\n",
    "# Assim como numpy, podemos usar as opções torch.sum(), assim como o métodos .sum() nos tensores.\n",
    "\n",
    "# opção 1 - torch.sum()\n",
    "y = activation(torch.sum(features * weights) + bias)\n",
    "print('opção 1: ', y)\n",
    "\n",
    "# opção 2 - .sum()\n",
    "y = activation((features * weights).sum() + bias)\n",
    "print('opção 2: ', y)\n",
    "\n",
    "# Podemos também juntar as operações de soma e multiplicação numa única operação, executando a multiplicação\n",
    "#   de matrizes. Em geral, multiplicação de matriz é mais eficiente, principalmente em GPUs. \n",
    "#   Para tanto, podemos utilizar as funções torch.mm() ou torch.matmul() - a última é mais complicada\n",
    "#      e oferece mais opções (verificar em https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "# opção 3 - torch.mm()\n",
    "y = activation(torch.mm(features, weights.view(5,1)) + bias)\n",
    "print('opção 3: ', y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "opção 1:  tensor([[0.1595]])\n",
      "opção 2:  tensor([[0.1595]])\n",
      "opção 3:  tensor([[0.1595]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note que na opção 3 tivemos que redimensionar nosso vetor de pesos com a função .view(). Caso contrário, teríamos um erro muito comum:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "torch.mm(features, weights)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 1x5)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_781/1895717032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 1x5)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Isso por que, na multiplicação de matrizes, o número de colunas no primeiro tensor deve ser igual ao número de linhas do segundo tensor. Tanto o tensor features quanto o tensor weights tem o mesmo formato, i.e., (1,5). Sendo assim, foi necessário mudar o formato para que a multiplicação funcionasse.\n",
    "\n",
    "Obs: para ver o formato de um tensor, podemos simplesmente usar .shape.\n",
    "\n",
    "Existem também algumas opções para mudar o formato do tensor: [`.reshape()`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape), [`.resize_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.resize_.html#torch.Tensor.resize_) e [`.view()`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view).\n",
    "\n",
    "Usando como exemplo nosso tensor weights:\n",
    "\n",
    "* `weights.reshape(a, b)` retorna um novo tensor com os mesmos dados de `weights` com tamanho `(a, b)`, quando possível retorna apenas um view(), quando não, faz uma cópia dos dados.\n",
    "\n",
    "* `weights.resize_(a, b)` retorna o mesmo tensor com um formato diferente. Se o número de elementos for menor que o original, alguns elementos serão removidos do tensor (mas não da memória). Se o novo formato tem mais elementos, estes serão inicializados na memória. Note que o _ quer dizer que as operações são executadas **in-place**. [Clique aqui para mais informações a respeito](https://discuss.pytorch.org/t/what-is-in-place-operation/16244).\n",
    "\n",
    "* `weights.view(a, b)` retorna um tensor  no formato `(a, b)` com os mesmos dados contidos wm `weights`.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Numpy para Torch e vice-versa\n",
    "\n",
    "PyTorch apresenta diversos modos de converter entre arrays Numpy e tensores Torch. Vejamos alguns exemplos:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Gerando um array numpy de (4,3)\n",
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.88192157, 0.37980126, 0.74126201],\n",
       "       [0.6078123 , 0.99352859, 0.87861698],\n",
       "       [0.77271544, 0.12175601, 0.27517931],\n",
       "       [0.35672085, 0.73070465, 0.19871354]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Convertendo de numpy para tensor\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.8819, 0.3798, 0.7413],\n",
       "        [0.6078, 0.9935, 0.8786],\n",
       "        [0.7727, 0.1218, 0.2752],\n",
       "        [0.3567, 0.7307, 0.1987]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# convertendo de tensor para numpy\n",
    "b.numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.88192157, 0.37980126, 0.74126201],\n",
       "       [0.6078123 , 0.99352859, 0.87861698],\n",
       "       [0.77271544, 0.12175601, 0.27517931],\n",
       "       [0.35672085, 0.73070465, 0.19871354]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A memória é compartilhada entre o array Numpy e o tensor Torch, então, se o valor de um objeto for mudado _in-place_ , o outro objeto também será alterado."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Multiplicando o tensor por 2, in-place\n",
    "b.mul_(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.7638, 0.7596, 1.4825],\n",
       "        [1.2156, 1.9871, 1.7572],\n",
       "        [1.5454, 0.2435, 0.5504],\n",
       "        [0.7134, 1.4614, 0.3974]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# O array numpy é ajustado ao novo valor\n",
    "a"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.76384315, 0.75960252, 1.48252402],\n",
       "       [1.21562461, 1.98705718, 1.75723395],\n",
       "       [1.54543088, 0.24351202, 0.55035862],\n",
       "       [0.7134417 , 1.4614093 , 0.39742707]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regressão linear com PyTorch\n",
    "\n",
    "<img src=\"assets/rl.png\" width=600px>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Passo n°1: importando pacotes\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Verificando a versão do PyTorch e se está usando GPU\n",
    "print('Versão PyTorch: ', torch.__version__)\n",
    "print('Usando GPU: ', torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    print('GPU: ',torch.cuda.get_device_name(torch.cuda.current_device()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Versão PyTorch:  1.9.0\n",
      "Usando GPU:  True\n",
      "GPU:  NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Passo n°2: gerando algumas amostras\n",
    "x_data = Variable(torch.Tensor([[10.0], [9.0], [3.0], [2.0]]))\n",
    "y_data = Variable(torch.Tensor([[90.0], [80.0], [50.0], [30.0]]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para configurar a classe do nosso modelo, precisamos definir a classe init (onde definimos os atributos) e forward (em redes neurais é muito comum, visto que a etapa de atualização dos pesos é feita de modo backward com o backpropagation). \n",
    "\n",
    "Como o modelo recebe como entrada uma amostra com uma única _feature_ e entrega como saída um único valor, inicializamos o modelo com uma camada linear: torch.nn.Linear(1, 1). Linear por que essa camada executa uma combinação linear (os pesos e bias são intrínsicos na camada e não precisamos definir). O primeiro 1 representa o número de características de entrada, e o segundo 1 significa o tamanho da saída.\n",
    "\n",
    "Em seguida, definimos a função forward, que basicamente contém as instruções da sequência dos passos do modelo. Em outras palavras, esse passo executa todos os processos do modelo desde os dados de entrada até a saída. Como a regressão linear é bem simples, a função recebe uma entrada $x$ e produz uma estimativa de $y$ como saída, ou seja, $\\hat{y}$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    \n",
    "model = LinearRegression()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Função de Loss (Criterion) e Otimizador\n",
    "\n",
    "Após executar a função forward, a função de loss é usada para computar o quão distante está $\\hat{y}$ de $y$, e assim ajustar os pesos para aproximar essa diferença, a fim de produzir o melhor modelo possível. Definir essa função de loss no PyTorch é muito simples. Nesse caso usaremos o erro médio quadrado ( _Mean Square Error (MSE)_ ), por ser mais comum na tarefa de regressão."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "criterion = torch.nn.MSELoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na sequência, usaremos o otimizador Gradiente Descendente Estocástico (_Stochastic Gradient Descent (SGD)_) para atualizar os pesos do modelo. A função model.parameters() diz ao otimizador quais são os pesos a serem atualizados, enquanto _lr_ instrui qual a taxa de aprendizado será utilizada."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinando o modelo\n",
    "\n",
    "Agora nosso modelo está pronto para ser treinado. O procedimento será executado por $20$ épocas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    \n",
    "    # Zera os gradientes a cada época (usado no backpropagation).\n",
    "    #   esse passo é necessário pois a cada vez que o erro é propagado, \n",
    "    #   ele é acumulado em vez de ser substituido.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(x_data)\n",
    "    \n",
    "    # Computa o erro\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    \n",
    "    # Propaga o erro para as camadas anteriores \n",
    "    #    (no caso só temos um, mas seguimos o padrão de redes maiores)\n",
    "    loss.backward()\n",
    "    # Atualiza os pesos\n",
    "    optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fazendo predições\n",
    "\n",
    "Agora que o modelo está treinado, podemos usá-lo para fazer predições dado novos valores de entrada:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "new_x = Variable(torch.Tensor([[4.0]]))\n",
    "y_pred = model(new_x)\n",
    "print(\"Valor estimado: \", float(y_pred.data[0][0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Valor estimado:  39.5115966796875\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regressão Logística\n",
    "\n",
    "<img src=\"assets/regLog.png\" width=400px>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# importando pacotes\n",
    "\n",
    "# https://towardsdatascience.com/logistic-regression-on-mnist-with-pytorch-b048327f8d19\n",
    "    \n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carregando o dataset\n",
    "\n",
    "Usamos torchvision.datasets para carregar o dataset Fashion-MNIST. Transforms são ferramentas de normalização, aumento de dados, entre outros. Nesse caso utilizaremos apenas para transformar em vetor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "train_dataset = dsets.FashionMNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.FashionMNIST(root='./data', train=False, transform=transforms.ToTensor())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e928997acc814bc2b06576ad75eb9bdc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "678486008a954ad39e5d0b891f5c45f7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b46c3fa63024224b7b747f823dd025b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86b26082dc5a4c3bbcbef9495e2feab1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/laryssastephanie/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criando um data loader\n",
    "\n",
    "Conjuntos de dados grandes não podem ser carregados diretamente na memória, principalmente da GPU, por falta de espaço. Para isso, utilizamos data loaders, para carregar _batches_, ou seja, porções de amostras, a cada chamada."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criando o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definindo os hyperparâmetros e instanciando o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "n_iters = 3000\n",
    "epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate = 0.001\n",
    "\n",
    "model = LogisticRegression(input_dim, output_dim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instanciando a classe de Loss\n",
    "\n",
    "Em seguida definimos nossa função de loss, no caso a entropia cruzada (Cross-Entropy (CE)). Note que CE é praticamente a função Maximum Likelihood Estimation (MLE) que aprendemos na aula passada, com sinal inverso, ou seja, minimizar o BCE é praticamente a mesma coisa que maximizar o MLE."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definindo o otimizador"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinando o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "iter = 0\n",
    "for epoch in range(int(epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            # calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                # for gpu, bring the predicted and labels back to cpu for python operations to work\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct.float()/total\n",
    "            print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iter, loss.item(), accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration: 500. Loss: 1.6429442167282104. Accuracy: 62.7599983215332.\n",
      "Iteration: 1000. Loss: 1.3624911308288574. Accuracy: 65.36000061035156.\n",
      "Iteration: 1500. Loss: 1.1315202713012695. Accuracy: 66.77999877929688.\n",
      "Iteration: 2000. Loss: 0.932007372379303. Accuracy: 67.7699966430664.\n",
      "Iteration: 2500. Loss: 0.9733914732933044. Accuracy: 68.6500015258789.\n",
      "Iteration: 3000. Loss: 1.0482072830200195. Accuracy: 69.58999633789062.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercícios\n",
    "\n",
    "1. Plotar algumas imagens do dataset fashion MNIST para ter uma idea de como são as amostras.\n",
    "2. Estimar os rótulos das amostras de teste, computar a acurácia e gerar uma matriz de confusão para ver com quais classes cada classe está se confundindo\n",
    "3. Rodar esse algoritmo utilizando o dataset Kuzushiji-MNIST (KMNIST). Pesquisar para fazer aumento de dados (transform) com horizontal flipping. Plotar algumas imagens desse dataset também. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "f8b48a08561fd7e728b99163935dfd430a6e9dd7380afe98d8e7cbd9767295b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}