{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Redes Neurais Multilayer Perceptron (MLP) com PyTorch\n",
    "\n",
    "Redes Neurais podem apresentar um número massivo de parâmetros com dezenas de camadas a serem aprendidas (nesse caso, chamamos de ''deep learning''). Pora ajudar a construir essas redes, o PyTorch possui o módulo `nn`, que contêm diversas ferramentas para construir redes neurais de forma eficiente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Importando os pacotes necessários\n",
    "\n",
    "# comandos para plotar imagens mais bem definidas no notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Algumas funções auxiliares\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como exemplo, vamos mais uma vez utilizar o já conhecido dataset MNIST, formado por imagens de digitos em tons de cinza de dimensão $28\\times28$, apresentados na imagem abaixo.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/mnist.png'>\n",
    "\n",
    "Mais uma vez, vamos usar o pacote `torchvision` para carregar o dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transformação dos dados. \n",
    "# Note que nesse caso joga um valor médio de 0.5 e desvio de 0.5, normalizando os valores entre -1 e 1.\n",
    "# (https://discuss.pytorch.org/t/understanding-transform-normalize/21730)\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/laryssastephanie/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Criamos o data loader de treinamento `trainloader` e criamos um _iterator_ `iter(trainloader)`, que será chamadado da seguinte forma:\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "Note que usamos batches de tamanho $64$. Aqui vamos consultar o primeiro batch para verificar os dados. Observe que `images` aqui é um vetor com tamanho `(64, 1, 28, 28)`, ou seja, 64 imagens por batch, $1$ cor por canal (se fossem imagens coloridas seriam 3 canais), e imagens de 28x28 pixels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "plotando uma das imagens"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAHwCAYAAAC7cCafAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAcCUlEQVR4nO3dfaxtZX0n8O9PoFykggxpa5vaoJSXprY4YCuFDPISHWxTAYUZ/6gljdha7Qgqk07Ky1DbaUxs6huO1JqWCslggy2NU6pOeJGrWJteYpH4AhSujK0UkeGCIurFZ/7Y67S313PuvWfvfc4659mfT7Kzzl5rPfv53cXifM9ae61nVWstAEA/njZ2AQDAfAl3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOjM/mMXsBaq6v4khyTZPnIpADCtI5I81lp7zmobdhnumQT7vxteALBQej0tv33sAgBgDrZP02jUcK+qH62qP66qf6qqb1XV9qp6R1UdNmZdALCZjXZavqqOTHJ7kh9M8pdJvpDkZ5NcmOTMqjq5tfa1seoDgM1qzCP3/5lJsL+htXZ2a+2/tdZOT/L2JMck+R8j1gYAm1a11ta/08lR+72ZfJdwZGvtu7sse0aSrySpJD/YWvvGFJ+/Lcnx86kWAEZzR2vthNU2Guu0/GnD9GO7BnuStNYer6pPJnlJkhOT3LTShwwhvpxj51IlAGxCY52WP2aY3r3C8nuG6dHrUAsAdGWsI/dDh+mOFZYvzX/mnj5kpVMVTssDsMh6vc8dABbWWOG+dGR+6ArLl+Y/uvalAEBfxgr3Lw7Tlb5TP2qYrvSdPACwgrHC/ZZh+pKq+jc1DLfCnZzkiSR/s96FAcBmN0q4t9b+IcnHMnnizet3W/zbSQ5Ocs0097gDwKIb86lwr8tk+Nl3VdUZST6f5IWZ3AN/d5JLRqwNADat0a6WH47eX5Dk6kxC/c1JjkzyziQnGlceAKYz6vPcW2v/N8mvjFkDAPTGfe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdGS3cq2p7VbUVXg+OVRcAbHb7j9z/jiTvWGb+19e5DgDoxtjh/mhr7YqRawCArvjOHQA6M/aR+4FV9UtJfizJN5LcmeS21tpT45YFAJvX2OH+rCTX7Dbv/qr6ldbax/fWuKq2rbDo2JkrA4BNaszT8n+S5IxMAv7gJD+V5A+THJHkr6vquPFKA4DNq1prY9fwb1TV7yd5c5IbWmvnTPkZ25IcP9fCAGD93dFaO2G1jTbiBXVXDdNTRq0CADapjRjuXx2mB49aBQBsUhsx3E8cpveNWgUAbFKjhHtV/URVfc+ReVUdkeTK4e2161oUAHRirFvh/nOSN1fVbUm+lOTxJEcm+YUkW5LcmOT3R6oNADa1scL9liTHJPn3SU7O5Pv1R5N8IpP73q9pG+0yfgDYJEYJ92GAmr0OUgOsrac//elTtz3ssMNm6vuss86aqf3LX/7yqdsedNBBM/X9mte8Zuq2n/vc52bqG/bFRrygDgCYgXAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDozCjPcwfm49xzz52p/e/93u9N3fbII4+cqe+qmql9a22m9rPYunXr1G0vv/zymfp+z3veM1N7FoMjdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM7UmI9NXCtVtS3J8WPXAfvida973dRt3/a2t83U95YtW2ZqP4vN/MjXWezYsWOm9i984QunbnvPPffM1DejuKO1dsJqGzlyB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DO7D92AbDZnXrqqTO1P//886duO+bz2Ge1c+fOmdpv3bp16rYf+MAHZur7uOOOm7rthRdeOFPfnufOvnDkDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BmPfIUZXXXVVTO1P+qoo+ZUyfq64YYbZmr/+te/fqb2Dz744EztZ3HRRReN1vcsjwi+9tpr51gJG5kjdwDozFzCvarOrap3V9XWqnqsqlpV7fFPxKo6qapurKpHquqbVXVnVV1UVfvNoyYAWFTzOi1/aZLjknw9yZeTHLunlavqrCQfSvJkkg8meSTJLyZ5e5KTk5w3p7oAYOHM67T8G5McneSQJL++pxWr6pAkf5TkqSSnttZe3Vr7r0men+RTSc6tqlfOqS4AWDhzCffW2i2ttXtaa20fVj83yQ8kua619ne7fMaTmZwBSPbyBwIAsLIxLqg7fZh+ZJlltyV5IslJVXXg+pUEAP0Y41a4Y4bp3bsvaK3trKr7k/xkkucm+fyePqiqtq2waI/f+QNAz8Y4cj90mO5YYfnS/GeufSkA0J9NPYhNa+2E5eYPR/THr3M5ALAhjHHkvnRkfugKy5fmP7r2pQBAf8YI9y8O06N3X1BV+yd5TpKdSe5bz6IAoBdjhPvNw/TMZZadkuTpSW5vrX1r/UoCgH6MEe7XJ3k4ySur6gVLM6tqS5LfHd6+d4S6AKALc7mgrqrOTnL28PZZw/Tnqurq4eeHW2sXJ0lr7bGqek0mIX9rVV2XyfCzL8vkNrnrMxmSFgCYwryuln9+kt2fQ/jc4ZUkX0py8dKC1toNVfWiJJckeUWSLUnuTfKmJO/ax5HuAIBlzCXcW2tXJLlilW0+meTn59E/zOr7v//7p257zDHH7H2lPZjlb9mnnnpqpr5PPPHEqdtu27bSGFLr44ADDpi67SWXXDJT3xdffPHeV1pBVc3UN+wLz3MHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDozLye5w6b2pVXXjl121ke2Zok3/nOd6Zue+mll87U99iPbZ3FOeecM3Xbyy67bI6VrM6s+8uLX/ziOVVCzxy5A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnatZnC29EVbUtyfFj18Hm8fjjj0/d9uCDD56p73/8x3+cuu2zn/3smfoe0+GHHz5T+/vvv3/qtrP+NxvTfvvtN3YJrK87WmsnrLaRI3cA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DOCHcA6IxwB4DO7D92AcBi2rJly0ztN+tjW2+66aaxS2ABOHIHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM54njuM7JBDDpm67a/+6q/O1Pf73ve+qdtefvnlM/V9zjnnzNR+s/rzP//zsUtgAThyB4DOzCXcq+rcqnp3VW2tqseqqlXVtSuse8SwfKXXdfOoCQAW1bxOy1+a5LgkX0/y5STH7kObv09ywzLz75pTTQCwkOYV7m/MJNTvTfKiJLfsQ5vPtNaumFP/AMBgLuHeWvuXMK+qeXwkADClMa+W/5Gq+rUkhyf5WpJPtdbuXM0HVNW2FRbty9cCANClMcP9xcPrX1TVrUnOb609MEpFANCBMcL9iSS/k8nFdPcN8346yRVJTktyU1U9v7X2jb19UGvthOXmD0f0x8+jWADYbNb9PvfW2kOttctba3e01h4dXrcleUmSTyf58SQXrHddANCLDTOITWttZ5L3D29PGbMWANjMNky4D746TA8etQoA2MQ2WrifOEzv2+NaAMCK1j3cq+r4qvqefqvqjEwGw0mSZYeuBQD2bi5Xy1fV2UnOHt4+a5j+XFVdPfz8cGvt4uHnP0hyVFXdnsmodsnkavnTh58va63dPo+6AGARzetWuOcnOX+3ec8dXknypSRL4X5NknOS/EySlyY5IMk/J/mzJFe21rbOqSYAWEjVWhu7hrlznzurNcuzyS+55JKZ+j7ggANmar9ZzTpU9Zi/uz784Q9P3fass86aYyUsgDtWGtNlTzbaBXUAwIyEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0Zl7Pc4dN7S1vecvUbZ/xjGfM1Peb3vSmmdovqlke+frtb397pr5nfcwvrDVH7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGc9zhxlddtllM7V/4IEHpm57wQUXzNT30UcfPXXb7/u+75up7zHdfffdM7W/66675lQJrA1H7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ0R7gDQGeEOAJ2p1trYNcxdVW1LcvzYdcBG97znPW/qtp/+9Kdn6vuggw6aqf0sv7suvPDCmfq+8sorZ2oPq3BHa+2E1TZy5A4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4Andl/7AKA8WzZsmXqtk972rjHBk888cTUbW+99db5FQIb0Mz/d1bV4VV1QVX9RVXdW1XfrKodVfWJqnp1VS3bR1WdVFU3VtUjQ5s7q+qiqtpv1poAYJHN48j9vCTvTfKVJLckeSDJDyV5eZL3J3lpVZ3XWmtLDarqrCQfSvJkkg8meSTJLyZ5e5KTh88EAKYwj3C/O8nLkvxVa+27SzOr6reS/G2SV2QS9B8a5h+S5I+SPJXk1Nba3w3zL0tyc5Jzq+qVrbXr5lAbACycmU/Lt9Zubq19eNdgH+Y/mOSq4e2puyw6N8kPJLluKdiH9Z9Mcunw9tdnrQsAFtVaXxHznWG6c5d5pw/Tjyyz/m1JnkhyUlUduJaFAUCv1uxq+araP8kvD293DfJjhundu7dpre2sqvuT/GSS5yb5/F762LbComNXVy0A9GMtj9zfmuR5SW5srX10l/mHDtMdK7Rbmv/MNaoLALq2JkfuVfWGJG9O8oUkr1qLPpKktXbCCv1vS3L8WvULABvZ3I/cq+o3krwzyeeSnNZae2S3VZaOzA/N8pbmPzrv2gBgEcw13KvqoiTvTnJXJsH+4DKrfXGYHr1M+/2TPCeTC/Dum2dtALAo5hbuVfWbmQxC85lMgv2hFVa9eZieucyyU5I8PcntrbVvzas2AFgkcwn3YQCatybZluSM1trDe1j9+iQPJ3llVb1gl8/YkuR3h7fvnUddALCIZr6grqrOT/KWTEac25rkDVW1+2rbW2tXJ0lr7bGqek0mIX9rVV2XyfCzL8vkNrnrMxmSFgCYwjyuln/OMN0vyUUrrPPxJFcvvWmt3VBVL0pySSbD025Jcm+SNyV5167j0AMAqzNzuLfWrkhyxRTtPpnk52ftH5jemWcud+nLvjnwwNkGkVzmDN+q7Nix0lAZe3fXXXfN1DdsdOM+kBkAmDvhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0BnhDgCdEe4A0JmZn+cObF6vfe1rp27bWptjJZuvf9jIHLkDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0RrgDQGeEOwB0xiNfgVE89dRTM7V/17veNadKoD+O3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM8IdADoj3AGgM57nDoziySefnKn92972tjlVAv1x5A4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZ4Q4AnRHuANAZj3yFBfbZz3526rY//MM/PFPff/qnfzpTe2BljtwBoDMzh3tVHV5VF1TVX1TVvVX1zaraUVWfqKpXV9XTdlv/iKpqe3hdN2tNALDI5nFa/rwk703ylSS3JHkgyQ8leXmS9yd5aVWd11pru7X7+yQ3LPN5d82hJgBYWPMI97uTvCzJX7XWvrs0s6p+K8nfJnlFJkH/od3afaa1dsUc+gcAdjHzafnW2s2ttQ/vGuzD/AeTXDW8PXXWfgCAfbPWV8t/Z5juXGbZj1TVryU5PMnXknyqtXbnGtcDAN1bs3Cvqv2T/PLw9iPLrPLi4bVrm1uTnN9ae2Af+9i2wqJj97FMAOjOWt4K99Ykz0tyY2vto7vMfyLJ7yQ5Iclhw+tFmVyMd2qSm6rq4DWsCwC6tiZH7lX1hiRvTvKFJK/adVlr7aEkl+/W5LaqekmSTyR5YZILkrxzb/201k5Yof9tSY5ffeUAsPnN/ci9qn4jk2D+XJLTWmuP7Eu71trOTG6dS5JT5l0XACyKuYZ7VV2U5N2Z3Kt+2nDF/Gp8dZg6LQ8AU5pbuFfVbyZ5e5LPZBLsD03xMScO0/vmVRcALJq5hHtVXZbJBXTbkpzRWnt4D+sev/uQtMP8M5K8cXh77TzqAoBFNPMFdVV1fpK3JHkqydYkb6iq3Vfb3lq7evj5D5IcVVW3J/nyMO+nk5w+/HxZa+32WesCgEU1j6vlnzNM90ty0QrrfDzJ1cPP1yQ5J8nPJHlpkgOS/HOSP0tyZWtt6xxqAoCFVd/7PJfNz61wAHTijpVu+94Tz3MHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM4IdwDojHAHgM70Gu5HjF0AAMzBEdM02n/ORWwUjw3T7SssP3aYfmHtS+mGbTYd2206ttvq2WbT2cjb7Yj8a56tSrXW5lvKJlBV25KktXbC2LVsFrbZdGy36dhuq2ebTafX7dbraXkAWFjCHQA6I9wBoDPCHQA6I9wBoDMLebU8APTMkTsAdEa4A0BnhDsAdEa4A0BnhDsAdEa4A0BnhDsAdGahwr2qfrSq/riq/qmqvlVV26vqHVV12Ni1bVTDNmorvB4cu76xVNW5VfXuqtpaVY8N2+PavbQ5qapurKpHquqbVXVnVV1UVfutV91jW812q6oj9rDvtaq6br3rH0NVHV5VF1TVX1TVvcO+s6OqPlFVr66qZX+PL/r+ttrt1tv+1uvz3L9HVR2Z5PYkP5jkLzN5du/PJrkwyZlVdXJr7WsjlriR7UjyjmXmf32d69hILk1yXCbb4Mv512dCL6uqzkryoSRPJvlgkkeS/GKStyc5Ocl5a1nsBrKq7Tb4+yQ3LDP/rvmVtaGdl+S9Sb6S5JYkDyT5oSQvT/L+JC+tqvPaLiOS2d+STLHdBn3sb621hXgl+WiSluS/7Db/D4b5V41d40Z8JdmeZPvYdWy0V5LTkhyVpJKcOuxD166w7iFJHkryrSQv2GX+lkz+4GxJXjn2v2kDbrcjhuVXj133yNvs9EyC+Wm7zX9WJoHVkrxil/n2t+m2W1f720Kclh+O2l+SSVC9Z7fF/z3JN5K8qqoOXufS2KRaa7e01u5pw2+FvTg3yQ8kua619ne7fMaTmRzJJsmvr0GZG84qtxtJWms3t9Y+3Fr77m7zH0xy1fD21F0W2d8y1XbryqKclj9tmH5smf/Qj1fVJzMJ/xOT3LTexW0CB1bVLyX5sUz+ELozyW2ttafGLWvTOH2YfmSZZbcleSLJSVV1YGvtW+tX1qbxI1X1a0kOT/K1JJ9qrd05ck0bxXeG6c5d5tnf9m657baki/1tUcL9mGF69wrL78kk3I+OcF/Os5Jcs9u8+6vqV1prHx+joE1mxf2vtbazqu5P8pNJnpvk8+tZ2Cbx4uH1L6rq1iTnt9YeGKWiDaCq9k/yy8PbXYPc/rYHe9huS7rY3xbitHySQ4fpjhWWL81/5tqXsun8SZIzMgn4g5P8VJI/zOT7qb+uquPGK23TsP9N54kkv5PkhCSHDa8XZXJx1KlJblrwr9LemuR5SW5srX10l/n2tz1babt1tb8tSrgzpdbabw/fXf1za+2J1tpdrbXXZnIh4kFJrhi3QnrVWnuotXZ5a+2O1tqjw+u2TM6yfTrJjye5YNwqx1FVb0jy5kzu+nnVyOVsGnvabr3tb4sS7kt/qR66wvKl+Y+ufSndWLog5ZRRq9gc7H9z1FrbmcmtTMkC7n9V9RtJ3pnkc0lOa609stsq9rdl7MN2W9Zm3d8WJdy/OEyPXmH5UcN0pe/k+V5fHaab5jTViFbc/4bv/56TyYU9961nUZvcQu5/VXVRkndncs/1acOV37uzv+1mH7fbnmy6/W1Rwv2WYfqSZUYlekYmgzo8keRv1ruwTezEYbowvyBmcPMwPXOZZackeXqS2xf4yuVpLNz+V1W/mckgNJ/JJKAeWmFV+9suVrHd9mTT7W8LEe6ttX9I8rFMLgJ7/W6LfzuTv8auaa19Y51L29Cq6ieWu4Ckqo5IcuXwdo9DrpIkuT7Jw0leWVUvWJpZVVuS/O7w9r1jFLaRVdXxyw2tWlVnJHnj8HYh9r+quiyTC8G2JTmjtfbwHla3vw1Ws916299qUcaSWGb42c8neWEm98DfneSkZvjZf6Oqrsjk4pPbknwpyeNJjkzyC5mMdnVjknNaa98eq8axVNXZSc4e3j4ryX/M5K/6rcO8h1trF++2/vWZDAd6XSbDgb4sk9uWrk/ynxZhYJfVbLfh9qOjMvn/9svD8p/Ov97HfVlrbSmsulVV5ye5OslTmZxaXu4q+O2ttat3aXN2Fnx/W+12625/G3uIvPV8JXl2Jrd2fSXJtzMJrHckOWzs2jbiK5PbQP5XJleWPprJwA9fTfJ/MrlPtMauccRtc0UmQ1Wu9Nq+TJuTM/mD6P8l+WaSz2ZyRLDf2P+ejbjdkrw6yf/OZGTJr2cynOoDmYyV/h/G/rdsoG3Wktxqf5ttu/W2vy3MkTsALIqF+M4dABaJcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOiMcAeAzgh3AOjM/wcXEoqvzekRugAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "image/png": {
       "width": 251,
       "height": 248
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inicialmente, podemos construir uma rede usando matrizes e multiplicação de matrizes. Depois, vamos refazer nossa rede usando as ferramentas do modulo `nn`. \n",
    "\n",
    "As camadas da rede MLP são chamadas de *fully-connected* ou *dense*, isso porque  todas as unidades de uma camada está conectada a todas as unidades da camada seguinte. As entradas de cada uma das camadas deve ser um vetor de uma única dimensão, e por isso nossas imagens de 28x28 devem ser convertidas em tensores de 784 unidades. Sendo assim, nosso tensor de tamanho `(64, 1, 28, 28)` é convertido para um de tamanho `(64, 784)`. Esse procedimento é chamado de *flattening*, nós achatamos um tensor de 2 dimensões em um tensor de 1 dimensão."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## Definindo a função de ativação\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "# fazendo o flattening. Mantém o tamanho da primeira dimensão (64), referente ao tamanho do batch\n",
    "#    e transforma todas as outras dimensões em uma única dimensão.\n",
    "inputs =  images.view(images.shape[0],-1)\n",
    "\n",
    "# pesos conectando a camada de entrada (784) à camada escondida \n",
    "#    note que a camada escondida é composta por 256 neurônios\n",
    "W1 = torch.randn(inputs.shape[1] , 256)\n",
    "# pesos conectando a camada escondida à camada de saída.\n",
    "#    note que a camada de saída tem 10 neurônios pois queremos classificar 10 dígitos (classes)\n",
    "W2 = torch.randn(256, 10)\n",
    "\n",
    "# termos de bias para a camada escondida de camada de saída\n",
    "B1 = torch.randn(256)\n",
    "B2 = torch.randn(10)\n",
    "\n",
    "# computa os termos da camada escondida\n",
    "h = sigmoid(torch.mm(inputs,W1) + B1)\n",
    "\n",
    "# computa a saída da camada de saída, ou seja, a saída da rede\n",
    "out = torch.mm(h,W2) + B2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dadas essas 10 saídas, queremos apresentar uma imagem a rede e computar a probabilidade de pertencer a cada classe, o que, a princípio, será algo do tipo:\n",
    "\n",
    "\n",
    "<img src='assets/image_distribution.png' width=500px>\n",
    "\n",
    "A probabilidade para cada classe é mais ou menos a mesma, porque a rede não foi treinada.\n",
    "\n",
    "Para calcular essa distribuição de probabilidades, frequentemente é usada a função [**softmax**](https://en.wikipedia.org/wiki/Softmax_function), a qual pode ser definida como:\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "\n",
    "O que a função faz é `esmagar` a saida da rede para valores entre zero e um e depois normalizar esse valor, sendo assim, a soma das probabilidades de cada classe vai ser igual a 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def softmax(x):\n",
    "    # dim = 1 é para executar a soma pelo eixo 1, percorrendo todas as 10 possíveis classes, \n",
    "    #    e não cada uma das amostras. A saída da softmax será um tensor de 64x10, ou seja, para cada\n",
    "    #    amostra, a probabilidade dela pertencer a cada uma das classes.\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim = 1).view(-1,1)\n",
    "\n",
    "# Aqui, probabilities recebe a saída da softmax, ou seja, o tensor com formato (64,10) \n",
    "probabilities = softmax(out)\n",
    "\n",
    "# verificando o formato (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Verificando se a soma do valor das probabilidades de cada amostra é igual a 1.\n",
    "print(probabilities.sum(dim=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construíndo nossa rede usando PyTorch\n",
    "\n",
    "Agora vamos ver como fica a construção da nossa rede usando o modulo `nn` do PyTorch."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define a função Sigmoid e Softmax\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1) # dimensão 1 para passar por colunas\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passa o tensor de entrada por cada uma das operações\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indo por partes\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Aqui herdamos da classe `nn.Module`. Combinada com `super().__init__()` criará uma classe que trilha a arquitetura e fornece varios atributos e métodos. Essa herança é obrigatória e qualquer nome pode ser dado à classe.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "Essa linha cria um modulo para a transformação linear , $x\\mathbf{W} + b$, com 784 entradas e 256 saídas, e aqui chamada de `self.hidden`, para nossa camada escondida. O módulo cria automaticamente os tensores de pesos e bias, os quais serão usados no método `forward`. Esse pesos e bias podem ser acessados após instanciar a rede (`net`) usando os comandos `net.hidden.weight` e `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "De forma similar, criamos outra transformação linear, com 256 entradas e 10 saídas.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Aqui definimos a função de ativação Sigmoid para ativação, e a Softmax para computar as probabilidades. Setando `dim=1` na `nn.Softmax(dim=1)` estamos computando os valores para cada coluna.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "As redes criadas usando o módulo `nn.Module` do PyTorch devem definir o método `forward`. Ela recebe como entrada um tensor `x` e passa ele pelas operações definidas no método `__init__`.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Aqui o tensor de entrada `x` é passado por cada uma das operações e o retorno é jogado de volta pra `x`. O vetor passa pela camada escondida, pela Sigmoid, pela camada de saída, e finalmente pela Softmax. A sequência em que esses métodos são definidos no método `__init__` não importa, mas eles devem ser definidos na ordem correta no método `forward`\n",
    "\n",
    "Agora podemos criar nosso objeto `Network`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Criando a rede e visualizando sua representação em forma de texto.\n",
    "model = Network()\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A mesma rede pode ser definida de modo mais consido e limpo usando o módulo `torch.nn.functional`. Para isso, importamos o módulo `F`, `import torch.nn.functional as F`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Entradas para transformação linear da camada escondida\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Camada de saída, 10 unidades, 1 para cada dígito\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Camada escondida com ativação Sigmoid\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Camada escondida com ativação Softmax \n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funções de ativação\n",
    "\n",
    "Até agora nós utilizamos a função de ativação Sigmoid, mas no geral, qualquer função pode ser usada como uma função de ativação. O único requisito é que a função seja não linear. Aqui tem alguns exemplos de funções de ativação comuns: Tanh (Tangente hyperbolic), e ReLU (rectified linear unit).\n",
    "\n",
    "<img src=\"assets/activation.png\" width=700px>\n",
    "\n",
    "Na prática, ReLU é a função usada quase que exclusivamente para a ativação  de camadas escondidas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sua vez de construir uma rede neural\n",
    "\n",
    "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
    "\n",
    "> **Exercício:** Crie uma rede neuraç com 784 neurônios de entrada, uma camada escondida de 128 unidades e função de ativação ReLU, outra camada escondida com 64 neurônios e novamente a função de ativação ReLU, e finalmente uma camada de saída com a Softmax como função de ativação, como mostrado na figura acima. Para usar a ReLU, pode usar o módulo `nn.ReLU` ou a função `F.relu`.\n",
    "\n",
    "Uma boa prática é nomear suas camadas por seu tipo, como 'fc', por exemplo, representando camadas _fully-connected_. Para varias camadas, use `fc1`, `fc2`, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## Coloque a sua solução aqui"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passagem Forward \n",
    "\n",
    "Agora que temos nossa rede, vamos ver o que acontece quando apresentamos uma imagem a ela."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Obtendo algumas imagens\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Redimensionando essas imagens em vetores de 1 dimensão. \n",
    "#    Novo formato deve ser(tamanho do batch, número de canais de cor, pixels da imagem) \n",
    "images.resize_(64, 1, 784)\n",
    "# podemos usar tambem images.resize_(images.shape[0], 1, 784) para pegar o tamanho do batch automaticamente\n",
    "\n",
    "# Passagem Forward pela rede\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1EAAAHXCAYAAABd89BGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAABYlAAAWJQFJUiTwAAAuuklEQVR4nO3debxt93w38M83IvNAEkk0xDVFokmRW6kaEypFipharzaK0lGrVfpIlYo+POKptqE6UCWmTmiiGjMxRqmb4AkhlCsSMsg8j7/nj7WOHMc5N3ft7HP23ne/36/Xfq2z19q/tb573TPsz/391m9Vay0AAABsnq0mXQAAAMAsEaIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAgJlVVa1/rJt0LfOgqjb25/vQWTluVR3Ttz1+c/dbVYf26zeOVjFbOiEKAJi4qtqhqn67qt5bVWdV1VVVdWVVfbuq3lVVR1XV9pOuc60s+nC/+HFjVV1YVZ+qqudV1Q6TrnMeVdWRfTA7dNK1MDlbT7oAAGC+VdVjk7whyd6LVl+Z5KYk6/rHk5K8qqqe1lr72FrXOEFXJrmi/3qbJLsleXD/eHZVHdZaO39Sxc2IHyT5epLvD2hzVd/mnGW2HZnk6f3XH781hTG79EQBABNTVc9IcmK6APX1JE9LskdrbafW2i5Jbpfkyek+rP5EkodOos4JenVrbe/+sVuSPZK8IklLcu904ZNNaK29rrW2f2vtjwe0+Xzf5hGrWRuzS4gCACaiqu6T5O/TfR55X5L7tdbe3lq7cOE1rbVLW2vvbq0dluSpSS6fTLXTobV2YWvtxUne3K96fFX9xCRrgnkkRAEAk/LyJNumGzL1y621qzf14tbavyb5y83ZcVXdpqoeXVWvr6oNVXVeVV1XVd+rqhOq6uGbaLtVVT2jqk7ur0G6vqouqKqvVNWbqupRy7S5a1X9XVWdWVVX99d0faeqPl5Vf1xVe2xO3QP886KvD15Uxw8n2qiqA6rqLVX13f49nLik5vtV1dv77ddW1Q+q6oNV9aTNKaCq9q2qN/btr+mvX3t1Ve26wuu3raqnVNVbq+pL/fGu6c/TO6pq/Sodd8WJJTZxjB+bWGJhXW4eyvfSpdet9a/70/75F27hGM/sX/fdqvKZfMa4JgoAWHNVtU+SI/qnr22tXbo57VprbTMPcUC63q0FlyW5Lskd013TcmRVvai19spl2r4tyS8ven5pkl3SDaW7d//4wMLGqjo43XDDnftV16e7lmnf/vGwJKctbjMGi6/V2WWZ7Q9J18u3Q7reuxsWb6yq30jyd7n5P9QvSTd08vAkh1fV25M8o7V24wrHv0eSf0tyh3TXbLV01649P13v2ENba0uvQXpk3yb96y/pl/umO9+/WFW/1lp72wrHHPW443JdkvOS7Jpku/zo9WqLvSnJS5Osr6qDWmv/b4X9/Vq/fEtr7aZxF8vqknoBgEk4NEn1X//HKuz/unQfZn8+ya6ttV1bazsl2SvJS5LcmOQVVfUzixtV1UPTfaC/McnzkuzSWrtdug/NP5HkGUk+veRYr04XoD6X5ODW2jattdsn2THJ/ZMcly6IjdO+i76+ZJntf5vkv5Mc1F9btkO6oJGqemBuDlDvSnLnvt7bJXlxumByVJJNXUP06nTv6SGttZ3Tvdcj003icI8kb1mmzRVJXpvuuradWmu7tda2T3KXdOdo6yRvqKp9l2l7a447Fq21U1preyf514VaFl2vtne/La21s5N8sH/NM5fbV1XdM93kIC03D81khghRAMAkHNAvr003ocRYtdbObK09q7X2odbaZYvWn99ae3mSl6ULcb+1pOkD+uWHW2vHtdYu79u11tr3W2tvaa29YIU2v99aO23Rsa5qrX2htfa81tpnx/oGk1/vlzelC0tLnZ/k0a210xfV/z/9tv+d7jPgZ5I8tf/Qn9baFa21VyQ5tn/dC6tquV6upBuG+ejW2qf7tje11t6T5Bf77Y+sqgcvbtBa+3hr7fdba59qrV21aP1ZrbXnpQu922WF4DHqcSfkH/rlUVV122W2L7zHTy76d2GGCFEAwCTs3i8vHjBEb5ze2y8ftGT9QuDac8B1Kgtt7nirq9qEqtqmqu5dVW9MN+V7kvxra+2CZV7+uuWuMauq3ZIc1j995QrD9V6V5JokOyV5zArl/Ftr7ZtLV7bWTk5ySv/0ySu/m2Wt9G+y2sddDe9NN/TvDkl+YfGG/vvqV/unb1rjuhgTIQoA2CJV1fb9TWk/XlXn95MrLEwAsNBjtHRmu4+mGwp4cJKPV3eT31ua/W7h2qu3VtWxVfWAFXofRvHSRTVfm+QrSZ7Vb/uvJL+zQruVer7ul64HriX5xHIv6K9P29A/PXi512TT90da2O+Pta2q3arqJVV1Sj9pxw2L3t8J/cs2db5HOu5aa63dkJuHFi7tWfv5JPukC9/vWsu6GB8TSwAAk7Awjfntq6rG3RtVVXdM94F7v0Wrr0xycbohcLdJN1HEjovbtda+UVW/neR16SZneEi/v43pJoZ4w+Ihe70/SnKvJA9M8sL+cU1VfTbJO5Mcf0szD27C4skLbkx3PdAZ6QLHv/Qf1pezXO9U0vWMJMmlrbXlJkVYcPaS1y+13E1ol277kbZVde8kH0t3XdqCy5NcnS7UbZNk4VqyW9r3Zh93gt6Y5H8leXRV7dVaO69fvzChxL8sHtbIbNETBQBMwhn9ctt0AWTcjksXoL6Vbujbbv0NfPfsJwB4wEoNW2tvSnLXJH+Q5D3pAt+6dNdPbaiqFy15/YXpJgl4ZLqJE05LFwgOSzfBw+lVdacR38fiyQv2aa3du7X2pP5+WisFqKQLXJuy7Yj13BpvThegTk3yqCQ7t9Z2aa3t1f+bPKV/Xa20g1nSWvtGut6xrdPdRDpVtXuSx/UvMZRvhglRAMAkfCJd70Ny84fKsaiqbZI8vn/6K621f2+tXbzkZXtlE1pr57XWXtNaOzJdz8Yh6Xp/Ksn/rqqfWvL61lr7SD9xwsHperl+M8lFSe6W5K9u7fsak4Uequ2ralM9Nguhb6UerU0NuVvY9sO2/Yx7h6QLd49rrX1wmZ6wTf6bjHLcKfDGfrkwpO9X0gXsr7TWPjeZkhgHIQoAWHP9jHAL1xL93iZmgfsRVbU5vRR75OaelqVD7xb83OYcL/lhQPrvdD0lZ6f7/LTJGeBaaxe31t6QZKHX6mGbe7xVdlpuDq+HLfeC/qa1Cze+PXWF/Wzq/SxsW9z2h6GstbbSkLzN+TcZetzVsHBPp835XnxXuino791Pp78QpkxrPuOEKABgUl6cbrKEOyX5p6rablMvrqpfTPKHm7Hfy3NzUDhomf3cMcnvrXCMbVbaaT+T3fX90237129VVZu6xvzqxa+ftNbaRUlO7p++cIUZCF+YbqrxK/KjNyxe7Jeq6m5LV/b32VqYXe+dizYt3Cdrr6rac5l2B+VHb3C8kqHHXQ0LszHe7pZe2Fq7Jsnb+6d/keS+6b6HNnVDYWaAEAUATERr7YtJnpMu8ByR5LR+NrzdFl5TVbtW1ROr6uR0NzndeTP2e3m6meuS5E1Vdd9+X1tV1SPSDSVcqRfh/1TVu6rqyCV17FVVr013rVRL8uF+0y5JvllVf1JVB1XVbZYc6xX96z6Y6fGSdL0pByf5l4Xrtapqp/56r6P71x27+B5bS1yX5P39jXsX3u9jc/Nscx9urX1m0evPSNeLV0n+taru0be7bVU9Md353NREF6MedzV8pV8+qg/kt2RhSN9CyPvP1tr54y+LtSREAQAT01r7xyRPTHdz2P3T/Q/9hVV1eVVdlm4o1LuTHJrkO+lmd9scz0vXC3RQunB2RboP6R9Jd4+qZ63Qbut0E1Gc0NdxaV/Hubm59+rFCzex7d0lycuTfDnJ1VV1YboP+x9J18v2rWxeD9qaaK2dkm5q9JvSDVE8q6ouSneuX5Eu6LwjN990dzkvSDeT3meq6vJ05/Y/0l0/9s0kT19yzJuSPLc/5qFJvtGf1yvS/ftem24ij1sy6Lir5IR017rtl+Tsqvp+VW3sZ3D8Ma21LyX5wqJVJpTYAghRAMBEtdZOTDf5wnPSDR87O12Y2TrJxnS9DL+c5F6ttU9u5j4/l+Rnk5yYblrz26YLaq9PN6TqSys0/at0H/bfk+TMdIFi2yTfTdcT9tDW2v9Z9PrL0t1M9bgkn083qcHO6aYm/+8kf5Lkvv01YFOjtfb6JPdP8k9Jvp/uxrqXpusRekpr7agVbsS74JtJfjpdILg03ZTxG9MNWfvp1tr3lznmCUke3h/j8nT/Jt9J8up096/anHM0+Ljj1lr7Qbrryf493b/3HdIF6btsotm/98vvJ3n/qhbImqjJ3CQcAADmQ1V9ON3EGa9qrR19S69n+glRAACwSvrrv87sn+7XWvvmJOthPAznAwCAVVBVOyX563TDQv9TgNpy6IkCAIAxqqo/SDdRxt7prqm7Jsn61tpXJ1gWY6QnCgAAxut26SaauDHJKUkOF6C2LHqiAAAABtATBQAAMIAQBQAAMMDWozZ85FZPMQ4QYM59+KZ31qRrAIC1picKAABgACEKAABggJGH8wHALKuqbyfZJcnGCZcCwGSsS3JZa+2uQxsKUQDMq12233773Q444IDdJl0IAGvvjDPOyNVXXz1SWyEKgHm18YADDthtw4YNk64DgAlYv359Tj311I2jtHVNFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABbT7oAAJiU08+5NOuOPmnSZWzSxmOPmHQJACyhJwoAAGAAIQoAAGAAIQoAAGAAIQoAAGAAIQoAAGAAIQoAAGAAIQoAAGAAIQqAqVWdX6+qz1XVFVV1ZVV9oap+q6r8DQNgIvwBAmCavT3JG5KsS/LPSd6YZIckf5fk+IlVBcBc23rSBQDAcqrqCUl+Ocm3kxzSWvtBv36bJO9O8rSqOrG19u8TLBOAOaQnCoBp9YR++RcLASpJWmvXJXlJ//R317wqAOaeEAXAtNq7X35rmW0L6x7S90wBwJoxnA+AabXQ+3TXZbbdrV9u3X/9tZV2UlUbVti0/+ilATDP9EQBMK1O6pd/WFW7Laysqtsmedmi191+TasCYO7piQJgWv1Lkqcl+fkkX62q9yS5JsnPJbljkrOS7Jvkpk3tpLW2frn1fQ/VweMsGID5oCcKgKnUWrsxyWOTHJ3kgiRP7x/fSPLAJJf3Lz1/IgUCMLf0RAEwtVpr1yd5Vf/4oaraLsk9k/ygtfbtSdQGwPzSEwXALHpqkm3S3YAXANaUEAXA1KqqXZZZd98kf57k4iTHrnVNAGA4HwDT7MNVdXWS09NdA3VAkiOSXJ3ksa21702yOADmkxAFwDR7V7qhe0cl2T7JOUnekOSVrbWzJ1kYAPNLiAJgarXW/jzd0D0AmBquiQIAABhAiAIAABhAiAIAABhAiAIAABhAiAIAABjA7HwAzK0D99k1G449YtJlADBj9EQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMYIpzAObW6edcmnVHnzT2/W40bTrAFk1PFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFABTraqOqKoPVdXZVXV1VX2rqt5ZVT876doAmE9CFABTq6peleQ/kxyc5ANJXpPk1CSPT/KZqjpqguUBMKe2nnQBALCcqto7yQuSnJfkp1pr5y/adliSjyX5syRvn0yFAMwrPVEATKu7pPs79bnFASpJWmsnJ7k8yR0mURgA802IAmBafSPJdUkOqao9Fm+oqocm2TnJRyZRGADzzXA+AKZSa+2iqnphkr9M8tWqOjHJhUnunuRxST6c5DdvaT9VtWGFTfuPqVQA5owQBcDUaq0dV1Ubk7wpya8v2vTNJMcvHeYHAGvBcD4AplZV/a8k70pyfLoeqB2TrE/yrSTvqKr/e0v7aK2tX+6R5GurWDoAWzAhCoCpVFWHJnlVkv9orf1ha+1brbWrWmunJnlCknOSPL+q7jbBMgGYQ0IUANPqF/rlyUs3tNauSvL5dH/H7reWRQGAEAXAtNq2X640jfnC+uvWoBYA+CEhCoBp9al++RtVtc/iDVX16CQPSnJNklPWujAA5pvZ+QCYVu9Kdx+on0tyRlWdkOTcJAekG+pXSY5urV04uRIBmEdCFABTqbV2U1U9Jslzkjw13WQSOyS5KMn7kry2tfahCZYIwJwSogCYWq2165Mc1z8AYCq4JgoAAGAAIQoAAGAAIQoAAGAA10TBrDjkoJGa7fjqc0dqt/u2V43U7pwjthvc5sYfmFwNAJgdeqIAAAAGEKIAAAAGMJwPgLl14D67ZsOxR0y6DABmjJ4oAACAAYQoAACAAYQoAACAAYQoAACAAYQoAACAAYQoAACAAUxxDsDcOv2cS7Pu6JMmXcbYbTRtO8Cq0hMFAAAwgBAFAAAwgBAFAAAwgGui5tBtdt9tcJvtTrjNSMe6z67njNTuoy998Ejttj/x8yO1mwVX33H7kdq97+4fHHMlm/aEdz9mcJsbH7YKhQAArBI9UQAAAAMIUQAAAAMIUQBMpap6RlW1W3jcOOk6AZg/rokCYFp9McnLVtj2kCQPT/L+NasGAHpCFABTqbX2xXRB6sdU1Wf7L9+wVvUAwALD+QCYKVV1UJIHJDknyUkTLgeAOSREATBrfqNf/mNrzTVRAKw5IQqAmVFV2yc5KsmNSd444XIAmFOuiQJglvxiktslOam19t3NaVBVG1bYtP+4igJgvuiJAmCWLAzle/1EqwBgrumJAmAmVNVPJnlgkrOTvG9z27XW1q+wvw1JDh5PdQDMEz1RAMwKE0oAMBWEKACmXlVtl+Rp6SaU+McJlwPAnDOcbw7dcK87D27zzru/eRUqWdlbnviAkdrd88Tx1sFw51y2y+A2e+TcVaiELcxTktw+yX9u7oQSALBa9EQBMAsWhvK9YaJVAECEKACmXFUdkOTBGTihBACsFsP5AJhqrbUzktSk6wCABXqiAAAABhCiAAAABhCiAAAABhCiAAAABhCiAAAABhCiAAAABjDFOQBz68B9ds2GY4+YdBkAzBg9UQAAAAMIUQAAAAMYzjeHzv/pHSddAiP47hFt0iVslitP3WNwmz1y5ipUAgCwOvREAQAADCBEAQAADCBEAQAADOCaKADm1unnXJp1R5806TJ+zEbTrgNMNT1RAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAEy9qnpEVZ1QVedW1bVV9b2q+mBVPWbStQEwf9wnCoCpVlX/N8kfJTk7yX8k+UGSOyRZn+TQJO+bWHEAzCUhCoCpVVW/ni5AvSXJb7TWrluy/bYTKQyAuSZEzaHL7nHjpEtgBIff9/Q1Pd7Xrr92pHZ3+6fzB7fxHclyqmrbJK9IclaWCVBJ0lq7fs0LA2DuCVEATKtHphu2d1ySm6rqiCQHJrkmyedba5+dYG0AzDEhCoBpdf9+eU2S09IFqB+qqk8meXJr7YK1LgyA+SZEATCt9uyXf5Tkq0kekuSLSe6a5NVJDk/yznSTS6yoqjassGn/cRQJwPwxxTkA02rhb9QNSR7XWvt0a+2K1tr/S/KEdLP1PayqfnZiFQIwl/REATCtLumXp7XWNi7e0Fq7qqo+mORZSQ5JsuL1Ua219cut73uoDh5LpQDMFT1RAEyrr/fLS1bYfnG/3H71SwGAmwlRAEyrjyZpSe5dVcv9vVqYaOLba1cSAAhRAEyp1tp3krw3yb5Jfn/xtqo6PMnPp+ul+sCaFwfAXHNNFADT7DlJ7pfkL/v7RJ2Wbna+I9Pdp/nZrbVLJ1ceAPNIiAJgarXWzq6q9Un+NMnjkjw0yWXpeqhe2Vr7/CTrA2A+CVEATLX+Zrq/1z8AYOJcEwUAADCAEAUAADCA4XxMpTt8eNtJlzB1nrPnySO23GakVpfcNNq/QV173UjtAABmhZ4oAACAAYQoAACAAYQoAACAAVwTBcDcOnCfXbPh2CMmXQYAM0ZPFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwABCFAAAwACmOAdgbp1+zqVZd/RJt3o/G02TDjBX9EQBAAAMIEQBAAAMYDjfHNrrnj+YdAm3aLtLbpx0Cavmukfdf6R2d9v6v8ZcyaadctU9R2p3w8azxlwJAMB00RMFAAAwgBAFAAAwgBAFAAAwgBAFAAAwgBAFwNSqqo1V1VZ4nDvp+gCYT2bnA2DaXZrkuGXWX7HGdQBAEiEKgOl3SWvtmEkXAQALDOcDAAAYQE8UANNu26o6Ksm+Sa5M8uUkn2ytbbl35QZgqglRAEy7vZO8bcm6b1fVM1trn7ilxlW1YYVN+9/qygCYS4bzATDN3pzkEemC1I5JDkry+iTrkry/qu4zudIAmFd6ogCYWq21ly1ZdXqS36qqK5I8P8kxSZ5wC/tYv9z6vofq4DGUCcCc0RMFwCz6+3750IlWAcBc0hM1yw45aKRm//6TfzdCqx1GOtY5N141Ursdvjva7V9uGqnVaLbabruR2l1+59F+7LavbUZqN6qPnHfAiC3PHmsdsIIL+uWOE60CgLmkJwqAWfSAfvmtiVYBwFwSogCYSlV1QFX9WE9TVa1L8rr+6dvXtCgAiOF8AEyvX0ry/Kr6ZJLvJLk8yd2THJFkuyTvS/LqyZUHwLwSogCYVicnuVeS+yV5ULrrny5J8ul09416W2utTaw6AOaWEAXAVOpvpHuLN9MFgLXmmigAAIABhCgAAIABhCgAAIABhCgAAIABhCgAAIABzM4HwNw6cJ9ds+HYIyZdBgAzRk8UAADAAHqiZtj1u2wzUrs9b7PDmCtZ2XZVI7Xb9jUXjnjEvUZsN9z9bvfdkdq9eI+/GXMlq+Mhd/jmSO0+le3GXAkAwHTREwUAADCAEAUAADCAEAUAADCAEAUAADCAiSUAmFunn3Np1h190qTLGJuNpmsHWBN6ogAAAAYQogAAAAYQogAAAAYQogAAAAYQogAAAAYQogAAAAYQogAAAAYQogCYGVV1VFW1/vHsSdcDwHxys90Ztv3pZ4/U7vnnHjK4zV/s/fmRjrX7VtuP1O7d93j/SO0Yn7d84LCR2t0tnx1zJdCpqjsneV2SK5LsNOFyAJhjeqIAmHpVVUnenOTCJH8/4XIAmHNCFACz4LlJHp7kmUmunHAtAMw5IQqAqVZVByQ5NslrWmufnHQ9AOCaKACmVlVtneRtSc5K8qIR97FhhU37j1oXAPNNiAJgmv1pkvsleXBr7epJFwMAiRAFwJSqqp9J1/v0F621kad9bK2tX2H/G5IcPOp+AZhfrokCYOr0w/jemuTMJC+ZcDkA8COEKACm0U5J9ktyQJJrFt1gtyV5af+af+jXHTepIgGYT4bzATCNrk3yjytsOzjddVKfTvL1xB2eAVhbQhQAU6efROLZy22rqmPShai3tNbeuJZ1AUBiOB8AAMAgQhQAAMAAQhQAM6W1dkxrrQzlA2BSXBM1w24497yR2n38+AcObrPxBR8f6Vh3v+1OI7W7sd00Urv3XrXLSO2O+/bPDW7zvQ13HOlYDzj0KyO1e/O+Hx+p3deuv3akdnf66PUjtQMA2NLpiQIAABhAiAIAABhAiAIAABhAiAIAABjAxBIAzK0D99k1G449YtJlADBj9EQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMYIpzAObW6edcmnVHnzTRGjaaYh1g5uiJAgAAGEBP1Bza669PGdzmN09/7kjHuuC+243U7nbfuGGkdtt/+Esjtdv22o2D29w1w9skyf2/cvFI7UZ1/EUPHKndNh/8wpgrAQDYMuiJAgAAGECIAgAAGECIAgAAGECIAgAAGECIAgAAGECIAmBqVdWrquqjVfXdqrq6qi6qqtOq6qVVtfuk6wNgPglRAEyz5yXZMcmHk7wmyTuS3JDkmCRfrqo7T640AOaV+0QBMM12aa1ds3RlVb0iyYuS/HGS31nzqgCYa3qiAJhaywWo3r/1y3uuVS0AsECIAmAWPbZffnmiVQAwlwznA2DqVdULkuyUZNckP53kwekC1LGb0XbDCpv2H1uBAMwVIQqAWfCCJHstev6BJM9orV0woXoAmGNCFABTr7W2d5JU1V5JHpiuB+q0qvqF1tqpt9B2/XLr+x6qg8ddKwBbPiGKzXKbkzf5GWVFe5885kJuQVvDY219p31GanfULqeMeMTtRmwHW47W2nlJTqiqU5OcmeStSQ6cbFUAzBsTSwAwc1pr30ny1SQ/WVV7TLoeAOaLEAXArPqJfnnjRKsAYO4IUQBMparar6p2XWb9Vv3NdvdMckpr7eK1rw6AeeaaKACm1WOSvLKqPp3k20kuTDdD38OS3C3JuUl+fXLlATCvhCgAptVHktwj3T2h7pfkdkmuTDehxNuSvLa1dtHEqgNgbglRAEyl1trpSX530nUAwFKuiQIAABhAiAIAABhAiAIAABhAiAIAABhAiAIAABjA7HwAzK0D99k1G449YtJlADBj9EQBAAAMoCcKRnT+I/cdqd0uW2035koAAFhLeqIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGMLEEAHPr9HMuzbqjT5p0GT9ioynXAaaenigAAIABhCgAAIABhCgAAIABhCgAAIABhCgAAIABhCgAAIABhCgAAIABhCgAplJV7V5Vz66qE6rqm1V1dVVdWlWfrqpnVZW/YQBMhJvtAjCtnpLk75J8P8nJSc5KsleSJyZ5Y5JHV9VTWmttciUCMI+EKACm1ZlJHpfkpNbaTQsrq+pFST6f5EnpAtW7J1MeAPPKUAgAplJr7WOttfcuDlD9+nOT/H3/9NA1LwyAuSdEATCLru+XN0y0CgDmkuF8AMyUqto6ya/2Tz+wGa/fsMKm/cdWFABzRU8UALPm2CQHJnlfa+2Dky4GgPmjJwqAmVFVz03y/CRfS/K0zWnTWlu/wr42JDl4fNUBMC/0RAEwE6rqd5O8JslXkxzWWrtowiUBMKeEKACmXlX9QZK/TnJ6ugB17mQrAmCeCVEATLWqemGSv0ryxXQB6vzJVgTAvBOiAJhaVfWSdBNJbEjyiNbaDyZcEgCYWAKA6VRVT0/yZ0luTPKpJM+tqqUv29haO36NSwNgzglRAEyru/bL2yT5gxVe84kkx69FMQCwQIiCEe1y1nUjtbu23TBSu23LjyvzpbV2TJJjJlwGAPwY10QBAAAMIEQBAAAMIEQBAAAMIEQBAAAMIEQBAAAMYLovAObWgfvsmg3HHjHpMgCYMXqiAAAABhCiAAAABhCiAAAABhCiAAAABhCiAAAABhCiAAAABjDFOQBz6/RzLs26o08a+343mjYdYIsmRMGILtt3m5HabVtr+2P37k8fMlK7e+ZzY64EAGDLYDgfAADAAEIUAADAAEIUAADAAEIUAADAAEIUAADAAEIUAADAAEIUAFOpqp5cVX9dVZ+qqsuqqlXV2yddFwC4TxQA0+rFSe6T5IokZyfZf7LlAEBHTxQA0+p5SfZLskuS355wLQDwQ3qiAJhKrbWTF76uqkmWAgA/Qk8UAADAAHqiANiiVdWGFTa5xgqAkeiJAgAAGEBPFIzowoddN+kSNsvd3zkbdcJqaa2tX25930N18BqXA8AWQE8UAADAAEIUAADAAEIUAADAAEIUAADAACaWAGAqVdWRSY7sn+7dL3+2qo7vv/5Ba+0Fa1wWAAhRAEyt+yZ5+pJ1d+sfSfKdJEIUAGvOcD4AplJr7ZjWWm3isW7SNQIwn4QoAACAAYQoAACAAYQoAACAAYQoAACAAYQoAACAAUxxDsDcOnCfXbPh2CMmXQYAM0aIghHdfvfLJ13CZrnt9y8Zqd2N4y0DAGCLYTgfAADAAEIUAADAAEIUAADAAEIUAADAAEIUAADAAGbnA2BunX7OpVl39EkTrWGjKdYBZo6eKAAAgAGEKAAAgAGEKAAAgAGEKAAAgAGEKAAAgAGEKAAAgAGEKAAAgAHcJwpGdJt37z5Su6fv/vCR2u2z/SUjtasrrhqpHUyDqrpTkj9L8qgkuyf5fpITk7ystXbxBEsDYI4JUQBMpaq6e5JTkuyZ5D1JvpbkkCS/n+RRVfWg1tqFEywRgDllOB8A0+pv0wWo57bWjmytHd1ae3iSv0pyrySvmGh1AMwtIQqAqdP3Qh2eZGOSv1my+aVJrkzytKracY1LAwAhCoCpdFi//FBr7abFG1prlyf5TJIdkjxgrQsDANdEATCN7tUvz1xh+zfS9VTtl+Sjm9pRVW1YYdP+o5UGwLzTEwXANNq1X166wvaF9bdb/VIA4EfpiQJgi9ZaW7/c+r6H6uA1LgeALYCeKACm0UJP064rbF9Yf8nqlwIAP0qIAmAafb1f7rfC9nv2y5WumQKAVSNEATCNTu6Xh1fVj/ytqqqdkzwoyVVJ/mutCwMAIQqAqdNa+58kH0qyLslzlmx+WZIdk7yttXblGpcGACaWAGBq/U6SU5K8tqoekeSMJD+T7h5SZyb5kwnWBsAcE6JgRLc//rMjtbvg+NGOd8FozZKcN3JLmKTW2v9U1U8n+bMkj0rymCTfT/KaJC9rrV08yfoAmF9CFABTq7X23STPnHQdALCYa6IAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGMDsfAHPrwH12zYZjj5h0GQDMGD1RAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAAwhRAAAAA2w96QIAYELWnXHGGVm/fv2k6wBgAs4444wkWTdKWyEKgHm109VXX33jqaee+qVJFzJl9u+XX5toFdPHeVmZc7M852V503Re1iW5bJSGQhQA8+r0JGmt6YpapKo2JM7LUs7Lypyb5Tkvy9tSzotrogAAAAYYuSfqwze9s8ZZCAAAwCzQEwUAADCAEAUAADCAEAUAADBAtdYmXQMAAMDM0BMFAAAwgBAFAAAwgBAFAAAwgBAFAAAwgBAFAAAwgBAFAAAwgBAFAAAwgBAFwBahqu5UVW+qqu9V1bVVtbGqjquq2w/cz259u439fr7X7/dOq1X7aru156aqdqyqX6mqf6qqr1XVlVV1eVV9oaqeX1XbrPZ7WA3j+p5Zss+HVtWNVdWq6uXjrHetjPO8VNXB/ffN2f2+zquqT1TVr65G7atpjL9jHlxV7+nbX1NVZ1XV+6rqUatV+2qpqidX1V9X1aeq6rL++/7tI+5r7D+Pq8nNdgGYeVV19ySnJNkzyXuSfC3JIUkOS/L1JA9qrV24GfvZvd/Pfkk+luS/k+yf5PFJzk/ys621b63Ge1gt4zg3/Ye79ye5KMnJSb6Z5PZJHpdk737/j2itXbNKb2PsxvU9s2SfOyf5cpI9kuyU5BWttRePs+7VNs7zUlW/m+Q1SS5OclKSc5LsluTAJGe31p469jewSsb4O+a3k/xtkiuTnJDk7CR3SvLEJDskeXFr7RWr8R5WQ1V9Mcl9klyR7r3sn+QdrbWjBu5n7D+Pq6615uHh4eHhMdOPJB9M0pL83pL1f9mv//vN3M/r+9f/xZL1z+3Xf2DS73US5ybJfZP8SpJtlqzfOcmGfj/Pn/R7ncT3zJK2b0oXNF/U7+Plk36fkzovSQ5PclO/v52X2X7bSb/XtT4vSW6b5JIkVye515JtByS5JslVSbad9PsdcF4OS3LPJJXk0P5cvH1S33dr+dATBcBM6/8H85tJNia5e2vtpkXbdk7y/XR/4PdsrV25if3slK636aYkd2ytXb5o21ZJvpXkLv0xZqI3alzn5haO8ctJ3pHkP1trj73VRa+B1TgvVfX4JCcmeVqSrZO8OTPWEzXO81JVX0pyjyT7tmnrQRhojL9j9kpybpIvt9bus8z2Lyc5KMkes3jOqurQdD3Vg3qi1uL31GpwTRQAs+6wfvmhxX98k6QPQp9JN0zmAbewnwck2T7JZxYHqH4/C/+jvvh4s2Bc52ZTru+XN9yKfay1sZ6XqtozyT8kObG1NtL1IFNiLOelqg5M8lNJPpTkoqo6rKpe0F8/94j+PyVmybi+X85PckGS/arqnos3VNV+6Xp0vjiLAepWWovfU2M3a9/EALDUvfrlmSts/0a/3G+N9jNN1uI9/Vq//MCt2MdaG/d5+Yd0n6l+69YUNQXGdV7u3y/PT/LxdNcX/nmSVyf5SJIvVtU9Ri9zzY3lvLRu+Ndz0n2vbKiqt1TVK6vqremGxX4lyVPGUO+smcnfvVtPugAAuJV27ZeXrrB9Yf3t1mg/02RV31M/ccCjknwx3fVAs2Js56Wqfi3dBBu/1Fo779aXNlHjOi979stnpZtM4ogkn06yV5I/TXJUkpOq6qDW2nUjV7t2xvb90lp7Z1V9L8k/J1k8Q+F56YaAzsRQ4TGbyd+9eqIAgMGq6olJjkt3jceTWmvXb7rFlqeq1qU7B+9srf3bZKuZKgufL2+T5Kmttfe11i5rrX0jXXD4QrpehSdNqsBJqaqj0vXGfSrdZBI79MuPJnldkn+ZXHUMIUQBMOsW/pdy1xW2L6y/ZI32M01W5T1V1ZHpPuydn+TQWZloY5FxnZc3pZtp7XfGUNM0GNd5Wdh+bmvts4s39EPa3tM/PWRgfZMylvPSX/f0pnTD9p7WWvtaa+3q1trX0k1IsiHJU/oJGubJTP7uFaIAmHVf75crjZdfuIB7pfH2497PNBn7e6qqpyR5Z7rhRw9rrX39FppMo3Gdl4PTDV27oL/JaKuqlm5YVpL8Sb/uxFtV7doZ98/SJStsv7hfbr95ZU3cuM7L4emmOf/EMhMo3JTkk/3T9aMUOcNm8neva6IAmHUn98vDq2qrZabHfVC6e6/81y3s57/S9So8qKp2XmaK88OXHG8WjOvcLLT5lSRvSXedy2Ez2AO1YFzn5a3phmMtdc8kD013rdiGJKfd2oLXyDh/lq5Msq6qdlxmWuoD++W3x1DzWhjXedm2X95hhe0L62fhOrFxGuvvqbWiJwqAmdZa+590UymvSzfz1WIvS7Jjkrct/iBXVftX1f5L9nNFkrf1rz9myX5+t9//B2cpOIzr3PTrn54uNJyV5KGzdB6WGuP3zHNba89e+sjNPVEn9ev+ZtXezBiN8bxcleQfk2yX5OVVVYtef1CSZ6SbEv9d438X4zfGn6NP9csnV9VPLd5QVfdN8uR0N5b92NiKnyJVddv+vNx98fpRzu80cLNdAGZe/0f5lHRDq96T5IwkP5Pu/iNnJnng4nuv9EOu0lqrJfvZvd/Pfuk+yHw+3UXfj093/c8D+z/4M2Mc56aqDkt3MfxW6a7p+O4yh7qktXbc6ryL8RvX98wK+35GZvBmu8lYf5Z2SfKJJPdN8rl09/rZK8kT0w3j+4PW2mtW+e2MzRjPy5uSPDNdb9MJSb6TLjwcmWSbJMe11p63uu9mfPrrI4/sn+6d5OfTzTC4EBh/0Fp7Qf/adel6H7/TWlu3ZD+Dzu80EKIA2CJU1Z2T/Fm6Kbd3T3eX+xOSvKy1dvGS1674gbiqdkvy0nQfDO6Y5MIk70/yp621s1fxLayaW3tuFoWCTfmxD0bTblzfM8vs9xmZ0RCVjPVnaackf5zu3kd3STdc9vNJXt1a+9BqvofVMI7z0vfKPT1db9x9kuyc5LJ0Qz7/obU2U7PzVdUx6X5fruSHvxc2FaL67Zt9fqeBEAUAADCAa6IAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAGEKIAAAAG+P/TqbvI6aeeYAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "image/png": {
       "width": 424,
       "height": 235
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como pudemos ver, nossa rede não faz ideia de que digito seja. Isso porque ela foi inicializada com pesos aleatórios e ainda não foi treinada!\n",
    "\n",
    "\n",
    "### Usando `nn.Sequential`\n",
    "\n",
    "PyTorch também fornece um modo mais conveniente para construir redes mais simples, onde o tensor é passado de forma sequencial pelas operações, `nn.Sequential` ([documentação](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Podemos utilizá-lo para construir uma rede similar equivalente à acima:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Hyperparametros da rede \n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Construindo a rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Passo Forward de uma única amostra pela rede e mostrando a saída\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "image/png": {
       "width": 424,
       "height": 235
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nosso modelo aqui é o mesmo que o de antes, com 784 unidades de entrada, uma camada oculta com 128 unidades, ativação ReLU, camada oculta com 64 unidades seguida por outra ReLU, e então a camada de saída com 10 unidades seguida pela Softmax.\n",
    "\n",
    "As operações ficam disponíveis se consultadas pelo indice apropriado. Podemos, por exemplo, consultar os pesos da primeira operação linear usando `model[0]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(model[0])\n",
    "print(model[0].weight)\n",
    "#print(model[0].bias)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.7908e-02, -1.8985e-02,  2.6389e-02,  ..., -1.5206e-02,\n",
      "          5.7172e-03,  3.9179e-03],\n",
      "        [-1.4419e-02, -3.0349e-02, -1.4357e-02,  ...,  9.6216e-03,\n",
      "          3.4604e-02, -5.5924e-03],\n",
      "        [-3.3952e-02,  2.9855e-02,  5.4988e-04,  ..., -3.0222e-02,\n",
      "          1.9547e-02,  2.0608e-02],\n",
      "        ...,\n",
      "        [ 2.7459e-02,  1.6633e-03, -1.5543e-02,  ...,  1.3676e-02,\n",
      "          2.2794e-02, -2.7444e-02],\n",
      "        [ 6.6063e-03,  1.8149e-02, -3.1262e-02,  ...,  3.3945e-02,\n",
      "          3.0847e-02,  3.0943e-02],\n",
      "        [ 5.7226e-03,  8.8888e-03, -6.7924e-05,  ...,  2.4681e-02,\n",
      "         -1.0513e-02, -3.1997e-02]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos também passar um `OrderedDict` para dar um nome a cada camada de forma individual, e assim buscar por elas sem precisar passar um índice. Note que as chaves desse dicionário devem ser únicas, então _cada operação deve ter um nome diferente_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora podemos acessar as camadas tanto pelo indice quanto pelo nome."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(model[0])\n",
    "print(model.fc1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Treinando a rede Neural\n",
    "\n",
    "A rede que construimos ainda não é tão esperta, e não é capaz de reconhecer os dígitos:\n",
    "\n",
    "<img src=\"assets/function_approx.png\" width=500px>\n",
    "\n",
    "A princípio, a função responsável por mapear as entradas para as saídas é composta por pesos aleatórios. Nós vamos treinar o modelo apresentando dados reais, e ajustando esses pesos a fim de aproximar a saída da função do rótulo real esperado.\n",
    "\n",
    "Para encontrar esses pesos, ou parametros, precisamos identificar o quanto a rede está errando, e pra isso usamos a já conhecida **funçao loss** (também chamada de função de custo), uma medida de quanto as estimativas da rede estão errando. Uma função loss que já vimos para regressão e classificação é o erro médio quadrático:\n",
    "\n",
    "$$\n",
    "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
    "$$\n",
    "onde $n$ é o número de amostras de treinamento, $y_i$ são os rótulos verdadeiros, e $\\hat{y}_i$ são os rótulos estimados.\n",
    "\n",
    "Minimizando esse erro ao ajustar os pesos da rede conseguimos encontrar a configuração em que o erro é mínimo e a rede fica pronta para estimar os rótulos que fornecem a melhor acurácia. Podemos encontrar esse erro mínimo utilizando um processo chamado **gradiente descendente**. O gradiente é o vetor de derivadas, ou seja, inclinação da função de custo em direção ao mínimo da função. Para alcançar o ponto mínimo, devemos seguir o gradiente na direção de sua descida. Pense se estivesse descendo uma montanha e cada iteração fosse um passo na direção de sua base.\n",
    "\n",
    "<img src='assets/gradient_descent.png' width=350px>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backpropagation\n",
    "\n",
    "Para redes com uma única camada, o gradiente descendente é mais fácil de implementar, como vimos na última aula. No entanto, fica mais complicapo para redes mais profundas, como a que construímos. A complexidade é tanta que levou cerca de 30 anos até que os pesquisadores descobrissem uma forma adequada de treinar essas redes.\n",
    "\n",
    "O treinamento de redes multi-camadas é feito pelo algoritmo **backpropagation**, o qual é apenas uma aplicação da regra de cadeia em calculo. É mais fácil entender se convertermos uma rede de 2 camadas em uma representação gráfica.\n",
    "\n",
    "\n",
    "\n",
    "<img src='assets/backprop_diagram.png' width=550px>\n",
    "\n",
    "No passo forward, os dados e operações seguem de baixo pra cima. A entrada $x$ passa pela transformação linear\n",
    "$L_1$ com pesos $W_1$ e biases $b_1$. A saída passa pela Sigmoid $S$ e outra camada linear $L_2$. Finalmente computamos a saída da função loss $\\ell$, o qual é usado para medir o quanto a rede está errando. O objetivo é ajustar os pesos e bias para minimizar $\\ell$.\n",
    "\n",
    "Para treinar os pesos com gradiente descendente, propagamos o gradiente do erro de volta pela rede. Cada operação tem alguns gradientes entre a entrada e a saída. Conforme enviamos os gradientes de volta, multiplicamos o gradiente atual pelo gradiente da operação. Matematicamente falando, o que o método faz é apenas calcular o gradiente do erro em relação aos pesos usando a regra da cadeia.\n",
    "\n",
    "\n",
    "$$\n",
    "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
    "$$\n",
    "\n",
    "Os pesos são atualizados usando esse gradiente em conjunto com uma taxa de aprendizagem $\\alpha$. \n",
    "\n",
    "$$\n",
    "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
    "$$\n",
    "\n",
    "A taxa de aprendizagem $\\alpha$ é escolhida de forma que a atualização dos pesos a cada passo seja pequena o suficiente para que o método chegue ao valor mínimo de loss de forma iterativa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Funções de loss em PyTorch\n",
    "\n",
    "Vamos relembrar como calcular funções de loss usando PyTorch. Usando o módulo `nn`, podemos encontrar várias funções _loss_, como por exemplo a entropia cruzada (`nn.CrossEntropyLoss`). Essa função geralmente é atribuída como `criterion`. Como vimos anteriormente, classificação multi-classe, como no caso da MNIST, usamos a softmax para predizer a probabilidade de cada classe. Com a saída da softmax, queremos usar a entropia cruzada como função de _loss_. Para calcular o erro de fato, precisamos definir o critério e passar os rótulos corretos à nossa rede.\n",
    "\n",
    "\n",
    "\n",
    "Note um ponto muito importante na documentação:[documentação de `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
    "\n",
    "> Esse critério combina `nn.LogSoftmax()` e `nn.NLLLoss()` em uma única classe.\n",
    ">\n",
    "> A saída deve conter a pontuação esperada para cada classe.\n",
    "\n",
    "Isso significa que precisamos passar diretamente a saída da rede para computar o _loss_, em vez de fornecer a saída após passar pela função Softmax. Essa saída direta (antes da Softmax) é chamada *logit* ou *scores*. Usamos os logits porque as probabilidades fornecidas pela Softmax ficam muito próximas de 0 ou 1. ([leia mais aqui](https://docs.python.org/3/tutorial/floatingpoint.html)). Ou seja, é melhor evitar calculos usando probabilidades, uma vez que é mais comum usar o log das probabilidades."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define as transformações para normalizar os dados\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Baixa e/ou carrega os dados\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Definindo a função loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Obtendo os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logits = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.3231, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As vezes pode ser mais conveniente construir um modelo usando como saída a função log-softmax usando `nn.LogSoftmax` ou `F.log_softmax` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Então você pode obter as probabilidades reais através da exponencial `torch.exp(output)`. Com a saída da log-softmax, podemos computar o _negative log likelihood_, `nn.NLLLoss` ([documentação](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)), o que é equivalente à saída da `nn.CrossEntropyLoss`. \n",
    "\n",
    ">**Exercício:** Construa um modelo que retorne o log-softmax como saída e calcule a função de loss utilizando o _negative log likelihood_. Note que para `nn.LogSoftmax` e `F.log_softmax` você precisa setar o parâmetro `dim` de forma apropriada. `dim=0` computa o softmax pelas linhas (amostras), de forma que as colunas somem 1, enquanto `dim=1` calcula a softmax pelas colunas, de forma que as linhas somem 1. Pense no que deseja como saída e escolha `dim` de forma apropriada.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# TODO: Construa sua rede feed-forward com saída log-softmax\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Defina a função de loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Rode o trecho para testar se funcionou\n",
    "# Obtém os dados\n",
    "images, labels = next(iter(trainloader))\n",
    "# achatando a imagem (2-D para 1-D)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Passagem Forward pass, pegando os logits\n",
    "logps = model(images)\n",
    "# Calculando o erro com os logits e os rótulos\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2.3018, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Autograd\n",
    "\n",
    "Agora que sabemos como computar o _loss_, como usá-lo no backpropagation? O PyTorch tem um módulo chamado `autograd` que computa os gradientes de forma automática. Autograd armazena as operações executadas em cada tensor, então faz o passe de volta calculando os gradientes pelo caminho. Para ter certeza que PyTorch está armazenando as operações de um tensor, devemos setar `requires_grad = True` no tensor. Podemos fazer isso em sua criação com a chamada `requires_grad`, ou a qualquer momente com `x.requires_grad_(True)`.\n",
    "\n",
    "Também é possível desligar os gradiente de um bloco usando `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "x = torch.zeros(1, requires_grad=True)\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n",
    "```\n",
    "\n",
    "Além disso, podemos ligar ou desligar a armazenagem de todos os gradientes ao mesmo tempo usando `torch.set_grad_enabled(True|False)`.\n",
    "\n",
    "Os gradiente são computados em relação a alguma variável `z` com `z.backward()`. Isso faz o passo de volta pela operação que criou `z`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.2380,  0.9605],\n",
      "        [ 0.8407, -1.5803]], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "y = x**2\n",
    "print(y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.0566, 0.9226],\n",
      "        [0.7068, 2.4974]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abaixo podemos ver a operação que criou `y`, uma operação ao quadrado `PowBackward0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "## grad_fn mostra a função que gerou essa variável\n",
    "print(y.grad_fn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<PowBackward0 object at 0x7f89940f5370>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O modulo autograd mantém registro dessas operações e sabe como computar o gradiente de cada uma. Dessa forma, ele consegue computar o gradiente para uma cadeia de operações, com relaçao a qualquer tensor. Vamos reduzir o tensor `y` para um escalar, computando a média."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.0459, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos verificar os gradientes de `x` e `y`, mas no momento eles estão vazios."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_5908/106071707.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para computar os gradientes, precisamos executar o comando `.backward` na variável `z`, por exemplo. isso irá computar o gradiente de `z` em relação a `x`.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.1190,  0.4803],\n",
      "        [ 0.4204, -0.7902]])\n",
      "tensor([[-0.1190,  0.4803],\n",
      "        [ 0.4204, -0.7902]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O calculo dos gradientes é muito importante para qualquer rede neural. Uma vez que conhecemos o gradiente, podemos executar o gradiente descendente."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Juntando a função Loss e Autograd \n",
    "\n",
    "Quando criamos uma rede com PyTorch, todos os parametros são inicializados com `requires_grad = True`. Isso significa que quando computamos o erro e chamamos `loss.backward()`, os gradientes dos parâmetros são computados. Esses gradientes são usados para atualizar os pesos usando gradiente descendente. Abaixo vemos um exemplo de como computar os gradientes usando a passagem de volta (_backward pass_)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Construindo uma rede feed-forward\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007],\n",
      "        [-0.0030, -0.0030, -0.0030,  ..., -0.0030, -0.0030, -0.0030],\n",
      "        ...,\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Treinando a rede!\n",
    "\n",
    "A última peça que precisamos para começar a treinar é a seleção do otimizador, o qual utilizaremos para atualizar os pesos com o gradiente. Esses otimizadores estão em disponíveis em [`optim` package](https://pytorch.org/docs/stable/optim.html). Como exemplo, podemos usar o gradiente descendente estocástico (SGD) com `optim.SGD`. Definimos da seguinte forma:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora que sabemos como utilizar as partes individuais, é hora de juntar tudo. O processo geral pode ser definido da seguinte forma:\n",
    "\n",
    "* Fazer a passagem forward na rede\n",
    "* Usar a saída da rede para computar o o erro (_loss_)\n",
    "* Fazer a passagem de volta (backward) pela rede com `loss.backward()` para computar os gradientes\n",
    "* Utilizar o otimizador para atualizar os pesos\n",
    "\n",
    "Abaixo passamos por um passo do treinamento e printamos como os pasos e gradientes vão mudando. Note que a linha `optimizer.zero_grad()` é usada para zerar os gradientes, que são acumulados a cada bassagem backward. Ou seja, esses valores devem ser zerados a cada iteração para evitar os valores acumulados em outras passadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print('Pesos iniciais - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Limpa os gradientes acumulados\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Passagens Forward, backward, e atualização dos pesos\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradiente -', model[0].weight.grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pesos iniciais -  Parameter containing:\n",
      "tensor([[ 0.0248,  0.0088,  0.0346,  ...,  0.0331,  0.0308,  0.0265],\n",
      "        [-0.0061, -0.0136,  0.0256,  ..., -0.0336, -0.0328,  0.0155],\n",
      "        [ 0.0350, -0.0186,  0.0174,  ..., -0.0272, -0.0329,  0.0038],\n",
      "        ...,\n",
      "        [ 0.0065,  0.0302,  0.0051,  ...,  0.0246, -0.0053,  0.0353],\n",
      "        [ 0.0141, -0.0003,  0.0245,  ...,  0.0006,  0.0352, -0.0219],\n",
      "        [ 0.0022,  0.0090, -0.0168,  ..., -0.0291, -0.0232,  0.0009]],\n",
      "       requires_grad=True)\n",
      "Gradiente - tensor([[-7.8506e-05, -7.8506e-05, -7.8506e-05,  ..., -7.8506e-05,\n",
      "         -7.8506e-05, -7.8506e-05],\n",
      "        [-1.1317e-03, -1.1317e-03, -1.1317e-03,  ..., -1.1317e-03,\n",
      "         -1.1317e-03, -1.1317e-03],\n",
      "        [-3.1830e-03, -3.1830e-03, -3.1830e-03,  ..., -3.1830e-03,\n",
      "         -3.1830e-03, -3.1830e-03],\n",
      "        ...,\n",
      "        [ 4.6954e-03,  4.6954e-03,  4.6954e-03,  ...,  4.6954e-03,\n",
      "          4.6954e-03,  4.6954e-03],\n",
      "        [ 5.8513e-04,  5.8513e-04,  5.8513e-04,  ...,  5.8513e-04,\n",
      "          5.8513e-04,  5.8513e-04],\n",
      "        [-2.2105e-03, -2.2105e-03, -2.2105e-03,  ..., -2.2105e-03,\n",
      "         -2.2105e-03, -2.2105e-03]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Passo de atualização dos pesos\n",
    "optimizer.step()\n",
    "print('Pesos Atualizados - ', model[0].weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pesos Atualizados -  Parameter containing:\n",
      "tensor([[ 0.0248,  0.0088,  0.0346,  ...,  0.0331,  0.0308,  0.0265],\n",
      "        [-0.0061, -0.0136,  0.0256,  ..., -0.0336, -0.0328,  0.0155],\n",
      "        [ 0.0351, -0.0186,  0.0174,  ..., -0.0272, -0.0328,  0.0038],\n",
      "        ...,\n",
      "        [ 0.0065,  0.0301,  0.0051,  ...,  0.0245, -0.0053,  0.0353],\n",
      "        [ 0.0141, -0.0003,  0.0245,  ...,  0.0006,  0.0352, -0.0219],\n",
      "        [ 0.0022,  0.0090, -0.0168,  ..., -0.0291, -0.0231,  0.0010]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando de verdade\n",
    "\n",
    "Agora vamos colocar o algoritmo dentro de um laço para que possamos iterar por todas as imagens. Uma passagem por todas as amostras de treinamento é chamada época. Vamos iterar pelo `trainloader` para obter nossos batches de treinamento. Para cada batch, vamos fazer uma passada de treinamento onde é computado o erro, faz o backpropagation e atualiza os pesos.\n",
    "\n",
    ">**Exercicio:** Implemente o treinamento completo de nossa rede. Se for implementada corretamente, você deverá ver o _loss_ diminuindo a cada época."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "## Sua solução vai aqui\n",
    "\n",
    "# TODO: defina o modelo, o critério e o atualizador\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784, 128), \n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "                      \n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: implemente a etapa de treinamento\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 1.894082000387757\n",
      "Training loss: 0.8660992916776682\n",
      "Training loss: 0.5402673182329898\n",
      "Training loss: 0.43951564182096453\n",
      "Training loss: 0.3929946764286901\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Com a rede treinada, podemos verificar as predições estimadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# desligando o gradiente para acelerar o processo\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# As saidas da rede são o log da probabilidade, por isso precisamos fazer o exponencial para termos as \n",
    "#    probabilidades reais.\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "image/png": {
       "width": 424,
       "height": 235
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b48a08561fd7e728b99163935dfd430a6e9dd7380afe98d8e7cbd9767295b8"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}