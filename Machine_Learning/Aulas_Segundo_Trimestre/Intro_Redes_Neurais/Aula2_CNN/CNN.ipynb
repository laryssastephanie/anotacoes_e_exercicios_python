{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f866698",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "---\n",
    "\n",
    "Nessa aula vamos treinar uma rede CNN para classificar imagens do dataset CIFAR-10 utilizando aumento de dados\n",
    "\n",
    "O dataset e composto de imagens coloridas divididas em 10 classes, como mostrado no exemplo:\n",
    "\n",
    "<img src='assets/cifar_data.png' width=70% height=70% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0655ddf",
   "metadata": {},
   "source": [
    "### Testando o [CUDA](http://pytorch.org/docs/stable/cuda.html)\n",
    "\n",
    "Como essas imagens sao maiores (32x32x3), pode ser muito util acelerar o processo de treinamento usando processamento em placa de videos. CUDA e uma plataforma de computacao paralela que utiliza tensores (algo tipo os arrays do numpy) para computar informacoes na GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0969f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA nao funcionando. Treinamento na CPU ...')\n",
    "else:\n",
    "    print('CUDA esta disponivel! Treinando na GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92044a05",
   "metadata": {},
   "source": [
    "---\n",
    "## Carregando e aumentando os [dados](https://pytorch.org/vision/stable/datasets.html)\n",
    "\n",
    "Carregar o dataset pode levar alguns minutos. Vamos carregar os dados de treinamento e teste, dividir o conjunto de treinamento em treinamento e validacao, e criar os Dataloaders para cada um desses conjuntos.\n",
    "\n",
    "\n",
    "#### Aumento de dados\n",
    "\n",
    "Vamos tambem executar uma forma simples de [aumento de dados](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced) que inverte e rotaciona as imagens de forma aleatoria. Isso e feito definindo uma transformacao do `torchvision`. Voce pode procurar mais tipos de transformacao para pre-processamento e aumento de dados [aqui](https://pytorch.org/vision/stable/transforms.html).\n",
    "\n",
    "\n",
    "Este tipo de aumento de dados deve adicionar alguma variedade em relacao a posicao das imagens, para que quando treinarmos o modelo e seja robusto em relacao a mudancas geometricas (exemplo: reconhecer um navio, independente da direcao em que ele esteja apontando). E recomendavel que voce sempre escolha uma ou duas transformacoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230d53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# numero de subprocessos usados para carregar os dados\n",
    "num_workers = 0\n",
    "# quantas amostras serao carregadas para cada batch\n",
    "batch_size = 20\n",
    "# porcentagem dos conjuntotes de treinamento e validacao\n",
    "valid_size = 0.2\n",
    "\n",
    "# converte os dados para um torch.FloatTensor normalizado\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # inverte e rotaciona aleatoriamente\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# escolhe os dados de treino e teste\n",
    "train_data = datasets.CIFAR10('~/.pytorch/CIFAR10_data/', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('~/.pytorch/CIFAR10_data/', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtem os indices de treino que serao usados para validacao\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define os samplers para extrair os batches de treinamento e validacao\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepara os data loaders (combina o dataset e o sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# especifica a classe das imagens\n",
    "classes = ['aviao', 'automovel', 'passaro', 'gato', 'veado',\n",
    "           'cachorro', 'sapo', 'cavalo', 'navio', 'caminhao']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f4797",
   "metadata": {},
   "source": [
    "### Visualizando o batch de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3baca3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# funcao auxiliar para desnormalizar e mostrar a imagem\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # converte o tensor para imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec015630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtem um batch de amostras de treinamento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # converte as imagens para formato numpy para apresentar\n",
    "\n",
    "# plota as imagens no batch, junto com os respectivos rotulos\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# mostra 20 imagens\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a17cda1",
   "metadata": {},
   "source": [
    "### Visualizando as imagens com maiores detalhes\n",
    "\n",
    "Aqui nos olhamos para os canais vermelho, verde e azul (RGB) normalizados como tres canais separados de intensidade em tons de cinza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba8d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = np.squeeze(images[3])\n",
    "channels = ['canal vermelho', 'canal verde', 'canal azul']\n",
    "\n",
    "fig = plt.figure(figsize = (36, 36)) \n",
    "for idx in np.arange(rgb_img.shape[0]):\n",
    "    ax = fig.add_subplot(1, 3, idx + 1)\n",
    "    img = rgb_img[idx]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(channels[idx])\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "            ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center', size=8,\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d31763",
   "metadata": {},
   "source": [
    "---\n",
    "## Definindo a  [arquitetura](http://pytorch.org/docs/stable/nn.html) da rede\n",
    "\n",
    "Agora vamos definir a arquitetura da CNN. Em vez de camadas lineares, como nas redes MLP, vamos usar as seguintes camadas:\n",
    "* [Camadas convolucionais](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d), as quais podem ser consideradas um empilhamento de imagens filtradas.\n",
    "* [Camadas Maxpooling](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d), as quais reduzem as dimensoes de uma entrada, mantendo apenas os pixels mais ativos da camada anterior.\n",
    "* As ja conhecidas camadas lineares e Dropout para evitar overfitting e produzir uma saida de dimensionalidade igual a 10 (numero de classes).\n",
    "\n",
    "A imagem abaixo apresenta 2 camadas convolucionais.\n",
    "\n",
    "<img src='assets/2_layer_conv.png' height=50% width=50% />\n",
    "\n",
    "#### Definindo um modelo com multiplas camadas convolucionais e definindo o comportamento do modelo durante a passagem feedforward.\n",
    "\n",
    "Note que quanto mais camadas convolucionais forem incluidas, mais complexos sao os padroes de cor e forma que o modelo e capaz de detectar. Para essa tarefa, e sugerido um modelo com 2 ou 3 camadas convolucionais, com camadas lineares e dropout para evitar overfitting. Para termos uma idea de como escolher esses valores, uma boa sugestao seria procurar trabalhos ja publicados. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ceb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definindo nossa arquitetura\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Camada convolucional (enxerga um tensor representando uma imagem de dimensao 32x32x3)\n",
    "        # primeiro parametro e o numero de canais de entrada (3 pq e RGB), segundo e o numero de canais de saida (16)\n",
    "        # terceiro e o tamanho do kernel (filtro de 3x3) e o padding e uma moldura para evitar que a imagem seja redimensionada.\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # Camada convolucional (enxerga um tensor de  16x16x16 - 16 canais, dimensionalidade reduzida de 32x32 pela camada de MaxPool)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # Camada convolucional (enxerga um tensor de  8x8x32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # camada max pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # camada linear (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        # camada linear (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        # camada dropout (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # adiciona uma sequencia de convolucoes e maxpooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # achata x, transformando em um vetor\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # adiciona a camada dropout\n",
    "        x = self.dropout(x)\n",
    "        # adiciona a primeira camada escondida, com ativacao relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # adiciona uma camada dropout\n",
    "        x = self.dropout(x)\n",
    "        # adiciona segunda camada escondida, com ativacao relu\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# cria uma CNN completa\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move os tensores pra GPU, se o CUDA estiver disponivel\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6698d54",
   "metadata": {},
   "source": [
    "### Definindo a  [funcao de custo](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "\n",
    "Precisamos decidir qual a melhor funcao de custo e otimizacao para a tarefa de classificacao.Precisamos tamber prestar atencao ao valor da **taxa de aprendizado**, uma vez que ela determina como o modelo vai convergir para um erro menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e6bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# especificamos como funcao de custo a funncao categorical cross-entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# e como funcao de otimizacao o gradiente descendente estocastico\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8404a",
   "metadata": {},
   "source": [
    "---\n",
    "## Treinando a rede\n",
    "\n",
    "Lembrem que precisamos verificar como o custo de treinamento e validacao diminuem conforme o tempo. Se o custo de validacao aumenta, pode indicar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "121f9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero de epocas de treinamento\n",
    "n_epochs = 12\n",
    "\n",
    "valid_loss_min = np.Inf # mantem registro do custo minimo de validacao\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # mantem registro dos custos de treinamento e validacao\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # treina o modelo #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move os tensores pra GPU se o CUDA estiver disponivel\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # limpa os gradientes de todas as variaveis otimizadas\n",
    "        optimizer.zero_grad()\n",
    "        # passo forward: computa as saidas do modelo\n",
    "        output = model(data)\n",
    "        # calcula o custo por batch\n",
    "        loss = criterion(output, target)\n",
    "        # passo backward: computa o gradiente do custo em respeito aos parametros do modelo\n",
    "        loss.backward()\n",
    "        # executa um unico passo de otimizacao (atualizacao dos parametros)\n",
    "        optimizer.step()\n",
    "        # atualiza o custo de trein\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # valida o modelo #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        # move os tensores para a GPU se o CUDA estiver disponivel\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # passo forward: computa as saidas do modelo\n",
    "        output = model(data)\n",
    "        # calcula o custo por batch\n",
    "        loss = criterion(output, target)\n",
    "        # atualiza o custo de validacao\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # calcula a media dos custos\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # imprime  as estatisticas de treino e validacao \n",
    "    print('Epoca: {} \\tCusto de treinamento: {:.6f} \\tCusto de validacao: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # salva o modelo se o custo de validacao diminuir\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Reducao do custo de validacao ({:.6f} --> {:.6f}).  Salvando o modelo ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_augmented.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003336fb",
   "metadata": {},
   "source": [
    "### Carregando o modelo com menor custo de validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea42841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_augmented.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabffd6",
   "metadata": {},
   "source": [
    "---\n",
    "## Testando a rede treinada\n",
    "\n",
    "Testa seu modelo treinado em dados novos. Um \"bom\" resultado sera uma CNN com acuracia por volta de 70% (ou mais, tente melhorar) sobre as imagens de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d688e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# registra o custo de teste\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "# itera sobre os dados de teste\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move os tensores pra GPU, se disponivel\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # passo forward: computa as saidas do modelo\n",
    "    output = model(data)\n",
    "    # computa o custo do batch\n",
    "    loss = criterion(output, target)\n",
    "    # atualiza o custo de teste\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # converte as probabilidades para a classe predita\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compara as predicoes com os rotulos reais\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # computa a acuracia para cada classe\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# media de custo de teste\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Custo de teste: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Acuracia de teste de %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Acuracia de teste de %5s: N/A (nenhuma amostra vista no treinamento)' % (classes[i]))\n",
    "\n",
    "print('\\nAcuracia de teste (Geral): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f87a3b",
   "metadata": {},
   "source": [
    "### Visualizando os resultados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2ad861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo um batch de amostras de teste\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.numpy()\n",
    "\n",
    "# movendo as entradas para GPU\n",
    "if train_on_gpu:\n",
    "    images = images.cuda()\n",
    "\n",
    "# obtendo as saidas\n",
    "output = model(images)\n",
    "# convertendo as probabilidades em classes\n",
    "_, preds_tensor = torch.max(output, 1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "# plotando as imagens do batch junto com a classe predita e real\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx].to('cpu'))\n",
    "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
    "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea813ee",
   "metadata": {},
   "source": [
    "# Exercicios\n",
    "\n",
    "1. Pesquise a [documentacao sobre transformacoes](https://pytorch.org/vision/stable/transforms.html) e adicione outros tipos de transformacao para aumento de dados e veja como o modelo vai se comportar.\n",
    "\n",
    "2. Tentar modificar o modelo para conseguir uma acuracia maior sobre o conjunto de teste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
