{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3b56c0-5293-4afc-918a-7f4d950ebf59",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "\n",
    "Assim como o PCA, o LDA e uma tecnica de transformacao linear que tambem pode ser utilizado para reducao de dimensionalidade, com a diferenca que o LDA e supervisionado, enquanto o PCA e nao supervisionado.\n",
    "\n",
    "O PCA tenta sumarizar o conjunto de caracteristicas se orientando pela direcao das maiores variancias. Em datasets grandes, muitas caracteristicas podem ser redundantes e correlatas, cuja remocao geralmente nao causa grande impacto no dataset para maioria das tarefas.\n",
    "\n",
    "Ja o LDA tenta reduzir a dimensionalidade dos dados retendo informacoes capazes de discriminar a classe a ser predita. O LDA tenta encontrar a reta (hyperplano) entre os agrupamentos de cada classe. Sendo assim, ele tenta projetar as amostras em um espaco dimensional onde esses agrupamentos sao o mais bem separaveis possivel, e os cada elemento esteja o mais proximo possivel do centro do agrupamento. As novas dimensoes sao rankeadas de acordo com suas capacidades de maximizar a distancia entre os agrupamentos e minimizar a distancia entre os pontos dentro de um agrupamento e seu centro. Essas dimensoes formam os discriminantes lineares do conjunto de caracteristicas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c7262-5636-4a5b-ba9f-06270bc1ad27",
   "metadata": {},
   "source": [
    "## Implementando LDA com o Scikit learn:\n",
    "\n",
    "Vamos utilizar o dataset Iris, muito famoso para problemas de classificacao. Informacoes sobre o dataset podem ser encontradas no link a seguir:\n",
    "https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e72d6e-e3a0-4e47-a897-ca96fe9b9542",
   "metadata": {},
   "source": [
    "## Importando pacotes e o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f62b08-c299-4aa8-bfff-02b62c8ba9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "dataset = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae32c0-ebbd-440a-bda5-6118044fb314",
   "metadata": {},
   "source": [
    "## Processamento dos dados\n",
    "\n",
    "Uma vez que o dataset esteja carregado em um dataframe pandas, o primeiro passo e separar o vetor de caracteristicas e os rotulos correspontes, e em seguida dividi-lo em treinamento e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466cfaf2-823c-4f64-9feb-5f8fbcefbee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1b866-d5d4-4de5-907d-e01aac8d1b0f",
   "metadata": {},
   "source": [
    "## Normalizacao dos dados\n",
    "\n",
    "Assim como a maioria dos algoritmos de ML, o LDA tambem requer (ou pelo menos funciona melhor) com dados normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0bea665-67a4-4585-b9c3-18b7ba7ea8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589d52f-25f6-41fc-ac60-53680771a8f1",
   "metadata": {},
   "source": [
    "## Executando o LDA\n",
    "\n",
    "Sao necessarias apenas poucas linhas para executarmos o LDA, utilizando a classe `LinearDiscriminantAnalysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17c76cc-4725-4dac-a142-3113fca3c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa7fe5-cba2-468f-885b-7d3da1253531",
   "metadata": {},
   "source": [
    "No codigo acima, importamos o LDA passando como parametro o numero de componentes que desejamos extrair, nesse caso 1. Na sequencia, executamos a funcao `fit_transform` para treinar e converter os dados de treinamento, e `transform` para converter os dados de teste considerando o modelo ja treinado.\n",
    "\n",
    "Note que, por ser um algoritmo supervisionado, o LDA requer como parametro os rotulos (y_train) para treinamento, diferente do PCA que e nao supervisionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc838bf9-1c04-456c-a295-e6bfc5c81798",
   "metadata": {},
   "source": [
    "## Treinando um classificador para predicoes\n",
    "\n",
    "Uma vez que gostariamos de comparar a performance do LDA com o PCA, podemos considerar uma tarefa de classificacao utilizando, por exemplo, o classificador Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9540431-3b97-4c80-a23c-e23579d90bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100cd4b-6a45-4779-bb9a-d4ba75150fed",
   "metadata": {},
   "source": [
    "## Avaliando a performance\n",
    "\n",
    "Como de costume, o ultimo passo e avaliar a performance do algoritmo utilizando alguma metrica, como por exemplo matriz de confusao, para verificarmos o quao bem o modelo foi na tarefa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb6e52b-f4c5-42c3-b399-f88468cf6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "Acuracia 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Acuracia ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e69a7-5bfa-4c77-8705-8133dbe795c1",
   "metadata": {},
   "source": [
    "Podemos ver que mesmo com um unico componente, o algoritmo foi capaz de obter uma acuracia de 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ed9b0-a5b7-44e7-8933-7cc04b580e83",
   "metadata": {},
   "source": [
    "## PCA vs LDA: qual escolher para tarefa de reducao de dimensionalidade?\n",
    "\n",
    "Para casos em que os dados sao distribuidos de maneira uniforme, LDA quase sempre se sai melhor que o PCA. No entando, para dados muito irregulares, PCA pode se dar maior, uma vez que LDA pode tender para classes majoritarias.\n",
    "\n",
    "Por fim, PCA tem a vantagem de poder ser aplicado em datasets rotulados e nao rotulados, enquanto LDA necessita dos rotulos para guiar o aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce846607-5461-4540-bf64-a46cfd0d7dd7",
   "metadata": {},
   "source": [
    "# Exercicios\n",
    "\n",
    "1. Execute o PCA no exemplo acima, usando o dataset Iris e Random Forest, e compare o resultado com o LDA.\n",
    "\n",
    "2. Comparar o LDA com o PCA para reducao de caracteristicas utilizando o dataset faces. Como classificador, compare os resultados do SVM e do Random Forest.\n",
    "\n",
    "3. LDA tambem pode ser usado como um algoritmo de classificacao, em que ele proprio encontra o hyperplano que melhor separa os dados. Compara o LDA na tarefa de classificacao com os resultados do exercicion numero 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
