{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLE (Locally Linear Embedding)\n",
    "\n",
    "LLE e um de varios metodos de reducao de dimensionalidade baseado na teoria spectral. O algoritmo tenta criar uma representacao de forma que os pontos que estao proximos em um espaco de maior dimensionnalidade permanecam proximos na representacao de menor dimensionalidade. \n",
    "\n",
    "O LLE cria as representacoes baseando-se apenas nas distancias entre as amostras vizinhas, sem considerar as distancias globais. O algoritmo assume que os dados estejam em um manifold suave (que nao apresente buracos) e que cada ponto esteja posicionados de forma aproximadamente linear aos seus vizinhos. Assumir a ultima parte permite que todos os pontos sejam expressos como uma soma ponderada dos seus vizinhos. A figura abaixo apresenta um manifold que nao e suave.\n",
    "\n",
    "<img src='assets/holes.jfif' width=400px>\n",
    "\n",
    "O LLE comeca construindo o mapa conforme os dados originais, que serao replicados nas representacoes com menor dimensao. O algoritmo assume que o dataset seja grande o suficiente e bem distribuido, de modo que tenha pontos suficientes para computar o $k$-NN, e inicia o processo criando a matriz de vizinhanca. Apos definir essa matriz, cada ponto e reconstruido como a soma linear de seus vizinhos. \n",
    "\n",
    "O nome LLE (Locally Linear Embedding) se da pela natureza das reconstrucoes. Uma vez que apenas os vizinhos participam da transformacao dos dados, essa reconstrucao e *local*, e e dada pelos coeficientes lineares, ou pesos, e por isso *linear*.\n",
    "\n",
    "Os pesos contribuem para a reconstrucao dos dados em em uma maior dimensionalidade sao os mesmos usados na representacao em uma menor dimensionalidade. Sendo assim, a funcao de custo deve ser definida de modo a nao depender da localizacao das amostras no espaco original, e ser representada por uma funcao de informacao geometrica definida pela matriz de pesos. Esses pesos sao aprendidos usando decomposicao de matriz, a qual gera uma unica solucao onde os pontos reconstruidos sao independentes. Nesse passo, a informacao geometrica da matriz de pesos e incorporada na estrutura global das representacoes.\n",
    "\n",
    "Vejamos cada etapa de forma mais detalhada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca pelos vizinhos\n",
    "\n",
    "A vizinhanca pode ser criada utilizando a tecnica $k$-vizinhos mais proximos ou a abordagem _$\\epsilon$-ball neighborhood_ .\n",
    "\n",
    "**K-nearest neighbor** - Cada ponto e conectado aos seus $k$-vizinhos mais proximos, o que sempre vai resultar em pelo menos $k$-vizinhos para cada ponto. Note que que cada ponto seleciona exatamente $k$-pontos e pode ser selecionado por algum outro ponto como vizinho, resultando em um numero de vizinhos maior do que o pre-estabelecido. A situacao e comum para casos de pontos isolados que selecionam vizinhos distantes, os quais podem selecionar um conjunto de vizinhos com uma distancia menor. Nesse caso, a matriz e ajustada para ser simetrica.\n",
    "\n",
    "**$\\epsilon$-ball neighbor** - Cada ponto seleciona todos os pontos dentro de uma circunferencia de raio $\\epsilon$ e centralizada na sua localizacao como seus vizinhos. As vezes o metodo conduz a pontos sem nenhum vizinho. Alem disso, pode ser dificil encontrar o melhor valor de $\\epsilon$ uma vez que valores pequenos podem gerar pontos isolados e valores grandes vao gerar um numero muito grande de vizinhos. Essa abordagem e boa para aproximar distancias geodesicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn import datasets, neighbors\n",
    "import numpy as np\n",
    "# vamos implementar o k-nn\n",
    "# usaremos o dataset iris\n",
    "iris_ = datasets.load_iris()\n",
    "\n",
    "iris = iris_.data\n",
    "def Knbor_Mat(X, K, t = 2.0, dist_metric = \"euclidean\", algorithm = \"ball_tree\"):\n",
    "    \n",
    "    n,p = X.shape\n",
    "    \n",
    "    knn = neighbors.NearestNeighbors(K+1, metric = dist_metric, algorithm=algorithm).fit(X)\n",
    "    distances, nbors = knn.kneighbors(X)\n",
    "    \n",
    "    return(nbors[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computando os pesos para reconstrucao\n",
    "\n",
    "O LLE tambem assume que os dados nao sejam muito ruidosos, de modo que nao existam muitas amostras anomalas. Sendo assim, cada ponto e reconstruido como a media ponderada de seus vizinhos. \n",
    "\n",
    "A matriz de pesos tem algumas caracteristicas muito interessante, como por exemplo, e invariante a reescala, rotacao e translacao, e pode ser solucionado utilizando operacoes algebricas em matrizes. \n",
    "\n",
    "Uma coisa a se lembrar e que se o numero de vizinhos for maior do que a dimensao original, essa solucao nao sera unica e alguns valores na matriz podem ter valor zero, o que pode ser resolvido adicionando um termo regularizador que penaliza pesos muito grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando os pesos de reconstrucao \n",
    "from scipy import linalg\n",
    "\n",
    "def get_weights(X, nbors, reg, K):\n",
    "    # n - numero de amostras\n",
    "    # p - numero de caracteristicas\n",
    "    n,p = X.shape\n",
    "    \n",
    "    # inicializa a matriz de pesos\n",
    "    Weights = np.zeros((n,n))\n",
    "    \n",
    "    # para cada amostra\n",
    "    for i in range(n):\n",
    "        # computa a covariancia com cada vizinho\n",
    "        X_bors = X[nbors[i],:] - X[i]\n",
    "        cov_nbors = np.dot(X_bors, X_bors.T)\n",
    "        \n",
    "        # introduz o termo regularizador\n",
    "        trace = np.trace(cov_nbors)\n",
    "        if trace >0 :\n",
    "            R = reg*trace\n",
    "        else:\n",
    "            R = reg\n",
    "        \n",
    "        # encontra os pesos dos vizinhos para essa amostra\n",
    "        cov_nbors.flat[::K+1] += R\n",
    "        weights = linalg.solve(cov_nbors, np.ones(K).T, sym_pos=True)\n",
    "\n",
    "        weights = weights/weights.sum()\n",
    "        Weights[i, nbors[i]] = weights\n",
    "        \n",
    "    return(Weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computando as representacoes usando a matriz de pesos\n",
    "\n",
    "Agora seguiremos para o ultimo passo do algoritmo, i.e., computar as representacoes dos dados com a ajuda da matriz de pesos. O erro de reconstrucao e computado utilizando decomposicao de matrizes, e os $p$ menores (com excessao do primeiro, ou seja, do segundo ate $p+1$ menores) autovetores sao usados como nossa nova representacao dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computando as representacoes \n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def Y_(Weights,d):\n",
    "    # n - numero de amostras\n",
    "    # p - numero de caracteristicas\n",
    "    n,p = Weights.shape\n",
    "    # cria uma matriz identidade de lado n\n",
    "    I = np.eye(n)\n",
    "    # subtrai os pesos da matriz identidade (todos os valores ficam negativos, com excessao da diagonal principal)\n",
    "    m = (I-Weights)\n",
    "    # multiplica a transposta dessa matriz por ela mesmo\n",
    "    M = m.T.dot(m)\n",
    "    \n",
    "    # computa os autovalores e autovetores\n",
    "    eigvals, eigvecs = eigh(M, eigvals=(1, d), overwrite_a=True)\n",
    "    ind = np.argsort(np.abs(eigvals))\n",
    "    \n",
    "    return(eigvecs[:, ind])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "n_points = 1000\n",
    "X, color = datasets.samples_generator.make_s_curve(n_points, random_state=0)\n",
    "\n",
    "def LLE_(X, K):\n",
    "    reg =0.001\n",
    "    nbors = Knbor_Mat(X,K)\n",
    "    print(nbors[0])\n",
    "    Weights = get_weights(X, nbors, reg,K)\n",
    "    \n",
    "    Y = Y_(Weights,2)\n",
    "    return(Y)\n",
    "test = [354,520, 246,134,3, 983, 186, 436, 893, 921]\n",
    "def plotter(K):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    Y = LLE_(X , K)\n",
    "    s = Y[test]\n",
    "    plt.scatter(Y[:,0],Y[:,1],c=color, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(s[:,0],s[:,1], c=\"black\")\n",
    "\n",
    "interact(plotter, K= widgets.IntSlider(min=10, max=100, value=10, step=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vantagens e desvantagens\n",
    "\n",
    "LLE tem propriedades interessantes. E um algoritmmo simples que proporciona uma solucao elegante e analitica, sem precisar de iteracoes e computacao de gradientes. A matriz de pesos e esparsa, o que torna a computacao mais facil. Assim como o ISOMAP, uma dificuldade e encontrar o melhor numero de vizinhos, uma vez que esse parametro e muito sensivel e pode proporcionar resultados completamente diferentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicios\n",
    "\n",
    "1. Converter o dataset digits usando LLE e comparar a visualizacao das representacoes com as do ISOMAP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
